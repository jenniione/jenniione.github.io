<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-04-12T04:24:38+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">JenDS</title><subtitle>JenDS by Jenny Won
</subtitle><author><name>Jenny Won (Dajeong Won)</name></author><entry xml:lang="ko"><title type="html">카이제곱 분포와 검정</title><link href="http://localhost:4000/2024/04/10/chi_squared_distribution_ko.html" rel="alternate" type="text/html" title="카이제곱 분포와 검정" /><published>2024-04-10T00:00:00+09:00</published><updated>2024-04-10T00:00:00+09:00</updated><id>http://localhost:4000/2024/04/10/chi_squared_distribution_ko</id><content type="html" xml:base="http://localhost:4000/2024/04/10/chi_squared_distribution_ko.html"><![CDATA[<h2 id="카이제곱-분포의-정의">카이제곱 분포의 정의</h2>

<table>
  <thead>
    <tr>
      <th><strong>DEFINITION</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>카이제곱 분포(Chi-Squared Distribution)</strong>은 \(k\) 개의 서로 독립이며, 표준 정규 분포를 따르는 확률 변수 \(X_1,\cdots, X_k\) 에 대하여, 각각의 확률 변수를 제곱한 다음 합하여 얻어지는 확률변수 <br /><center>$$Q = \sum_{i=1}^{k} X_i^2$$</center><br />의 분포이다. 즉, <br /><center> $$Q \sim X_k^{2}$$</center><br /> 이다. 이때, $k$를 <strong>자유도</strong>라고 한다.</td>
    </tr>
  </tbody>
</table>

<p>자유도가 $k$인 카이제곱 분포의 확률 밀도 함수(PDF)는 다음과 같다.</p>

\[f(x; k) =\dfrac{1}{\Gamma (r/2) 2^{r/2}}x^{r/2-1}e^{-x/2}\]

<ul>
  <li>$\Gamma(k/2)$ 는 감마 함수로, $(k/2)$ 의 인자(factorial)에 대한 일반화된 형태이다.</li>
</ul>

<h2 id="카이제곱-분포의-이해">카이제곱 분포의 이해</h2>
<p>자유도는 무엇이고, 카이제곱 분포는 왜 저런 모양을 띄는 걸까? 이를 이해해 보기 위해, 카이제곱 분포가 어떻게 그려지는 지 보자.</p>

<h3 id="자유도-k1">자유도 k=1</h3>
<p>표준 정규 분포를 따르는 하나의 확률 변수 \(X\)에 대한 카이제곱 분포를 그려보자.</p>

<p>하나의 확률 변수이므로 카이제곱 분포의 자유도는 1이라고 할 수 있다.</p>

<ul>
  <li>\(-1.5 \leq x \leq -1\) 와 \(1 \leq x \leq 1.5\)</li>
</ul>
<p align="center">
  <img class="image image--xl" src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/chi_squared_distribution/chi_squared_distribution_k=1(1).png" />
</p>

<p>구간 \(-1.5 \leq x \leq -1\) 와 \(1 \leq x \leq 1.5\) 의 확률 변수들을 제곱하면, 이것은 카이제곱 분포의 변량이 된다. 그리고, 제곱함으로써 그 확률값은 카이제곱 분포의 동일한 구간 \(1 \leq q \leq 2.25\) 에 누적된다. 같은 방식은 다양한 구간에서 반복해 보자.</p>

<ul>
  <li>\(-2.5 \leq x \leq 2\) 와 \(2 \leq x \leq 2.5\)</li>
</ul>

<p align="center">
  <img class="image image--xl" src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/chi_squared_distribution/chi_squared_distribution_k=1(2).png" />
</p>

<ul>
  <li>\(-0.5 \leq x \leq 0\) 와 \(0 \leq x \leq 0.5\)</li>
</ul>

<p align="center">
  <img class="image image--xl" src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/chi_squared_distribution/chi_squared_distribution_k=1(3).png" />
</p>

<h3 id="자유도-k-geq-2">자유도 \(k \geq 2\)</h3>
<p>이제부터 카이제곱 분포가 제곱의 <strong>‘합’</strong>임을 주목하자.</p>

<p>자유도가 1일 때는, 하나의 독립 변수를 제곱한 분포를 그렸다. 하지만, 독립 변수가 2개 이상일 때는 본격적으로 제곱의 ‘합’의 분포를 그리게 된다.</p>

<p>각각의 독립적인 확률변수 \(X_1, X_2\) 에 대해 \(Q = X_1^2 + X_2^2\) 은 다음과 같이 같은 구간에서 더 큰 값을 누적하게 된다.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/chi_squared_distribution/chi_squared_distribution_k=2.png" />
</p>

<p>자유도가 3, 4, … 로 점점 커질 때, 카이제곱 분포는 다음과 같이 변화한다.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/chi_squared_distribution/chi_squared_distribution_diff.png" />
</p>

<p>더 많은 확률 변수를 합한다는 것은 분산이 커지고, 가장 큰 확률 값을 갖는 구간 역시 커진다는 것을 의미하며, 그래프가 오른쪽으로 이동한다.</p>

<h2 id="카이제곱-분포의-활용">카이제곱 분포의 활용</h2>
<p>그럼 굳이 확률 변수들의 제곱의 합을 분포로 나타낼 필요성은 무엇일까?</p>

<p>제곱의 합은 사실 수학에서 <strong>오차나 편차 등 ‘차이’를 다루기 위해 많이 사용</strong>된다. - 물론, 방향성을 없애기 위해 절댓값을 활용할 수도 있지만 제곱이 미분에 유리하다. MSE 와 MAE 에 대한 이야기는 넘어가자.- 사실 지금까지의 카이제곱의 이해는 독립 변수들의 제곱의 합으로 발생하는 새로운 변수의 분포 형태를 이야기한 것이다. 이것이 이후의 p-value 등의 개념과 결합하여 확장되니, 우선은 서로 독립인 변수들의 제곱의 합이 이러한 분포 형태를 띈다라는 것을 이해하고 넘어가는 것으로 충분하다.</p>

<p>그렇지만 조금 아쉬우니 잠깐 엿보기를 위해, <strong>수학적 시각에서 ‘오차’</strong>를 바라보며 카이제곱 분포의 쓰임을 짐작해 보려고 한다. 꽤나 흥미로운 이야기가 될 것 같다.</p>

<p>자, 우리는 가우스처럼 어떤 실험적 측정이나 관측에서 참값과의 차이, 측 ‘오차’를 탐구해 보려고 한다. 오차가 발생하는 수많은 미세한 요인들이 있을 것이고, 각각의 오차들이 이런 독립적 요인들의 합으로 발생했다고 하자. 그렇다면 중심 극한 정리에 의해 각각의 오차들은 정규 분포가 될 것이다. 정규 분포라면 물론 스케일링을 통해 표준 정규 분포로 변환할 수 있다. 각각의 오차들은 표준 정규 분포가 되었다. 그렇다면 이 각각의 오차들의 제곱의 합이라는 새로운 확률 변수는 카이제곱 분포의 형태가 될 것이다.</p>

<p>와우, 이 내용을 이해했다면 우리는 앞으로 카이제곱 분포를 활용하기 위한 준비가 되었다.</p>

<h2 id="피어슨-카이제곱-통게량">(피어슨) 카이제곱 통게량</h2>

<table>
  <thead>
    <tr>
      <th>DEFINITION</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>다음과 같은 공식을 카이제곱 통계략 혹은 피어슨 카이제곱 통계량이라고 한다. <br /> <center>$$ \chi^2 = \sum_i \frac{(O_i - E_i)^2}{E_i} $$ </center><br /> \(\chi^2\): 카이제곱 <br /> \(O\) : 관측값 <br />\(E\) : 기댓값</td>
    </tr>
  </tbody>
</table>

<p>앞선 카이제곱 분포의 정의와 모양이 조금 달라보이지만, \(O_i - E_i\) 를 하나의 확률 변수로 보면, 확률 변수들의 제곱의 합이므로 카이제곱 통계량이고 할 수 있다. 여기서 \(E\) 로 나누는 행위는 분산의 정규화를 의미한다. 각각의 \(E_i\) 의 (분산의) 차이를 조정한다고 생각할 수 있다.</p>

<h2 id="카이제곱-검정">카이제곱 검정</h2>
<p>카이제곱 검정은 이론상의 카이제곱 분포와 실제 관측에 따른 카이제곱 분포의 차이를 대조 검증하는 것이라고 할 수 있다. 대표적인 적합도 검정과 교차 분석을 해보려고 한다. 이 부분의 이해는 통계하면 들어봤을 법한 t-value, p-value로 확장되니 원리를 정확히 이해할 필요가 있다고 생각한다. 하지만 단순 계산을 넘어 검정의 원리를 설명하는 글들을 많지 않았던 것 같아 적합도 검정에서는 그 원리를 정말 자세하게 다뤄보려고 한다.</p>

<h3 id="적합도-검정">적합도 검정</h3>
<ul>
  <li>주사위의 공정성 검정
주사위 던지를 했는데, 1부텉 6까지의 모든 숫자가 나올 확률이 동일할까? 즉, 이 주사위가 공정할까?에 대한 답을 해보려고 한다. 그래서 실제로 이 주사위를 가지고 600번 던지기를 했다. 그리고 다음과 같은 관측 빈도를 확인 했다.</li>
</ul>

<table>
  <thead>
    <tr>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>          95회          </td>
      <td>          105회          </td>
      <td>          110회          </td>
      <td>          85회            </td>
      <td>          105회          </td>
      <td>          100회          </td>
    </tr>
  </tbody>
</table>

<p>그럼 공정한지를 판단하기 위해 참값과 관측값 사이의 오차를 이용해 보려고 한다. 만약 이 주사위가 공정했다면 600번의 던지기에서 각 숫자들이 나올 기대 횟수는 \(600 / 6 = 100\) 회 일 것이다. 그럼 그 오차들은 다음과 같이 계산해 볼 수 있다. (우리는 오차를 다루기 위해 제곱합을 이용하는 것이다.)</p>

\[\chi^2 = \sum \frac{(O_i - E_i)^2}{E_i} = \frac{(95 - 100)^2}{100} + \frac{(105 - 100)^2}{100} + \cdots + \frac{(100 - 100)^2}{100} = 4\]

<p>자, 관측에 따른 오차(합)는 4가 된다. 그럼 <strong>이 오차가 주사위가 공정하다는 가정하에 관측될 법한 오차일까?</strong></p>

<p>이제, 이론 상으로 오차(합)가 4가 나오는 것이 얼마나 가능한 일인지 판단할 것이다.</p>

<p>앞서 관측된 오차는 잊자. 그리고 오차에 대한 아무런 정보가 없다고 생각하고, 거꾸로 추적해 보자. 어떤 5개의 오차들의 합인 어떤 카이제곱 분포가 있다. 이 카이제곱 분포는 5개의 임의의 오차들의 합으로 가능한 모든 확률값들을 나타내고 있다.</p>

<p>그럼 이 그래프에서 내가 실제로 관찰한 5개의 오차 합이 나타날 확률은 어떻게 될까? 충분히 발생할 수 있는 오차일까?</p>

<p>그래서 이런 오차의 합이 나타나는 건 어려워 혹은 가능해라고 판단할 수 있는 <u>기준을 설정</u>할 것이다.  <strong>5%(p-value)</strong>도 드물다고 말해도 되는 굉장히 작은 확률이라고 생각한다. 그래서 관측치가 나타날 확률이 5%보다 적다면, 이건 일반적인 오차라고 보기 어렵다, 즉 내가 <u>관측한 오차에 뭔가 문제가 있다</u>고 판단할 것이다.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/chi_squared_distribution/cgoodness_of_fit_test(1).png" />
</p>

<p>그럼 우리는 카이제곱 표를 이용해 자유도가 5일때, 95% 확률을 나타내는 \(\chi=x\)을 찾을 수 있다.</p>

\[\chi^2(5)_{0.95} = 11.07\]

<p>자유도가 5인 카이제곱 분포에서 오차의 합 11.07을 기준으로 왼쪽은 95%, 오른쪽은 5%가 된다.</p>

<p>그럼 관측치의 오차의 합인 4와 이론상의 기준인 11.07을 비교해 보자.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/chi_squared_distribution/cgoodness_of_fit_test(2).png" />
</p>

<p>4는 11.07보다 작으므로, 충분히 나타날 수 있는 오차의 범위 내에 있다고 할 수 있다.</p>

<p>즉, 주사위가 공정하다고 가정했을 때, 충분히 발생할 수 있는 오차의 범위에 있다. 따라서 우리는 <u>주사위가 공정하지 않다고 말할 근거가 없다</u>.</p>

<p>가끔 로또를 보며 각각의 번호가 공정한 확률로 나오는 걸까? 궁금할 때가 있다. 자유도가 크고, 관측값 계산이 복잡하겠지만 같은 원리로 적용해 볼 수 있지 않을까?</p>

<h3 id="교차-분석">교차 분석</h3>
<p>교차 분석은 우리가 다루는 엑셀 데이터처럼 범주형 변수가 여러개일 경우 활용하는 분석 방법이다. 목적은 범주들 간의 연관성이 있는지를 파악하는 것이다.</p>

<p align="center">
  <img class="image image--xl" src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/chi_squared_distribution/crosstab(1).png" />
</p>

<p>성별과 선호 과목은 연관성이 있을까? 연관성이 없다고 가정하자.(귀무가설)</p>

<p>두 범주가 독립이라는 가정하에 각각의 기대빈도를 구할 수 있다. 예를 들어 과학을 선호하는 남성의 기대 빈도는 다음과 같이 계산된다.</p>

\[\frac{(총 과학 선호하는 사람) * (총 남성수)} {총 사람 수} = \frac{50 * 60} {100} = 30\]

<p>모든 셀의 기대빈도를 구하면 다음과 같다.</p>

<p align="center">
  <img class="image image--xl" src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/chi_squared_distribution/crosstab(2).png" />
</p>

<p>관측된 오차의 카이제곱 통계량을 구하자.</p>

\[\chi^2 = \frac{(40-30)^2}{30} + \frac{(10-20)^2}{20} +
 \frac{(20-30)^2}{30} + \frac{(30-20)^2}{20}
= 16.666\]

<p>이론적 통계량을 구해보자.</p>

<p>자유도는 \((2-1) \times (2-1) = 1\) 이고 p-value 0.05에 대한 통계량은</p>

\[\chi^2(1)_{0.95} = 3.841\]

<p>이다.</p>

<p>따라서, \(3.841 \leq 16.666\) 이므로 <u>관측 통계량은 굉장히 발생 확률이 낮다고 할 수 있으므로, 두 변수 사이의 통계적으로 유의미한 연관성이 있을 가능성이 높다고 해석</u>할 수 있다.</p>

<p><br /><br />
<strong>참조</strong><br />
<a href="https://online.stat.psu.edu/stat414/lesson/15/15.9">Introduction to Probability Theory(STAT414, PennState Eberly College of Science)</a></p>]]></content><author><name>Jenny Won (Dajeong Won)</name></author><category term="통계학" /><summary type="html"><![CDATA[카이제곱 분포의 정의 DEFINITION 카이제곱 분포(Chi-Squared Distribution)은 \(k\) 개의 서로 독립이며, 표준 정규 분포를 따르는 확률 변수 \(X_1,\cdots, X_k\) 에 대하여, 각각의 확률 변수를 제곱한 다음 합하여 얻어지는 확률변수 $$Q = \sum_{i=1}^{k} X_i^2$$의 분포이다. 즉, $$Q \sim X_k^{2}$$ 이다. 이때, $k$를 자유도라고 한다. 자유도가 $k$인 카이제곱 분포의 확률 밀도 함수(PDF)는 다음과 같다. \[f(x; k) =\dfrac{1}{\Gamma (r/2) 2^{r/2}}x^{r/2-1}e^{-x/2}\] $\Gamma(k/2)$ 는 감마 함수로, $(k/2)$ 의 인자(factorial)에 대한 일반화된 형태이다. 카이제곱 분포의 이해 자유도는 무엇이고, 카이제곱 분포는 왜 저런 모양을 띄는 걸까? 이를 이해해 보기 위해, 카이제곱 분포가 어떻게 그려지는 지 보자. 자유도 k=1 표준 정규 분포를 따르는 하나의 확률 변수 \(X\)에 대한 카이제곱 분포를 그려보자. 하나의 확률 변수이므로 카이제곱 분포의 자유도는 1이라고 할 수 있다. \(-1.5 \leq x \leq -1\) 와 \(1 \leq x \leq 1.5\) 구간 \(-1.5 \leq x \leq -1\) 와 \(1 \leq x \leq 1.5\) 의 확률 변수들을 제곱하면, 이것은 카이제곱 분포의 변량이 된다. 그리고, 제곱함으로써 그 확률값은 카이제곱 분포의 동일한 구간 \(1 \leq q \leq 2.25\) 에 누적된다. 같은 방식은 다양한 구간에서 반복해 보자. \(-2.5 \leq x \leq 2\) 와 \(2 \leq x \leq 2.5\) \(-0.5 \leq x \leq 0\) 와 \(0 \leq x \leq 0.5\) 자유도 \(k \geq 2\) 이제부터 카이제곱 분포가 제곱의 ‘합’임을 주목하자. 자유도가 1일 때는, 하나의 독립 변수를 제곱한 분포를 그렸다. 하지만, 독립 변수가 2개 이상일 때는 본격적으로 제곱의 ‘합’의 분포를 그리게 된다. 각각의 독립적인 확률변수 \(X_1, X_2\) 에 대해 \(Q = X_1^2 + X_2^2\) 은 다음과 같이 같은 구간에서 더 큰 값을 누적하게 된다. 자유도가 3, 4, … 로 점점 커질 때, 카이제곱 분포는 다음과 같이 변화한다. 더 많은 확률 변수를 합한다는 것은 분산이 커지고, 가장 큰 확률 값을 갖는 구간 역시 커진다는 것을 의미하며, 그래프가 오른쪽으로 이동한다. 카이제곱 분포의 활용 그럼 굳이 확률 변수들의 제곱의 합을 분포로 나타낼 필요성은 무엇일까? 제곱의 합은 사실 수학에서 오차나 편차 등 ‘차이’를 다루기 위해 많이 사용된다. - 물론, 방향성을 없애기 위해 절댓값을 활용할 수도 있지만 제곱이 미분에 유리하다. MSE 와 MAE 에 대한 이야기는 넘어가자.- 사실 지금까지의 카이제곱의 이해는 독립 변수들의 제곱의 합으로 발생하는 새로운 변수의 분포 형태를 이야기한 것이다. 이것이 이후의 p-value 등의 개념과 결합하여 확장되니, 우선은 서로 독립인 변수들의 제곱의 합이 이러한 분포 형태를 띈다라는 것을 이해하고 넘어가는 것으로 충분하다. 그렇지만 조금 아쉬우니 잠깐 엿보기를 위해, 수학적 시각에서 ‘오차’를 바라보며 카이제곱 분포의 쓰임을 짐작해 보려고 한다. 꽤나 흥미로운 이야기가 될 것 같다. 자, 우리는 가우스처럼 어떤 실험적 측정이나 관측에서 참값과의 차이, 측 ‘오차’를 탐구해 보려고 한다. 오차가 발생하는 수많은 미세한 요인들이 있을 것이고, 각각의 오차들이 이런 독립적 요인들의 합으로 발생했다고 하자. 그렇다면 중심 극한 정리에 의해 각각의 오차들은 정규 분포가 될 것이다. 정규 분포라면 물론 스케일링을 통해 표준 정규 분포로 변환할 수 있다. 각각의 오차들은 표준 정규 분포가 되었다. 그렇다면 이 각각의 오차들의 제곱의 합이라는 새로운 확률 변수는 카이제곱 분포의 형태가 될 것이다. 와우, 이 내용을 이해했다면 우리는 앞으로 카이제곱 분포를 활용하기 위한 준비가 되었다. (피어슨) 카이제곱 통게량 DEFINITION 다음과 같은 공식을 카이제곱 통계략 혹은 피어슨 카이제곱 통계량이라고 한다. $$ \chi^2 = \sum_i \frac{(O_i - E_i)^2}{E_i} $$ \(\chi^2\): 카이제곱 \(O\) : 관측값 \(E\) : 기댓값 앞선 카이제곱 분포의 정의와 모양이 조금 달라보이지만, \(O_i - E_i\) 를 하나의 확률 변수로 보면, 확률 변수들의 제곱의 합이므로 카이제곱 통계량이고 할 수 있다. 여기서 \(E\) 로 나누는 행위는 분산의 정규화를 의미한다. 각각의 \(E_i\) 의 (분산의) 차이를 조정한다고 생각할 수 있다. 카이제곱 검정 카이제곱 검정은 이론상의 카이제곱 분포와 실제 관측에 따른 카이제곱 분포의 차이를 대조 검증하는 것이라고 할 수 있다. 대표적인 적합도 검정과 교차 분석을 해보려고 한다. 이 부분의 이해는 통계하면 들어봤을 법한 t-value, p-value로 확장되니 원리를 정확히 이해할 필요가 있다고 생각한다. 하지만 단순 계산을 넘어 검정의 원리를 설명하는 글들을 많지 않았던 것 같아 적합도 검정에서는 그 원리를 정말 자세하게 다뤄보려고 한다. 적합도 검정 주사위의 공정성 검정 주사위 던지를 했는데, 1부텉 6까지의 모든 숫자가 나올 확률이 동일할까? 즉, 이 주사위가 공정할까?에 대한 답을 해보려고 한다. 그래서 실제로 이 주사위를 가지고 600번 던지기를 했다. 그리고 다음과 같은 관측 빈도를 확인 했다. 1 2 3 4 5 6           95회                     105회                     110회                     85회                       105회                     100회           그럼 공정한지를 판단하기 위해 참값과 관측값 사이의 오차를 이용해 보려고 한다. 만약 이 주사위가 공정했다면 600번의 던지기에서 각 숫자들이 나올 기대 횟수는 \(600 / 6 = 100\) 회 일 것이다. 그럼 그 오차들은 다음과 같이 계산해 볼 수 있다. (우리는 오차를 다루기 위해 제곱합을 이용하는 것이다.) \[\chi^2 = \sum \frac{(O_i - E_i)^2}{E_i} = \frac{(95 - 100)^2}{100} + \frac{(105 - 100)^2}{100} + \cdots + \frac{(100 - 100)^2}{100} = 4\] 자, 관측에 따른 오차(합)는 4가 된다. 그럼 이 오차가 주사위가 공정하다는 가정하에 관측될 법한 오차일까? 이제, 이론 상으로 오차(합)가 4가 나오는 것이 얼마나 가능한 일인지 판단할 것이다. 앞서 관측된 오차는 잊자. 그리고 오차에 대한 아무런 정보가 없다고 생각하고, 거꾸로 추적해 보자. 어떤 5개의 오차들의 합인 어떤 카이제곱 분포가 있다. 이 카이제곱 분포는 5개의 임의의 오차들의 합으로 가능한 모든 확률값들을 나타내고 있다. 그럼 이 그래프에서 내가 실제로 관찰한 5개의 오차 합이 나타날 확률은 어떻게 될까? 충분히 발생할 수 있는 오차일까? 그래서 이런 오차의 합이 나타나는 건 어려워 혹은 가능해라고 판단할 수 있는 기준을 설정할 것이다. 5%(p-value)도 드물다고 말해도 되는 굉장히 작은 확률이라고 생각한다. 그래서 관측치가 나타날 확률이 5%보다 적다면, 이건 일반적인 오차라고 보기 어렵다, 즉 내가 관측한 오차에 뭔가 문제가 있다고 판단할 것이다. 그럼 우리는 카이제곱 표를 이용해 자유도가 5일때, 95% 확률을 나타내는 \(\chi=x\)을 찾을 수 있다. \[\chi^2(5)_{0.95} = 11.07\] 자유도가 5인 카이제곱 분포에서 오차의 합 11.07을 기준으로 왼쪽은 95%, 오른쪽은 5%가 된다. 그럼 관측치의 오차의 합인 4와 이론상의 기준인 11.07을 비교해 보자. 4는 11.07보다 작으므로, 충분히 나타날 수 있는 오차의 범위 내에 있다고 할 수 있다. 즉, 주사위가 공정하다고 가정했을 때, 충분히 발생할 수 있는 오차의 범위에 있다. 따라서 우리는 주사위가 공정하지 않다고 말할 근거가 없다. 가끔 로또를 보며 각각의 번호가 공정한 확률로 나오는 걸까? 궁금할 때가 있다. 자유도가 크고, 관측값 계산이 복잡하겠지만 같은 원리로 적용해 볼 수 있지 않을까? 교차 분석 교차 분석은 우리가 다루는 엑셀 데이터처럼 범주형 변수가 여러개일 경우 활용하는 분석 방법이다. 목적은 범주들 간의 연관성이 있는지를 파악하는 것이다. 성별과 선호 과목은 연관성이 있을까? 연관성이 없다고 가정하자.(귀무가설) 두 범주가 독립이라는 가정하에 각각의 기대빈도를 구할 수 있다. 예를 들어 과학을 선호하는 남성의 기대 빈도는 다음과 같이 계산된다. \[\frac{(총 과학 선호하는 사람) * (총 남성수)} {총 사람 수} = \frac{50 * 60} {100} = 30\] 모든 셀의 기대빈도를 구하면 다음과 같다. 관측된 오차의 카이제곱 통계량을 구하자. \[\chi^2 = \frac{(40-30)^2}{30} + \frac{(10-20)^2}{20} + \frac{(20-30)^2}{30} + \frac{(30-20)^2}{20} = 16.666\] 이론적 통계량을 구해보자. 자유도는 \((2-1) \times (2-1) = 1\) 이고 p-value 0.05에 대한 통계량은 \[\chi^2(1)_{0.95} = 3.841\] 이다. 따라서, \(3.841 \leq 16.666\) 이므로 관측 통계량은 굉장히 발생 확률이 낮다고 할 수 있으므로, 두 변수 사이의 통계적으로 유의미한 연관성이 있을 가능성이 높다고 해석할 수 있다. 참조 Introduction to Probability Theory(STAT414, PennState Eberly College of Science)]]></summary></entry><entry xml:lang="ko"><title type="html">정규 분포와 중심 극한 정리</title><link href="http://localhost:4000/2024/04/06/normal_distribution_and_clt_ko.html" rel="alternate" type="text/html" title="정규 분포와 중심 극한 정리" /><published>2024-04-06T00:00:00+09:00</published><updated>2024-04-06T00:00:00+09:00</updated><id>http://localhost:4000/2024/04/06/normal_distribution_and_clt_ko</id><content type="html" xml:base="http://localhost:4000/2024/04/06/normal_distribution_and_clt_ko.html"><![CDATA[<p align="center">
  <img class="image image--xl" src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/normal_distribution/normal_distribution_cover.jpeg" />
</p>

<p>많은 통계적 검정과 모델링 방법론은 정규 분포를 가정으로 한다. 카이제곱분포, t-분포, F-분포 등 통계학에서 다뤄지는 중요한 분포들 역시 정규분포과 깊은 연관이 있으며, 이로 부터 파생되거나 그 성질을 활용하니, 정규 분포가 없는 통계학은 상상하기 어려울 지경이다.</p>

<h2 id="정규-분포의-발견">정규 분포의 발견</h2>
<p>정규 분포는 가우스 분포 혹은 라플라스 분포라고도 불린다. 혹은 종모양이라고 해서 Bell Curve라고도 하는데, 여기서는 정규 분포(Normal Distribution)이라고 하겠다. 사실 이름이 어떻든 중요한 것은 당시대의 수학자들이 각자의 연구 과정에서 정규 분포를 관찰했다는 것이고, 이것이 이러한 분포를 정의할 필요성을 주었다는 사실이다. 간단하게 몇몇 수학자의 정규 분포의 발견을 보자.</p>

<p>정규 분포는 <u>'이항 분포의 근사'</u>로서 <strong>Abraham de Moivre</strong>에 의해 처음 발표되었다고 한다.</p>

<p align="center" class="circle shadow">
  <img class="image image--md" src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/normal_distribution/Abraham_de_moivre.jpg" />
  <br />
  Abraham de Moivre
  <br />
  출처: <a href="https://en.wikipedia.org/wiki/Abraham_de_Moivre">SWikipedia(Abraham de Moivre)</a>
</p>

<p>Abraham de Moivres(드무아브르)는 이항 분포의 n이 아주 큰 경우 어떤 식에 가까워질 지를 연구하던 중, 다음과 같은 근사식을 찾았는데, 실제로 n이 100을 넘을 정도로 크지 않은 값이여도 비교적 잘 성립한다는 것을 발견했다.</p>

\[_{n}C_{k} p^k q^{n-k} \approx {\frac{1}{\sqrt{2 \pi npq}} e}^{-\frac{(k-np)^2}{2npq}}\]

<p>이후 <strong>Johann Carl Friedrich Gauss</strong>(가우스)는 참값과 관측값 사이의 오차를 탐구하던 중 <u>오차들의 분포가 정규 분포를 이룬다</u>는 것을 발견했다.</p>

<p align="center" class="circle shadow">
  <img class="image image--md" src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/normal_distribution/Carl_Friedrich_Gauss.jpeg" />
  <br />
  Johann Carl Fredrich Gauss
  <br />
  출처: <a href="https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss">Wikipedia(Johann Carl Friedrich Gaus)</a>
</p>

<p>그는 관측치로 부터 참값을 추적하는 연구 중, 참값과 관측값의 차이인 오차들이 대칭성을 가진 특정한 분포를 나타낸다는 것을 알았다. 연구 진행을 위해 이 오차들의 분포를 정의할 필요가 있다고 판단하여 이 분포를 정의하게 되었다.</p>

<h2 id="정규-분포의-정의">정규 분포의 정의</h2>
<p>정규 분포는 <strong>평균 $\mu$ 와 표준편차 $\sigma$ 두 가지 파라미터</strong>로 완전히 정의된다.</p>

<table>
  <thead>
    <tr>
      <th>DEFINITION</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>정규 분포</strong>는 다음과 같이 표현할 수 있고, <br /> <center> $$ X\sim N(\mu ,{ \sigma  }^{ 2 }) $$ </center> <br /> 연속 확률 변수 \(X\) 에 대해 다음과 같은 확률 밀도 함수는(PDF)를 따른다. <br /> <center> $$ \begin{equation} \begin{aligned} f(x; \mu, \sigma) = \frac{1}{\sqrt{2\pi \cdot \sigma^{2}}} e^{-\frac{1}{2} \left(\frac{x-\mu}{\sigma}\right)^{2}} \end{aligned} \end{equation} $$</center></td>
    </tr>
  </tbody>
</table>

<h2 id="정규-분포의-시뮬레이션">정규 분포의 시뮬레이션</h2>
<p>정규 분포는 평균을 기준으로 좌우 대칭적 분포를 띈다. <a href="https://www.geogebra.org/m/EmRVMnXa">Geogebra 시뮬레이션(Normal Distribution by Joseph Manthey)</a>을 통해 평균값과 분산이 변화함에 따라 정규 분포가 어떻게 달라지는지 확인해 보자.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/normal_distribution/normal_distribution_simulation_mean.png" />
</p>

<p>평균값은 종모양의 중심의 위치이다. 따라서 평균값이 변화함에 따라 정규 분포는 좌우로 이동한다.</p>

<p>분산의 변화도 살펴보자.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/normal_distribution/normal_distribution_simulation_var.png" />
</p>

<p>분산은 분포가 평균을 기준으로 퍼진 정도를 나타낸다. 분산이 클 수록 넓게 퍼지고, 분산이 작을 수록 뾰족한 형태를 띈다.</p>

<h2 id="중심-극한-정리central-limit-theorem-clt">중심 극한 정리(Central Limit Theorem, CLT)</h2>
<p>이번 학습 노트를 작성하며, 계속해서 ‘그래, 종모양이 꽤나 아릅답구나. 근데 그래서 정규 분포는 왜 중요한데?’라는 질문을 계속 던지게 되었다. 그리고 결국 중심 극한 정리를 파헤치고 있는 스스로를 발견하였다.</p>

<p>사실 이번 포스트는 정규 분포를 빙자한 중심 극한 정리라고 해도 무방하다.</p>

<p>그만큼 중심 극한 정리는 정규 분포와 떼놓고 말하기 어렵기도 하고, 단순히 ‘봐봐, 정규 분포가 되지’라고 설명하고 넘어가기에는 중심 극한 정리가 정규 분포를 얼마나 중요하게 만들고 있는지 설명하는데 부족함이 크다고 생각한다.</p>

<p>또, 이 정리를 마치 ‘어떤 분포든 그 시행을 무수히 하면 정규 분포가 되는 이론’이라고 오해하는 경우도 간혹 있어, 여기서 자세히 공부해 보려고 한다. (쉽게 설명하려는 의도로 같은 의미인’샘플’과 ‘표본’, ‘동일한 분포’와 ‘고정된 분포’라는 표현을 혼용해서 사용하니 참고 바란다.)</p>

<p class="info"><strong>정의</strong>   중심 극한 정리(CLT:Central Limit Theorem)는 다음과 같이 정의된다. 고정된 분포를 가진 집단에서, 독립적인 무작위 샘플링을 시행했을 때, 샘플의 크기(샘플링의 규모)가 클수록 그 <u>샘플의 평균들의 분포(혹은 그 합)는 정규분포를 따른다</u>.</p>

<p>자, 하나 하나 그 의미를 따져보자.</p>

<ul>
  <li>고정된 분포를 가진 집단 : 그 분포의 형태는 상관없지만 전혀 다른 분포를 가진 집단에서 샘플링이 되어서는 안된다. 다시 말해, <strong>모집단이 어떠한 특정 분포를 따르더라도 그 모집단에 대해 중심 극한 정리는 유효</strong>하다.</li>
  <li>독립적인 무작위 샘플링 : 말 그대로 하나 하나의 샘플링이 서로 독립적이며 무작위로 발생해야 한다.</li>
  <li>샘플링의 크기가 크다면 : 흔히 이를 샘플링의 횟수를 많이 하면이라고 오해하기 쉽다. 하지만 정확히는 <strong>‘한 회에 발생하는 샘플링의 규모가 클수록’</strong>을 의미한다.</li>
  <li>평균들의 분포가 정규분포를 따른다 : ‘샘플링의 횟수가 많다면 분포가 정규 분포가 된다’라고 오해할 때 간과하기 쉬운 포인트가 <strong>‘평균들의 분포가’</strong> 정규 분포를 따른다는 것이다. 이는 각각의 샘플링에서 얻은 평균들의 분포가 정규 분포를 따른다는 것을 의미한다.</li>
</ul>

<p>종합하여, <strong><u>어떤 특정 분포를 따르는 모집단이더라도, 그 모집단에서 독립적이고 무작위적인 방식으로 샘플을 추출한다면, 더 큰 규모의 샘플에서 추출하는 방식일수록, 각각의 샘플들로 부터 얻은 평균들의 분포가 정규 분포를 따르게 된다</u></strong>는 것이다.</p>

<h3 id="중심-극한-정리의-직관적-이해">중심 극한 정리의 직관적 이해</h3>
<p>어떤 모집단으로부터 얻은 여러 샘플들에서 평균들을 모았다고 생각해 보자. 한번에 뽑는 샘플에 요소가 많아질 수록 샘플에서 얻은 평균들은 모집단의 특성을 더 잘 반영하게 될 것이다. 이것을 직관적으로 이해하는 것은 어려운 일이 아니다.</p>

<p>쉬운 예로 여론 조사를 떠올려보자. 우리는 무작위로 뽑은 100명의 집단 보다 1,000명의 집단에서 실시한 여론조사가 국민의 의견을 더 잘 반영한다고 한다. 혹은 믿을만 하다고도 한다. (신뢰성에 대한 이야기 역시 할 이야기가 많지만 우선은 넘어가도록 한다.) 왜 그렇게 생각할까? 더 큰 규모에서 샘플링이 시도된다면 모집단의 특성을 더 잘 나타낼 것이라는 것을 우린 직감적으로 이해할 수 있다. 특히, <u>모집단의 '평균'이라는 특성은 샘플의 규모가 크면 클수록 샘플의 평균에서 더 잘 나타나고, 샘플의 평균들은 모집단의 평균으로 수렴</u>하려고 할 것이다.</p>

<p>관점을 살짝 틀어보기 위해, <strong>극단적인 상황</strong>을 가정해 보자. 모집단 만큼이나 큰 샘플에서 평균을 얻는다고 생각해 보자. 아마 여러차례 샘플링을 시도하여 평균을 구한다면, 그 값은 웬만하면 모집단의 평균처럼 나올 것이다. 물론 정확히 모집단의 평균이 아닌 값들도 관찰될 되겠지만, <u>작은 오차는 빈번하게 발생할 수 있어도 큰 오차는 드물게 발생</u>할 것이다. 이것은 다음과 같이 해석될 수 있다. <strong>더 큰 샘플링을 시도할 수록 샘플들의 평균은 모집단의 평균을 더 정확히 추정</strong>하며, 추적의 과정에서 발생하는 오차들이 큰 오차보다는 작은 오차들이 나타나는 형태로 나름 대칭성을 갖고 분포한다는 것이다.</p>

<p>이렇게 생각해보니 중심 극한 정리가 “당연한 거 아니야?”라고 말할 수 있을 만큼 이해할 법 하다.</p>

<p><strong>‘오차’</strong>라는 이야기를 했는데, 이전에 가우스도 참값과 관측값 사이의 오차를 탐구하다 이 오차들이 정규 분포의 형태를 띈다는 것을 확인하고 이 분포를 정의하게 된 것이라고 했다.여기서 정규 분포가 앞으로 어떻게 활용될 수 있는지 짐작해 볼 수도 있을 것 같다.</p>

<h3 id="수학적-정의">수학적 정의</h3>
<p>앞서 직관적으로 이해한 중심 극한 정리를 수학적 관점에서 다시 정의하자면 다음과 같다.</p>

<table>
  <thead>
    <tr>
      <th>DEFINITION</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>중심 극한 정리(CLT:Central Limit Theorem)</strong>은 무작위로 추출된 표본의 크기가 커질수록 표본 평균의 분포는 모집단의 분포 모양과는 관계없이 정규분포 가까워진다는 정리이다. 임의의 분포를 갖는 확률변수 \(x_1, x_2, \cdots, x_n\) 들이 서로 독립이면서 동일한 분포를 갖고 있다고 하자(=i.i.d)*. 이 확률 분포의 기댓값 \(\mu\) 와 분산 \(\sigma\) 이 유효하다면, 평균 \(S_n = \frac{X_1 + X_2 + \cdots + X_n}{n}\) 의 분포는 기댓값 $\mu$, 표준편차 \(\frac{\sigma}{\sqrt{n}}\) 인 정규 분포 \(N(\mu, \frac{\sigma^2}{n})\) 에 분포 수렴한다. <br /> <center> $$\sqrt{n}((\frac{1}{n} \sum_{i=1}^{n}X_i) - \mu) \rightarrow N(0, \sigma^2)$$ <center></center> <br /> * i.i.d : Independent and Identically Distributed random variables</center></td>
    </tr>
  </tbody>
</table>

<p>여기서, 만약 표본 평균 \(\overline{X}\)를 \(Z= \frac{\overline{X}-\mu}{\sigma/\sqrt{n}}\) 으로 표준화한다면 이 통계량 \(Z\)는 중심 극한 정리에 따라 표준 정규 분포로 근사한다.</p>

<h3 id="중심-극한-정리의-증명">중심 극한 정리의 증명</h3>

<p>중심 극한 정리의 증명 방법에는 여러가지 버전이 존재한다. 초기 형태였던 라플라스에 의한 방법은 이항 분포의 정규 분포 근사에 초점이 맞춰져 있고, 현재가 가장 활발히 활용되는 방식은 모멘트 생성 함수의 성질을 이용한 린데베르그-레비의 중심 극한 정리이다. 하지만, 이번 섹션에서는 특성 함수와 합성곱을 활용하여 전통적인 방법 보다 직관적인 접근법을 택하고자 한다. 앞서 중심 극한 정리는 표본 <u>평균들의 분포</u>가 정규 분포에 수렴한다 ‘혹은’ <u>그 샘플들의 합</u>이 정규 분포에 수렴하다고 했다. 여기서 증명하고자 하는 명제는 <strong>변수들의 ‘합’의 수렴</strong>이니 혹여 증명 과정에서 길을 잃지 않도록 주의하기 바란다.</p>

<p class="warning"><strong>명제</strong>   독립적이고 동일하게 분포된(i.i.d.) 무작위 변수들의 ‘합’이, 적절하게 정규화될 때, 정규 분포에 수렴한다.</p>

<p>증명 과정이 꽤나 복잡할 수 있어, 중요한 발상을 잘 쫒기 위해 소제목을 붙이니 참고가 되길 바란다.</p>

<ul>
  <li><strong>확률 변수의 합성곱 정의</strong><br />
우선, 합성곱이라는 개념을 어떻게 확률변수에 어떻게 적용되는 지 살펴보자.</li>
</ul>

<p>두 개의 확률 변수 $X$, $Y$이 서로 독립이라고 하자. 그러면 새로운 확률 변수 $Z = X + Y$에 대한 확률은 다음과 같이 정의할 수 있다.</p>

\[P(Z) = \sum_{k=-\infty}^{\infty}{P(X)P(Y)}\]

<p>이 부분이 잘 이해가 되지 않는다면, $X$를 동전 던지기의 앞면이 나올 사건, $Y$를 주사위 던지기의 짝수가 나올 사건, $Z$를 동전과 주사위를 던졌을 때 앞면과 짝수가 나올 사건이라고 했을떄, Z의 확률을 구하기 위해, $X$, $Y$의 확률의 곱을 계산하고 있는 자신의 모습을 떠올려보자. 또, 이러한 내용을 전문적으로 아주 잘 설명하고 있는 <a href="https://colah.github.io/posts/2014-07-Understanding-Convolutions/">이 블로그</a>를 방문해 보길 추천한다.</p>

<p>$X$, $Y$의 확률 밀도 함수를 각각 $f(x)$, $g(x)$라고 하면, $Z = X + Y$의 확률 밀도 함수 $(f*g)(z)$ 는 다음과 같은 함수의 합성곱으로 표현될 수 있다.</p>

\[(f*g)(z) = \int_{-\infty}^{\infty}f(z-y)g(y)dy = \int_{-\infty}^{\infty}g(z-x)f(x)dx\]

<p>합이 곱으로 변환된다는 점에 주목하자. 이러한 성질을 확률 변수의 특성 함수를 정의함으로써 활용하고자 한다.</p>

<ul>
  <li><strong>확률 변수의 특성 함수 정의</strong></li>
</ul>

<p>임의의 확률 밀도 함수 $f_X(x)$에 대한 특성 함수는 다음과 같이 정의한다. (t는 실수)</p>

\[\phi_X(t) = E[e^{itX}] = \int_{-\infty}^{\infty}e^{jtx}f_X(x)dx\]

<p>이러한 특성 함수의 정의에서 다음과 같은 성질로 복소수 지수 함수 $e^{itX}$의 절대값은 항상 1이다.</p>

\[|e^{itx}| = |\cos(tx) + i\sin(tx)| =  \sqrt{\cos^2(tx) + \sin^2(tx)} = 1\]

<p>이러한 특성 함수 정의는 라플라스 변환, 확률 생선 함수, 혹은 모멘트 생성 함수와 같은 다른 변환들과 비교했을 때, 모든 확률 분포에 대해 적분이 존재한다는 매우 큰 장점을 갖는다.</p>

<ul>
  <li><strong>맥클로린 급수 전개</strong></li>
</ul>

<p>앞선 특성 함수 정의에서 $$e^{jtx}$ 는 맥클로린 급수 전개를 이용해 다음과 같이 전개할 수 있다.</p>

\[e^{jtx}=\sum_{k=1}^{\infty}\frac{(jtx)^k}{k!}=1+jtx+\frac{(jtx)^2}{2!}+\frac{(jtx)^3}{3!}+\cdots = 1+jtx+\frac{(jtx)^2}{2!}+O(t^2)\]

<p>$O(t^2)$ 은 네 번째 항부터 마지막까지의 항을 뭉뚱그려 쓴 것이다. 이것을 특성 함수 전개에 적용하면,</p>

\[\phi_X(t) = \int_{-\infty}^{\infty}e^{jtx}f_Y(t)dy=\int_{-\infty}^{\infty}\left\{1+jtx-\frac{t^2}{2}x^2+O(t^2)\right\}f_X(x)dy\notag\]

\[=\int_{-\infty}^{\infty}f_X(x)dy + \int_{-\infty}^{\infty}xf_X(x)dy - \frac{t^2}{2}\int_{-\infty}^{\infty}x^2f_X(x)dy+O(t^2)\notag\]

\[=1+jtE\left[x\right]-\frac{t^2}{2}E\left[x^2\right]+O(t^2)\]

<p>이 된다.</p>

<ul>
  <li><strong>정규화된 확률 변수 $Z_i$의 특성 함수</strong></li>
</ul>

<p>자, 확률 변수 $X$를 평균이 0($E(x)=0$)이고, 분산이 1(Var[x]=1)로 정규화한 새로운 확률 변수 $Z_i = \frac{X_i - \mu}{\sigma}$에 대한 특성 함수를 보려고 한다. 앞서 특성 함수의 전개를 봤듯이, $Z_i$에 대한 특성 함수는 다음과 같이 정리된다.</p>

\[\phi_Z(t) = E\left[e^{jtz}\right]=\int_{-\infty}^{\infty}e^{jtz}f_Z(z)dx\]

\[=1+jtE\left[z\right]-\frac{t^2}{2}E\left[z^2\right]+O(t^2)\]

\[= 1+0-\frac{t^2}{2}+O(t^2)\]

\[= 1-\frac{t^2}{2}+O(t^2)\]

<ul>
  <li><strong>$n$개의 $Z_i$의 합에 대한 특성 함수</strong></li>
</ul>

<p>$n$개의 독립적인 확률변수 $Z_i$의 합 $S_n = \sum_{i=1}^{n} Z_i = Z_1 + Z_2 + \cdots + Z_n$에 대한 특성 함수는, 합성곱의 성질을 이용하여 다음과 같이 나타낼 수 있다.</p>

\[\phi_{S_n}(t) = \left( \phi_{Z}(t) \right)^n\]

<p>앞선 정규화된 $Z$의 특성 함수 전개를 적용하면,</p>

\[\phi_{S_n}(t) = \left( \phi_{Z}(t) \right)^n = [1-\frac{t^2}{2N}+O\left(\frac{t^2}{N}\right)]^N\]

<p>이 된다. 여기서, $n$을 무한대로 보내면 $O(\frac{t^2}{N})$이 $\frac{t^2}{2N}$ 보다 빠르게 0에 수렴하므로, 그 극한값은 다음과 같이 수렴한다는 것을 알 수 있다.</p>

\[\lim_{N\rightarrow \infty}\phi_{S_N}(t) = \lim_{N\rightarrow\infty}\left[1-\frac{t^2}{2N}\right]^N=e^{-t^2/2}\]

<h3 id="샘플의-규모와-샘플의-수">샘플의 규모와 샘플의 수</h3>
<p>일반적으로 통계학자들은 표본의 크기가 30 이상일 때 안전하게 정규 분포를 따른다고 하지만, 이것은 경험적 규칙이다. 실제로는 모집단의 비대칭이 심한 경우 더 많은 표본이 필요할 수도 있다.
<strong>샘플의 규모</strong>는 <u>개별 샘플의 정확도와 대표성을 보장</u>하고, 충분한 <strong>샘플 수</strong>는 <u>연구 전반의 신뢰도와 결과의 일반화 가능성</u>과 관련이 있다. 다음은 1부터 10까지의 정수에서 샘플들의 편균의 분포를 나타낸다.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/normal_distribution/normal_distribution_small_n_of_samples.png" />
  <br />
  샘플의 규모와 샘플 수 시뮬레이션
  <br />
  출처: <a href="https://demonstrations.wolfram.com/TheCentralLimitTheorem/#related-demonstrationss">Wolfram, The Central Limit Theorem(Chris Boucher)</a>
</p>

<p>샘플 수가 지나체게 적다면, 아무리 샘플의 규모가 커도 모집단이 아니라 샘플의 분포를 누적할 뿐이다. 이 결과로 일반화가 가능한가에 대해서 심각하게 생각해 보아야 한다. 따라서 단순히 “표본의 크기가 크다면 정규 분포로 수렴!”이라고 생각하는 것은 주의할 필요가 있다.</p>

<p>당연히 샘플의 규모도 크고, 샘플의 수도 많은 것이 최고의 시나리오일 것이다.</p>

<h2 id="그래서-정규-분포가-중요한-이유">그래서, 정규 분포가 중요한 이유?</h2>

<p align="center">
  <img class="image image--xl" src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/normal_distribution/central limit theorem.webp" />
</p>

<p>샘플링 기법에 기반한 추론적 통계에서, 표본 평균들의 분포를 이해하는 것은 모평균을 추적함에 있어 중요하다. 그런데 중심 극한 정리에 따르면 충분히 큰 샘플에서 샘플링이 이루어 진다면, 모평균에 대해 전혀 알지 못해도, 이 표본 평균들의 분포가 정규 분포로 수렴한다. 일반적으로 많은 상황에서 우리는 제한된 관측치를 가지고 모집단을 추정해 본다. 이때, 관측치들을 일정하게 샘플링해 얻은 평균값들의 분포를 통해 모집단의 분포를 추정하려는 시도는, 우리가 정규 분포를 필연적으로, 꽤나 자주 마주하게 만들 것이다.</p>

<p><br /><br />
<strong>참조</strong><br />
<a href="https://integratedmlai.com/normal-distribution-an-introductory-guide-to-pdf-and-cdf/">Normal Distribution: An Introductory Guide to PDF and CDF(Teena Mary)</a><br />
<a href="https://recipesds.tistory.com/entry/%EA%B0%80%EC%9A%B0%EC%8B%9C%EC%95%88Gaussian-%EC%A0%95%EA%B7%9C%EB%B6%84%ED%8F%ACNormal-Distribution-%EB%84%88%EB%9E%80-%EB%B6%84%ED%8F%AC-%EC%A0%95%EB%A7%90">가우시안(Gaussian)-정규분포(Normal Distribution).너란 분포 정말(친절한 데이터 사이언스 강좌)</a><br />
<a href="https://medium.com/@amanatulla1606/python-implementation-of-central-limit-theorem-exploring-sample-data-to-infer-population-595e39e0c98e">“Python Implementation of Central Limit Theorem: Exploring Sample Data to Infer Population Parameters”(Amanatullah)</a><br />
<a href="https://colah.github.io/posts/2014-07-Understanding-Convolutions/">Understanding Convolutions(colah’s blog)</a><br />
<a href="https://sas.uwaterloo.ca/~dlmcleis/s901/chapt6.pdf">Characteristic Functions and the Central Limit Theorem(University of Waterloo)</a><br />
<a href="https://portal.eller.arizona.edu/sampling/">Sampling Distribution of the Mean Simulation</a><br /></p>]]></content><author><name>Jenny Won (Dajeong Won)</name></author><category term="통계학" /><summary type="html"><![CDATA[많은 통계적 검정과 모델링 방법론은 정규 분포를 가정으로 한다. 카이제곱분포, t-분포, F-분포 등 통계학에서 다뤄지는 중요한 분포들 역시 정규분포과 깊은 연관이 있으며, 이로 부터 파생되거나 그 성질을 활용하니, 정규 분포가 없는 통계학은 상상하기 어려울 지경이다. 정규 분포의 발견 정규 분포는 가우스 분포 혹은 라플라스 분포라고도 불린다. 혹은 종모양이라고 해서 Bell Curve라고도 하는데, 여기서는 정규 분포(Normal Distribution)이라고 하겠다. 사실 이름이 어떻든 중요한 것은 당시대의 수학자들이 각자의 연구 과정에서 정규 분포를 관찰했다는 것이고, 이것이 이러한 분포를 정의할 필요성을 주었다는 사실이다. 간단하게 몇몇 수학자의 정규 분포의 발견을 보자. 정규 분포는 '이항 분포의 근사'로서 Abraham de Moivre에 의해 처음 발표되었다고 한다. Abraham de Moivre 출처: SWikipedia(Abraham de Moivre) Abraham de Moivres(드무아브르)는 이항 분포의 n이 아주 큰 경우 어떤 식에 가까워질 지를 연구하던 중, 다음과 같은 근사식을 찾았는데, 실제로 n이 100을 넘을 정도로 크지 않은 값이여도 비교적 잘 성립한다는 것을 발견했다. \[_{n}C_{k} p^k q^{n-k} \approx {\frac{1}{\sqrt{2 \pi npq}} e}^{-\frac{(k-np)^2}{2npq}}\] 이후 Johann Carl Friedrich Gauss(가우스)는 참값과 관측값 사이의 오차를 탐구하던 중 오차들의 분포가 정규 분포를 이룬다는 것을 발견했다. Johann Carl Fredrich Gauss 출처: Wikipedia(Johann Carl Friedrich Gaus) 그는 관측치로 부터 참값을 추적하는 연구 중, 참값과 관측값의 차이인 오차들이 대칭성을 가진 특정한 분포를 나타낸다는 것을 알았다. 연구 진행을 위해 이 오차들의 분포를 정의할 필요가 있다고 판단하여 이 분포를 정의하게 되었다. 정규 분포의 정의 정규 분포는 평균 $\mu$ 와 표준편차 $\sigma$ 두 가지 파라미터로 완전히 정의된다. DEFINITION 정규 분포는 다음과 같이 표현할 수 있고, $$ X\sim N(\mu ,{ \sigma }^{ 2 }) $$ 연속 확률 변수 \(X\) 에 대해 다음과 같은 확률 밀도 함수는(PDF)를 따른다. $$ \begin{equation} \begin{aligned} f(x; \mu, \sigma) = \frac{1}{\sqrt{2\pi \cdot \sigma^{2}}} e^{-\frac{1}{2} \left(\frac{x-\mu}{\sigma}\right)^{2}} \end{aligned} \end{equation} $$ 정규 분포의 시뮬레이션 정규 분포는 평균을 기준으로 좌우 대칭적 분포를 띈다. Geogebra 시뮬레이션(Normal Distribution by Joseph Manthey)을 통해 평균값과 분산이 변화함에 따라 정규 분포가 어떻게 달라지는지 확인해 보자. 평균값은 종모양의 중심의 위치이다. 따라서 평균값이 변화함에 따라 정규 분포는 좌우로 이동한다. 분산의 변화도 살펴보자. 분산은 분포가 평균을 기준으로 퍼진 정도를 나타낸다. 분산이 클 수록 넓게 퍼지고, 분산이 작을 수록 뾰족한 형태를 띈다. 중심 극한 정리(Central Limit Theorem, CLT) 이번 학습 노트를 작성하며, 계속해서 ‘그래, 종모양이 꽤나 아릅답구나. 근데 그래서 정규 분포는 왜 중요한데?’라는 질문을 계속 던지게 되었다. 그리고 결국 중심 극한 정리를 파헤치고 있는 스스로를 발견하였다. 사실 이번 포스트는 정규 분포를 빙자한 중심 극한 정리라고 해도 무방하다. 그만큼 중심 극한 정리는 정규 분포와 떼놓고 말하기 어렵기도 하고, 단순히 ‘봐봐, 정규 분포가 되지’라고 설명하고 넘어가기에는 중심 극한 정리가 정규 분포를 얼마나 중요하게 만들고 있는지 설명하는데 부족함이 크다고 생각한다. 또, 이 정리를 마치 ‘어떤 분포든 그 시행을 무수히 하면 정규 분포가 되는 이론’이라고 오해하는 경우도 간혹 있어, 여기서 자세히 공부해 보려고 한다. (쉽게 설명하려는 의도로 같은 의미인’샘플’과 ‘표본’, ‘동일한 분포’와 ‘고정된 분포’라는 표현을 혼용해서 사용하니 참고 바란다.) 정의   중심 극한 정리(CLT:Central Limit Theorem)는 다음과 같이 정의된다. 고정된 분포를 가진 집단에서, 독립적인 무작위 샘플링을 시행했을 때, 샘플의 크기(샘플링의 규모)가 클수록 그 샘플의 평균들의 분포(혹은 그 합)는 정규분포를 따른다. 자, 하나 하나 그 의미를 따져보자. 고정된 분포를 가진 집단 : 그 분포의 형태는 상관없지만 전혀 다른 분포를 가진 집단에서 샘플링이 되어서는 안된다. 다시 말해, 모집단이 어떠한 특정 분포를 따르더라도 그 모집단에 대해 중심 극한 정리는 유효하다. 독립적인 무작위 샘플링 : 말 그대로 하나 하나의 샘플링이 서로 독립적이며 무작위로 발생해야 한다. 샘플링의 크기가 크다면 : 흔히 이를 샘플링의 횟수를 많이 하면이라고 오해하기 쉽다. 하지만 정확히는 ‘한 회에 발생하는 샘플링의 규모가 클수록’을 의미한다. 평균들의 분포가 정규분포를 따른다 : ‘샘플링의 횟수가 많다면 분포가 정규 분포가 된다’라고 오해할 때 간과하기 쉬운 포인트가 ‘평균들의 분포가’ 정규 분포를 따른다는 것이다. 이는 각각의 샘플링에서 얻은 평균들의 분포가 정규 분포를 따른다는 것을 의미한다. 종합하여, 어떤 특정 분포를 따르는 모집단이더라도, 그 모집단에서 독립적이고 무작위적인 방식으로 샘플을 추출한다면, 더 큰 규모의 샘플에서 추출하는 방식일수록, 각각의 샘플들로 부터 얻은 평균들의 분포가 정규 분포를 따르게 된다는 것이다. 중심 극한 정리의 직관적 이해 어떤 모집단으로부터 얻은 여러 샘플들에서 평균들을 모았다고 생각해 보자. 한번에 뽑는 샘플에 요소가 많아질 수록 샘플에서 얻은 평균들은 모집단의 특성을 더 잘 반영하게 될 것이다. 이것을 직관적으로 이해하는 것은 어려운 일이 아니다. 쉬운 예로 여론 조사를 떠올려보자. 우리는 무작위로 뽑은 100명의 집단 보다 1,000명의 집단에서 실시한 여론조사가 국민의 의견을 더 잘 반영한다고 한다. 혹은 믿을만 하다고도 한다. (신뢰성에 대한 이야기 역시 할 이야기가 많지만 우선은 넘어가도록 한다.) 왜 그렇게 생각할까? 더 큰 규모에서 샘플링이 시도된다면 모집단의 특성을 더 잘 나타낼 것이라는 것을 우린 직감적으로 이해할 수 있다. 특히, 모집단의 '평균'이라는 특성은 샘플의 규모가 크면 클수록 샘플의 평균에서 더 잘 나타나고, 샘플의 평균들은 모집단의 평균으로 수렴하려고 할 것이다. 관점을 살짝 틀어보기 위해, 극단적인 상황을 가정해 보자. 모집단 만큼이나 큰 샘플에서 평균을 얻는다고 생각해 보자. 아마 여러차례 샘플링을 시도하여 평균을 구한다면, 그 값은 웬만하면 모집단의 평균처럼 나올 것이다. 물론 정확히 모집단의 평균이 아닌 값들도 관찰될 되겠지만, 작은 오차는 빈번하게 발생할 수 있어도 큰 오차는 드물게 발생할 것이다. 이것은 다음과 같이 해석될 수 있다. 더 큰 샘플링을 시도할 수록 샘플들의 평균은 모집단의 평균을 더 정확히 추정하며, 추적의 과정에서 발생하는 오차들이 큰 오차보다는 작은 오차들이 나타나는 형태로 나름 대칭성을 갖고 분포한다는 것이다. 이렇게 생각해보니 중심 극한 정리가 “당연한 거 아니야?”라고 말할 수 있을 만큼 이해할 법 하다. ‘오차’라는 이야기를 했는데, 이전에 가우스도 참값과 관측값 사이의 오차를 탐구하다 이 오차들이 정규 분포의 형태를 띈다는 것을 확인하고 이 분포를 정의하게 된 것이라고 했다.여기서 정규 분포가 앞으로 어떻게 활용될 수 있는지 짐작해 볼 수도 있을 것 같다. 수학적 정의 앞서 직관적으로 이해한 중심 극한 정리를 수학적 관점에서 다시 정의하자면 다음과 같다. DEFINITION 중심 극한 정리(CLT:Central Limit Theorem)은 무작위로 추출된 표본의 크기가 커질수록 표본 평균의 분포는 모집단의 분포 모양과는 관계없이 정규분포 가까워진다는 정리이다. 임의의 분포를 갖는 확률변수 \(x_1, x_2, \cdots, x_n\) 들이 서로 독립이면서 동일한 분포를 갖고 있다고 하자(=i.i.d)*. 이 확률 분포의 기댓값 \(\mu\) 와 분산 \(\sigma\) 이 유효하다면, 평균 \(S_n = \frac{X_1 + X_2 + \cdots + X_n}{n}\) 의 분포는 기댓값 $\mu$, 표준편차 \(\frac{\sigma}{\sqrt{n}}\) 인 정규 분포 \(N(\mu, \frac{\sigma^2}{n})\) 에 분포 수렴한다. $$\sqrt{n}((\frac{1}{n} \sum_{i=1}^{n}X_i) - \mu) \rightarrow N(0, \sigma^2)$$ * i.i.d : Independent and Identically Distributed random variables 여기서, 만약 표본 평균 \(\overline{X}\)를 \(Z= \frac{\overline{X}-\mu}{\sigma/\sqrt{n}}\) 으로 표준화한다면 이 통계량 \(Z\)는 중심 극한 정리에 따라 표준 정규 분포로 근사한다. 중심 극한 정리의 증명 중심 극한 정리의 증명 방법에는 여러가지 버전이 존재한다. 초기 형태였던 라플라스에 의한 방법은 이항 분포의 정규 분포 근사에 초점이 맞춰져 있고, 현재가 가장 활발히 활용되는 방식은 모멘트 생성 함수의 성질을 이용한 린데베르그-레비의 중심 극한 정리이다. 하지만, 이번 섹션에서는 특성 함수와 합성곱을 활용하여 전통적인 방법 보다 직관적인 접근법을 택하고자 한다. 앞서 중심 극한 정리는 표본 평균들의 분포가 정규 분포에 수렴한다 ‘혹은’ 그 샘플들의 합이 정규 분포에 수렴하다고 했다. 여기서 증명하고자 하는 명제는 변수들의 ‘합’의 수렴이니 혹여 증명 과정에서 길을 잃지 않도록 주의하기 바란다. 명제   독립적이고 동일하게 분포된(i.i.d.) 무작위 변수들의 ‘합’이, 적절하게 정규화될 때, 정규 분포에 수렴한다. 증명 과정이 꽤나 복잡할 수 있어, 중요한 발상을 잘 쫒기 위해 소제목을 붙이니 참고가 되길 바란다. 확률 변수의 합성곱 정의 우선, 합성곱이라는 개념을 어떻게 확률변수에 어떻게 적용되는 지 살펴보자. 두 개의 확률 변수 $X$, $Y$이 서로 독립이라고 하자. 그러면 새로운 확률 변수 $Z = X + Y$에 대한 확률은 다음과 같이 정의할 수 있다. \[P(Z) = \sum_{k=-\infty}^{\infty}{P(X)P(Y)}\] 이 부분이 잘 이해가 되지 않는다면, $X$를 동전 던지기의 앞면이 나올 사건, $Y$를 주사위 던지기의 짝수가 나올 사건, $Z$를 동전과 주사위를 던졌을 때 앞면과 짝수가 나올 사건이라고 했을떄, Z의 확률을 구하기 위해, $X$, $Y$의 확률의 곱을 계산하고 있는 자신의 모습을 떠올려보자. 또, 이러한 내용을 전문적으로 아주 잘 설명하고 있는 이 블로그를 방문해 보길 추천한다. $X$, $Y$의 확률 밀도 함수를 각각 $f(x)$, $g(x)$라고 하면, $Z = X + Y$의 확률 밀도 함수 $(f*g)(z)$ 는 다음과 같은 함수의 합성곱으로 표현될 수 있다. \[(f*g)(z) = \int_{-\infty}^{\infty}f(z-y)g(y)dy = \int_{-\infty}^{\infty}g(z-x)f(x)dx\] 합이 곱으로 변환된다는 점에 주목하자. 이러한 성질을 확률 변수의 특성 함수를 정의함으로써 활용하고자 한다. 확률 변수의 특성 함수 정의 임의의 확률 밀도 함수 $f_X(x)$에 대한 특성 함수는 다음과 같이 정의한다. (t는 실수) \[\phi_X(t) = E[e^{itX}] = \int_{-\infty}^{\infty}e^{jtx}f_X(x)dx\] 이러한 특성 함수의 정의에서 다음과 같은 성질로 복소수 지수 함수 $e^{itX}$의 절대값은 항상 1이다. \[|e^{itx}| = |\cos(tx) + i\sin(tx)| = \sqrt{\cos^2(tx) + \sin^2(tx)} = 1\] 이러한 특성 함수 정의는 라플라스 변환, 확률 생선 함수, 혹은 모멘트 생성 함수와 같은 다른 변환들과 비교했을 때, 모든 확률 분포에 대해 적분이 존재한다는 매우 큰 장점을 갖는다. 맥클로린 급수 전개 앞선 특성 함수 정의에서 $$e^{jtx}$ 는 맥클로린 급수 전개를 이용해 다음과 같이 전개할 수 있다. \[e^{jtx}=\sum_{k=1}^{\infty}\frac{(jtx)^k}{k!}=1+jtx+\frac{(jtx)^2}{2!}+\frac{(jtx)^3}{3!}+\cdots = 1+jtx+\frac{(jtx)^2}{2!}+O(t^2)\] $O(t^2)$ 은 네 번째 항부터 마지막까지의 항을 뭉뚱그려 쓴 것이다. 이것을 특성 함수 전개에 적용하면, \[\phi_X(t) = \int_{-\infty}^{\infty}e^{jtx}f_Y(t)dy=\int_{-\infty}^{\infty}\left\{1+jtx-\frac{t^2}{2}x^2+O(t^2)\right\}f_X(x)dy\notag\] \[=\int_{-\infty}^{\infty}f_X(x)dy + \int_{-\infty}^{\infty}xf_X(x)dy - \frac{t^2}{2}\int_{-\infty}^{\infty}x^2f_X(x)dy+O(t^2)\notag\] \[=1+jtE\left[x\right]-\frac{t^2}{2}E\left[x^2\right]+O(t^2)\] 이 된다. 정규화된 확률 변수 $Z_i$의 특성 함수 자, 확률 변수 $X$를 평균이 0($E(x)=0$)이고, 분산이 1(Var[x]=1)로 정규화한 새로운 확률 변수 $Z_i = \frac{X_i - \mu}{\sigma}$에 대한 특성 함수를 보려고 한다. 앞서 특성 함수의 전개를 봤듯이, $Z_i$에 대한 특성 함수는 다음과 같이 정리된다. \[\phi_Z(t) = E\left[e^{jtz}\right]=\int_{-\infty}^{\infty}e^{jtz}f_Z(z)dx\] \[=1+jtE\left[z\right]-\frac{t^2}{2}E\left[z^2\right]+O(t^2)\] \[= 1+0-\frac{t^2}{2}+O(t^2)\] \[= 1-\frac{t^2}{2}+O(t^2)\] $n$개의 $Z_i$의 합에 대한 특성 함수 $n$개의 독립적인 확률변수 $Z_i$의 합 $S_n = \sum_{i=1}^{n} Z_i = Z_1 + Z_2 + \cdots + Z_n$에 대한 특성 함수는, 합성곱의 성질을 이용하여 다음과 같이 나타낼 수 있다. \[\phi_{S_n}(t) = \left( \phi_{Z}(t) \right)^n\] 앞선 정규화된 $Z$의 특성 함수 전개를 적용하면, \[\phi_{S_n}(t) = \left( \phi_{Z}(t) \right)^n = [1-\frac{t^2}{2N}+O\left(\frac{t^2}{N}\right)]^N\] 이 된다. 여기서, $n$을 무한대로 보내면 $O(\frac{t^2}{N})$이 $\frac{t^2}{2N}$ 보다 빠르게 0에 수렴하므로, 그 극한값은 다음과 같이 수렴한다는 것을 알 수 있다. \[\lim_{N\rightarrow \infty}\phi_{S_N}(t) = \lim_{N\rightarrow\infty}\left[1-\frac{t^2}{2N}\right]^N=e^{-t^2/2}\] 샘플의 규모와 샘플의 수 일반적으로 통계학자들은 표본의 크기가 30 이상일 때 안전하게 정규 분포를 따른다고 하지만, 이것은 경험적 규칙이다. 실제로는 모집단의 비대칭이 심한 경우 더 많은 표본이 필요할 수도 있다. 샘플의 규모는 개별 샘플의 정확도와 대표성을 보장하고, 충분한 샘플 수는 연구 전반의 신뢰도와 결과의 일반화 가능성과 관련이 있다. 다음은 1부터 10까지의 정수에서 샘플들의 편균의 분포를 나타낸다. 샘플의 규모와 샘플 수 시뮬레이션 출처: Wolfram, The Central Limit Theorem(Chris Boucher) 샘플 수가 지나체게 적다면, 아무리 샘플의 규모가 커도 모집단이 아니라 샘플의 분포를 누적할 뿐이다. 이 결과로 일반화가 가능한가에 대해서 심각하게 생각해 보아야 한다. 따라서 단순히 “표본의 크기가 크다면 정규 분포로 수렴!”이라고 생각하는 것은 주의할 필요가 있다. 당연히 샘플의 규모도 크고, 샘플의 수도 많은 것이 최고의 시나리오일 것이다. 그래서, 정규 분포가 중요한 이유? 샘플링 기법에 기반한 추론적 통계에서, 표본 평균들의 분포를 이해하는 것은 모평균을 추적함에 있어 중요하다. 그런데 중심 극한 정리에 따르면 충분히 큰 샘플에서 샘플링이 이루어 진다면, 모평균에 대해 전혀 알지 못해도, 이 표본 평균들의 분포가 정규 분포로 수렴한다. 일반적으로 많은 상황에서 우리는 제한된 관측치를 가지고 모집단을 추정해 본다. 이때, 관측치들을 일정하게 샘플링해 얻은 평균값들의 분포를 통해 모집단의 분포를 추정하려는 시도는, 우리가 정규 분포를 필연적으로, 꽤나 자주 마주하게 만들 것이다. 참조 Normal Distribution: An Introductory Guide to PDF and CDF(Teena Mary) 가우시안(Gaussian)-정규분포(Normal Distribution).너란 분포 정말(친절한 데이터 사이언스 강좌) “Python Implementation of Central Limit Theorem: Exploring Sample Data to Infer Population Parameters”(Amanatullah) Understanding Convolutions(colah’s blog) Characteristic Functions and the Central Limit Theorem(University of Waterloo) Sampling Distribution of the Mean Simulation]]></summary></entry><entry xml:lang="ko"><title type="html">포아송 분포</title><link href="http://localhost:4000/2024/04/02/poisson_distribution_ko.html" rel="alternate" type="text/html" title="포아송 분포" /><published>2024-04-02T00:00:00+09:00</published><updated>2024-04-02T00:00:00+09:00</updated><id>http://localhost:4000/2024/04/02/poisson_distribution_ko</id><content type="html" xml:base="http://localhost:4000/2024/04/02/poisson_distribution_ko.html"><![CDATA[<p align="center">
  <img class="image image--md" src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/poisson_distribution/Simeon Denis Poisson.jpg" />
</p>

<p>프랑스의 수학자 Siméon Denis Poisson는 이산 확률 분포의 한 형태로 포아송 분포를 처음 소개하였다. 이후 1898년 폴란드계 수학자 Ladislaus Bortkiewicz가 프로이센 군대의 군인들이 말차기로 우연히 죽는 빈도를 포아송 분포로 잘 모델링해 보임으로써 포아송 분포의 실제 적용이 이루어졌다.</p>

<h2 id="이항-분포의-포아송-분포로의-전환">이항 분포의 포아송 분포로의 전환</h2>
<h3 id="포아송-케이스">포아송 케이스</h3>
<p>앞서 <a href="https://jenniione.github.io/2024/03/27/binomial_distribution_ko.html#%EC%9D%B4%ED%95%AD-%EB%B6%84%ED%8F%AC%EC%9D%98-%EC%A0%95%EA%B7%9C-%EB%B6%84%ED%8F%AC-%EA%B7%BC%EC%82%AC">이항 분포의 시뮬레이션</a>을 통해, 다양한 경우의 이항 분포 형태를 확인할 수 있었다. 그 중 극단적인 n(시행횟수), p(성공확률)의 값에 대한 이항 분포는 정규 분포로의 근사와는 다른 독특한 분포 형태를 취했다. 특히 <strong>시행 횟수인 n이 충분히 큼에도 불구하고 성공 확률 p값이 지나치게 작을 경우</strong>, 다음과 같은 분포를 보인다는 것을 보았다.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/small p.png" />
</p>

<p>이러한 사건은 사실 이항 분포로 설명되는 대부분의 사건들과는 다른 특별한 케이스로, 이항 분포로 설명하기에 최적화되었다고 말하기 어렵다. 포아송 분포는 이러한 특별한 사건을 집중적으로 설명하기 위해 소개된 분포라고 할 수 있다. 포아송 분포가 다루는 사건에 대해 보다 자세히 살펴보자.</p>

<h3 id="포아송-케이스에-대한-이항-분포의-한계">포아송 케이스에 대한 이항 분포의 한계</h3>
<p>포아송 분포의 실제 적용에 기여한  Ladislaus Bortkiewicz의 ‘프로이센 군대의 군인들이 말차기로 우연히 죽는 빈도’ 문제를 생각해 보자. 어느날 프로이센의 군대를 관찰하던 중 군인들이 말차기로 우연히 죽는다는 것을 발견했다. 20년동안 매년 10명 정도의 군인이 말에 치여 사망하는 것 같다. 한해에 5명의 군인만이 말에 차여 사망할 확률을 알 수 있을까?
이 문제를 해결하기 위해 군인이 죽는지(성공)를 관찰하는 이항 분포만을 고려한다고 가정해 보자. 동전 던지기처럼 군인의 죽음을 관찰하는 n번의 시행이 이루어진다고 했을 때, n을 설정한다는 것은 꽤나 모호하다. 그럼에도 1년을 한번의 시행으로 쳐서 20번의 시행이 이루어졌다고 접근하여도 10명 군인이 1년째에 모두 나타거나, 2년째, …, 20년째에 한번에 나타나는 확률을 구하지 않는 이상 이항 분포의 활용은 꽤나 어려워 보인다. 이는 매년 평균적으로 10명이 죽는다고 해도, 시간을 기준으로 관찰시 <strong>매년 죽은 군인 수라는 사건 발생의 무작위성 때문</strong>이다.</p>

<h3 id="포아송-분포로의-접근과-유도">포아송 분포로의 접근과 유도</h3>
<p>우리는 이 문제를 해결하기 위해 n과 p라는 이항분포의 파라미터에서 벗어나서, ‘매년 10명’이라는 새로운 파라미터로 문제를 접근할 필요가 있다. 이를 \(\lambda\) 라고 하자. 즉 <u>$\lambda$ 는 단위 시간/공간 당 평균 발생 횟수</u>가 된다. 이는 이항 분포의 맥락에서 일종의 기댓값으로 \(\lambda = np\) 가 된다. ‘평균 10년’이라는 일정한 \(\lambda\) 이 주어졌을 때, 시간(시행)의 연속성을 적용하여 \(n\) 을 무한대로 보내면 \(p\) 는 0으로 접근한다고 볼 수 있다.</p>

\[\lim_{n\rightarrow \infty}p=\lim_{n\rightarrow \infty}\frac{\lambda}{n} = 0\]

<p>그럼, 이항 분포의 확률 밀도 함수에 이를 적용하여 그 극한값을 도출해 보자.</p>

\[\lim_{n \to \infty} B(k; n, p)\]

\[= \lim_{n \to \infty}  { {n}\choose{k} }  p^k(1-p)^{n-k}\]

\[= \lim_{n \to \infty}  \dfrac{n!}{k!(n-k)!}(\dfrac{\lambda}{n})^k  (1-\dfrac{\lambda}{n})^{n-k}\]

\[= \lim_{n \to \infty}  {\left[  \dfrac{n!}{(n-k)!  n^k} \right]}  \left[  \dfrac{\lambda^k}{k!}  (1-\dfrac{\lambda}{n})^{n}  \right]  {\left[  (1-\dfrac{\lambda}{n})^{-k}\right]}\]

\[= \lim_{n \to \infty}  {\left[  \dfrac{n(n-1)\dotsb(n-(k-1))}{n^k} \right]}  \left[  \dfrac{\lambda^k}{k!}  (1-\dfrac{\lambda}{n})^{n}  \right]  {\left[  (1-\dfrac{\lambda}{n})^{-k}\right]}\]

\[= 1\left[  \dfrac{\lambda^k}{k!}  e^{-\lambda}\right] 1\]

\[= (\frac{\lambda^k}{k!})e^{-\lambda}\\\]

<p>따라서,</p>

<ul>
  <li>(6) : \(n\) 이 무한대로 갈때, \(k\)는 상대적으로 작은 상수이므로 위와 같은 극한값이 계산된다.</li>
</ul>

\[Pr(K=k) = (\frac{\lambda^k}{k!})e^{-\lambda}\]

<p>결국 우리는 고정된 \(lambda\)가 주어졌을 때, n을 무한대로 보내는 이항 분포의 확률 밀도 함수를 도출해 냄으로써, 이항 분포의 파라미터로 설명하기 어려운 사건을 \(lambda\)라는 새로운 파라미터 하나로써 표현할 수 있게 되었다.</p>

<h2 id="포아송-분포의-정의">포아송 분포의 정의</h2>

<table>
  <thead>
    <tr>
      <th>DEFINITION</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>포아송(Poisson Distribution)</strong>은 단위 시간 또는 공간에서 발생하는 사건의 수를 모델링하는 확률 분포이다. 확률 변수 \(x\)가 포아송 분포를 따르는 경우 다음과 같이 표기하며, <br /> <center> $$\begin{aligned} x \sim \text{Pois}(\lambda) \end{aligned} $$ </center> <br /> 그 확률 질량 함수는 다음과 같다. <br /> <center> $$\begin{aligned} P(x) = \frac{\lambda^{k} e^{-\lambda}}{k!} \quad \text{ for } k =0,1,2,\cdots \end{aligned} $$</center></td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
    </tr>
  </tbody>
</table>

<h2 id="직관적-포아송-분포">직관적 포아송 분포</h2>
<p>포아송 분포는 특정 시간 간격이나 공간에서 발생하는 드문 사건의 횟수를 모델링하는 사용된다. 다시 말해, <strong>시행 횟수가 굉장히 크지만 드물게 발생할 확률을 가진 이항적 사건에서, 평균값이 주어졌을 때, 특정 값이 발생할 확률을 효과적으로 계산</strong>할 수 있도록 한다. 이러한 확률 계산은 어떤 상황에서 중요하게 활용될 수 있을까?</p>

<ul>
  <li>예시 1<br />
어떤 도시에서 $A$라는 질병이 <u>평균적으로 한 달에 2회</u> 발생한다. 보건 당국은 자원 할당과 질병 대응 준비를 위해 다음 달에 이 질병이 <u>발생하지 않을</u> 수 있을지 알고 싶다.</li>
</ul>

\[Pr(K=0)\]

\[= \frac{e^{-2} \times 2^0} {0!}\]

\[= 0.1353\]

<p>질병이 평균적으로 관찰되는 수치를 기반해 보았을 때, <u>다음 달에 이 질병이 발생하지 않을 확률은 13%</u>라고 할 수 있다.</p>

<ul>
  <li>예시 2<br />
이커머스 웹사이트가 특정 마케팅 캠페인이나 이벤트가 없는 일반적인 날을 기준으로 <u>평균적으로 하루 200건</u>의 주문을 처리한다. 운영팀은 예상 주문량에 따라 배송 준비나 고객 서비스 인력을 조정하는 등 효율적인 관리를 수행하기 위해, 현재 어느 정도의 주문 처리 능력을 보유하고 있는 것인지 알고 싶다. 정확히 &lt;/u&gt;250건&lt;/u&gt;을 처리할 수 있는 확률은 어떻게 될까?</li>
</ul>

\[P(X=250) = \frac{e^{-200} \times 200^{250}}{250!} = 0.000077\]

<p>이는 웹사이트 운영에 있어서 <u>특정 일의 주문량이 예상치를 초과할 확률이 얼마나 낮은지</u>를 보여준다. 특별히 높은 주문량을 처리할 준비를 해야할 날이 드물다는 정보를 통해, 재고, 배송, 고객 서비스 등의 자원 배치를 효과적으로 계획할 수 있다.</p>

<p>이처럼 포아송 분포는 다양한 상황에서 중요한 정보를 해석하는 데 활용될 수 있다.</p>

<h2 id="포아송-분포의-시뮬레이션">포아송 분포의 시뮬레이션</h2>
<p>포아송 분포의 파라미터는 \(\lambda\) 하나이다. 그렇다면 \(\lambda\) 값이 변함에 따라 포아송 분포는 어떻게 변화하는 지 살펴보자.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/poisson_distribution/poisson_distribution.png" />
</p>

<p>위 그래프는 \(\lambda = 1\)로, 그 값이 매우 작을 때, 대부분의 확률이 0 또는 1로 집중되어 있다는 것을 보여준다.</p>

<p>또한 \(\lambda = 10\), \(\lambda = 30\) 일 때를 보면, <strong>\(\lambda\)값이 커질 수록, 사건 발생 확률이 더 넓고 고르게 분포하며 그래프의 모양이 정규분포에 근사</strong>할 수 있음을 시각적으로 보여준다.</p>

<p>실제로 포아송 분포는 <strong>\(\lambda\) 가 커지면 정규분포 \(N(\lambda, \lambda^{2})\) 에 근사</strong>한다.</p>

<p><br /><br />
<strong>참조</strong></p>

<p><a href="https://ko.wikipedia.org/wiki/%ED%91%B8%EC%95%84%EC%86%A1_%EB%B6%84%ED%8F%AC">Wikipedia, Poisson Distribution</a><br />
<a href="https://angeloyeo.github.io/2021/04/26/Poisson_distribution.html">Angelo’s Math Notes(Angelo)</a></p>]]></content><author><name>Jenny Won (Dajeong Won)</name></author><category term="통계학" /><summary type="html"><![CDATA[프랑스의 수학자 Siméon Denis Poisson는 이산 확률 분포의 한 형태로 포아송 분포를 처음 소개하였다. 이후 1898년 폴란드계 수학자 Ladislaus Bortkiewicz가 프로이센 군대의 군인들이 말차기로 우연히 죽는 빈도를 포아송 분포로 잘 모델링해 보임으로써 포아송 분포의 실제 적용이 이루어졌다. 이항 분포의 포아송 분포로의 전환 포아송 케이스 앞서 이항 분포의 시뮬레이션을 통해, 다양한 경우의 이항 분포 형태를 확인할 수 있었다. 그 중 극단적인 n(시행횟수), p(성공확률)의 값에 대한 이항 분포는 정규 분포로의 근사와는 다른 독특한 분포 형태를 취했다. 특히 시행 횟수인 n이 충분히 큼에도 불구하고 성공 확률 p값이 지나치게 작을 경우, 다음과 같은 분포를 보인다는 것을 보았다. 이러한 사건은 사실 이항 분포로 설명되는 대부분의 사건들과는 다른 특별한 케이스로, 이항 분포로 설명하기에 최적화되었다고 말하기 어렵다. 포아송 분포는 이러한 특별한 사건을 집중적으로 설명하기 위해 소개된 분포라고 할 수 있다. 포아송 분포가 다루는 사건에 대해 보다 자세히 살펴보자. 포아송 케이스에 대한 이항 분포의 한계 포아송 분포의 실제 적용에 기여한 Ladislaus Bortkiewicz의 ‘프로이센 군대의 군인들이 말차기로 우연히 죽는 빈도’ 문제를 생각해 보자. 어느날 프로이센의 군대를 관찰하던 중 군인들이 말차기로 우연히 죽는다는 것을 발견했다. 20년동안 매년 10명 정도의 군인이 말에 치여 사망하는 것 같다. 한해에 5명의 군인만이 말에 차여 사망할 확률을 알 수 있을까? 이 문제를 해결하기 위해 군인이 죽는지(성공)를 관찰하는 이항 분포만을 고려한다고 가정해 보자. 동전 던지기처럼 군인의 죽음을 관찰하는 n번의 시행이 이루어진다고 했을 때, n을 설정한다는 것은 꽤나 모호하다. 그럼에도 1년을 한번의 시행으로 쳐서 20번의 시행이 이루어졌다고 접근하여도 10명 군인이 1년째에 모두 나타거나, 2년째, …, 20년째에 한번에 나타나는 확률을 구하지 않는 이상 이항 분포의 활용은 꽤나 어려워 보인다. 이는 매년 평균적으로 10명이 죽는다고 해도, 시간을 기준으로 관찰시 매년 죽은 군인 수라는 사건 발생의 무작위성 때문이다. 포아송 분포로의 접근과 유도 우리는 이 문제를 해결하기 위해 n과 p라는 이항분포의 파라미터에서 벗어나서, ‘매년 10명’이라는 새로운 파라미터로 문제를 접근할 필요가 있다. 이를 \(\lambda\) 라고 하자. 즉 $\lambda$ 는 단위 시간/공간 당 평균 발생 횟수가 된다. 이는 이항 분포의 맥락에서 일종의 기댓값으로 \(\lambda = np\) 가 된다. ‘평균 10년’이라는 일정한 \(\lambda\) 이 주어졌을 때, 시간(시행)의 연속성을 적용하여 \(n\) 을 무한대로 보내면 \(p\) 는 0으로 접근한다고 볼 수 있다. \[\lim_{n\rightarrow \infty}p=\lim_{n\rightarrow \infty}\frac{\lambda}{n} = 0\] 그럼, 이항 분포의 확률 밀도 함수에 이를 적용하여 그 극한값을 도출해 보자. \[\lim_{n \to \infty} B(k; n, p)\] \[= \lim_{n \to \infty} { {n}\choose{k} } p^k(1-p)^{n-k}\] \[= \lim_{n \to \infty} \dfrac{n!}{k!(n-k)!}(\dfrac{\lambda}{n})^k (1-\dfrac{\lambda}{n})^{n-k}\] \[= \lim_{n \to \infty} {\left[ \dfrac{n!}{(n-k)! n^k} \right]} \left[ \dfrac{\lambda^k}{k!} (1-\dfrac{\lambda}{n})^{n} \right] {\left[ (1-\dfrac{\lambda}{n})^{-k}\right]}\] \[= \lim_{n \to \infty} {\left[ \dfrac{n(n-1)\dotsb(n-(k-1))}{n^k} \right]} \left[ \dfrac{\lambda^k}{k!} (1-\dfrac{\lambda}{n})^{n} \right] {\left[ (1-\dfrac{\lambda}{n})^{-k}\right]}\] \[= 1\left[ \dfrac{\lambda^k}{k!} e^{-\lambda}\right] 1\] \[= (\frac{\lambda^k}{k!})e^{-\lambda}\\\] 따라서, (6) : \(n\) 이 무한대로 갈때, \(k\)는 상대적으로 작은 상수이므로 위와 같은 극한값이 계산된다. \[Pr(K=k) = (\frac{\lambda^k}{k!})e^{-\lambda}\] 결국 우리는 고정된 \(lambda\)가 주어졌을 때, n을 무한대로 보내는 이항 분포의 확률 밀도 함수를 도출해 냄으로써, 이항 분포의 파라미터로 설명하기 어려운 사건을 \(lambda\)라는 새로운 파라미터 하나로써 표현할 수 있게 되었다. 포아송 분포의 정의 DEFINITION 포아송(Poisson Distribution)은 단위 시간 또는 공간에서 발생하는 사건의 수를 모델링하는 확률 분포이다. 확률 변수 \(x\)가 포아송 분포를 따르는 경우 다음과 같이 표기하며, $$\begin{aligned} x \sim \text{Pois}(\lambda) \end{aligned} $$ 그 확률 질량 함수는 다음과 같다. $$\begin{aligned} P(x) = \frac{\lambda^{k} e^{-\lambda}}{k!} \quad \text{ for } k =0,1,2,\cdots \end{aligned} $$ 직관적 포아송 분포 포아송 분포는 특정 시간 간격이나 공간에서 발생하는 드문 사건의 횟수를 모델링하는 사용된다. 다시 말해, 시행 횟수가 굉장히 크지만 드물게 발생할 확률을 가진 이항적 사건에서, 평균값이 주어졌을 때, 특정 값이 발생할 확률을 효과적으로 계산할 수 있도록 한다. 이러한 확률 계산은 어떤 상황에서 중요하게 활용될 수 있을까? 예시 1 어떤 도시에서 $A$라는 질병이 평균적으로 한 달에 2회 발생한다. 보건 당국은 자원 할당과 질병 대응 준비를 위해 다음 달에 이 질병이 발생하지 않을 수 있을지 알고 싶다. \[Pr(K=0)\] \[= \frac{e^{-2} \times 2^0} {0!}\] \[= 0.1353\] 질병이 평균적으로 관찰되는 수치를 기반해 보았을 때, 다음 달에 이 질병이 발생하지 않을 확률은 13%라고 할 수 있다. 예시 2 이커머스 웹사이트가 특정 마케팅 캠페인이나 이벤트가 없는 일반적인 날을 기준으로 평균적으로 하루 200건의 주문을 처리한다. 운영팀은 예상 주문량에 따라 배송 준비나 고객 서비스 인력을 조정하는 등 효율적인 관리를 수행하기 위해, 현재 어느 정도의 주문 처리 능력을 보유하고 있는 것인지 알고 싶다. 정확히 &lt;/u&gt;250건&lt;/u&gt;을 처리할 수 있는 확률은 어떻게 될까? \[P(X=250) = \frac{e^{-200} \times 200^{250}}{250!} = 0.000077\] 이는 웹사이트 운영에 있어서 특정 일의 주문량이 예상치를 초과할 확률이 얼마나 낮은지를 보여준다. 특별히 높은 주문량을 처리할 준비를 해야할 날이 드물다는 정보를 통해, 재고, 배송, 고객 서비스 등의 자원 배치를 효과적으로 계획할 수 있다. 이처럼 포아송 분포는 다양한 상황에서 중요한 정보를 해석하는 데 활용될 수 있다. 포아송 분포의 시뮬레이션 포아송 분포의 파라미터는 \(\lambda\) 하나이다. 그렇다면 \(\lambda\) 값이 변함에 따라 포아송 분포는 어떻게 변화하는 지 살펴보자. 위 그래프는 \(\lambda = 1\)로, 그 값이 매우 작을 때, 대부분의 확률이 0 또는 1로 집중되어 있다는 것을 보여준다. 또한 \(\lambda = 10\), \(\lambda = 30\) 일 때를 보면, \(\lambda\)값이 커질 수록, 사건 발생 확률이 더 넓고 고르게 분포하며 그래프의 모양이 정규분포에 근사할 수 있음을 시각적으로 보여준다. 실제로 포아송 분포는 \(\lambda\) 가 커지면 정규분포 \(N(\lambda, \lambda^{2})\) 에 근사한다. 참조 Wikipedia, Poisson Distribution Angelo’s Math Notes(Angelo)]]></summary></entry><entry xml:lang="ko"><title type="html">기하 분포</title><link href="http://localhost:4000/2024/03/28/geometric_distribution_ko.html" rel="alternate" type="text/html" title="기하 분포" /><published>2024-03-28T00:00:00+09:00</published><updated>2024-03-28T00:00:00+09:00</updated><id>http://localhost:4000/2024/03/28/geometric_distribution_ko</id><content type="html" xml:base="http://localhost:4000/2024/03/28/geometric_distribution_ko.html"><![CDATA[<p><a href="https://jenniione.github.io/2024/03/27/binomial_distribution_ko.html">이항 분포</a>에 대한 개념을 잘 이해했다면 기하 분포를 그리 어려운 개념은 아니다.
이항 분포가 베르누이 시행에 따른 ‘성공’을 관찰하는 분포라면, 기하 분포는 <strong>‘성공할 때까지의 시행횟수’</strong> 혹은 <strong>‘성공할 때까지의 실패 횟수’</strong> 의 분포이다.</p>

<h2 id="기하-분포의-정의">기하 분포의 정의</h2>

<table>
  <thead>
    <tr>
      <th>DEFINITION 1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>기하 분포(Geometric Distribution)</strong>은 이항 분포와 같이 여러번의 베르누이 시행에서 처음 성공이 나타날 때까지의 <u>시행 횟수</u>를 모델링한 확률 분포이다.</td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th>DEFINITION 2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>기하 분포(Geometric Distribution)</strong>은 이항 분포와 같이 여러번의 베르누이 시행에서 첫 번째 성공이 나타날 때까지의 <u>실패 횟수</u>를 모델링한 확률 분포이다.</td>
    </tr>
  </tbody>
</table>

<p>기하 분포는 성공하기까지의 시도 횟수를 모델링하는 데 사용되며, 이에 대한 두 가지 정의가 있다. 이 두 정의의 주요 차이는 성공을 달성하기까지의 시도 횟수에 대한 계산 방법에 있다. 정의 (1)는 첫 성공이 포함된 전체 시도 횟수를 사용하는 반면, 정의 (2)는 첫 성공을 달성하기 전까지의 시도 횟수만을 고려한다.</p>

<p>동전 던지기를 예로 들면, 성공을 앞면이 나오는 경우로 정의할 때, ‘뒷면-뒷면-뒷면-앞면’이라는 결과가 나왔다고 가정하자. 이 상황에서 정의 (1)은 성공까지의 시도 횟수 $X$는 $4$가 된다. 반면에 정의 (2)를 적용하면, 첫 성공을 달성하기 전까지의 시도 횟수, 즉 3이 X의 값으로 사용된다. 이렇게 두 정의는 성공을 포함하는지 여부에 따라 1만큼의 차이를 보이며, 이는 기하 분포를 해석할 때 중요한 고려 사항이 된다.</p>

<p>기하 분포는 다음과 같이 표기하며,</p>

\[\begin{equation} 
 \begin{aligned} 
x \sim \text{Geom}(p)
\end{aligned}   
\end{equation}\]

<p>그 확률 질량 함수(PMF)는 다음과 같다.</p>

\[\begin{equation} 
\begin{aligned} 
P(x) = (1-p)^{k-1} p \quad \text{ for } k =1,2,\cdots
\end{aligned} 
\end{equation}\]

<p>## 
확률  함수를 이해하기 위해, 10번의 동전 던지기 예시를 다시 보자. ‘성공’이라는 앞면이 나올 때까지 시행 횟수는 \(X=x\)라고 하자. \(x=3\)일 때, 그 확률은 (실패 확률) $\cdot$ (실패 확률) $\cdot$ (성공 확률), 즉 \((1-\frac{1}{2})^2(\frac{1}{2})=0.125\)이 된다.</p>

<h2 id="기하-분포의-무기억성">기하 분포의 무기억성</h2>
<p>기하 분포의 특징에는 무기억성이 있다. 수학적으로는 다음과 같이 표현할 수 있다.</p>

\[P(X &gt; s + t | X &gt; s) = P(X &gt; t)\]

<p>이것은 과거의 결과가 미래의 확률에 영향을 주지 않는다는 것을 의미한다. 동전 던지기를 통해 이미 6번의 뒷면이 나왔다고 하여도, 다음 동전 던지기의 앞면이 나올 확률은 여전히 \(1/2\)이다. 또한 7번째 던지기에서 이전에 6번을 던졌다는 사실은 영향을 미치지 않는다. 다시 처음부터 시작해도 첫 성공까지의 기대 시도 횟수는 변하지 않는다는 것이다.</p>

<p>이러한 기하 분포의 무기억성은 네트워크 트래픽 분석, 대기열 이론 등에 유용하게 활용될 수 있다. 웹 서버 요청이 도착하는 시간 간격이 기하 분포를 따른다고 가정할 때, 이미 어느 정도 시간이 지났다 하여도 다음 요청이 도착할 때까지의 기대 시간은 변하지 않는다. 이는 대기  시간, 시스템의 처리량, 자원 할당 전략을 최적화하는데 중요한 역할을 한다.</p>

<h2 id="직관적-기하-분포">직관적 기하 분포</h2>
<p>기하 분포는 ‘성공’이 발생할 때까지 기다리는 관찰에 따른 결과이다. 이러한 특징은 웹사이트에서 사용자가 처음으로 구매를 하는데 필요한 페이지 방문 횟수, 즉, 실패 횟수를 분석하거나, 어떤 제품이나 서비스가 특정 기간 동안 실패하지 않고 지속될 확률을 계산하는 데에도 사용될 수 있다. 또한 A/B테스팅에서 특정 전략이 성공을 보이기까지의 시도 횟수를 분석하고 그 적략의 효율성을 평가할 수도 있다.</p>

<p><br /><br />
<strong>참조</strong></p>

<p><a href="https://www.geogebra.org/m/twbv2tmk">binomial and geometric distribution(pthao_nguyen, Zoran)</a></p>]]></content><author><name>Jenny Won (Dajeong Won)</name></author><category term="통계학" /><summary type="html"><![CDATA[이항 분포에 대한 개념을 잘 이해했다면 기하 분포를 그리 어려운 개념은 아니다. 이항 분포가 베르누이 시행에 따른 ‘성공’을 관찰하는 분포라면, 기하 분포는 ‘성공할 때까지의 시행횟수’ 혹은 ‘성공할 때까지의 실패 횟수’ 의 분포이다. 기하 분포의 정의 DEFINITION 1 기하 분포(Geometric Distribution)은 이항 분포와 같이 여러번의 베르누이 시행에서 처음 성공이 나타날 때까지의 시행 횟수를 모델링한 확률 분포이다. DEFINITION 2 기하 분포(Geometric Distribution)은 이항 분포와 같이 여러번의 베르누이 시행에서 첫 번째 성공이 나타날 때까지의 실패 횟수를 모델링한 확률 분포이다. 기하 분포는 성공하기까지의 시도 횟수를 모델링하는 데 사용되며, 이에 대한 두 가지 정의가 있다. 이 두 정의의 주요 차이는 성공을 달성하기까지의 시도 횟수에 대한 계산 방법에 있다. 정의 (1)는 첫 성공이 포함된 전체 시도 횟수를 사용하는 반면, 정의 (2)는 첫 성공을 달성하기 전까지의 시도 횟수만을 고려한다. 동전 던지기를 예로 들면, 성공을 앞면이 나오는 경우로 정의할 때, ‘뒷면-뒷면-뒷면-앞면’이라는 결과가 나왔다고 가정하자. 이 상황에서 정의 (1)은 성공까지의 시도 횟수 $X$는 $4$가 된다. 반면에 정의 (2)를 적용하면, 첫 성공을 달성하기 전까지의 시도 횟수, 즉 3이 X의 값으로 사용된다. 이렇게 두 정의는 성공을 포함하는지 여부에 따라 1만큼의 차이를 보이며, 이는 기하 분포를 해석할 때 중요한 고려 사항이 된다. 기하 분포는 다음과 같이 표기하며, \[\begin{equation}   \begin{aligned}  x \sim \text{Geom}(p) \end{aligned}    \end{equation}\] 그 확률 질량 함수(PMF)는 다음과 같다. \[\begin{equation}  \begin{aligned}  P(x) = (1-p)^{k-1} p \quad \text{ for } k =1,2,\cdots \end{aligned}  \end{equation}\] ## 확률 함수를 이해하기 위해, 10번의 동전 던지기 예시를 다시 보자. ‘성공’이라는 앞면이 나올 때까지 시행 횟수는 \(X=x\)라고 하자. \(x=3\)일 때, 그 확률은 (실패 확률) $\cdot$ (실패 확률) $\cdot$ (성공 확률), 즉 \((1-\frac{1}{2})^2(\frac{1}{2})=0.125\)이 된다. 기하 분포의 무기억성 기하 분포의 특징에는 무기억성이 있다. 수학적으로는 다음과 같이 표현할 수 있다. \[P(X &gt; s + t | X &gt; s) = P(X &gt; t)\] 이것은 과거의 결과가 미래의 확률에 영향을 주지 않는다는 것을 의미한다. 동전 던지기를 통해 이미 6번의 뒷면이 나왔다고 하여도, 다음 동전 던지기의 앞면이 나올 확률은 여전히 \(1/2\)이다. 또한 7번째 던지기에서 이전에 6번을 던졌다는 사실은 영향을 미치지 않는다. 다시 처음부터 시작해도 첫 성공까지의 기대 시도 횟수는 변하지 않는다는 것이다. 이러한 기하 분포의 무기억성은 네트워크 트래픽 분석, 대기열 이론 등에 유용하게 활용될 수 있다. 웹 서버 요청이 도착하는 시간 간격이 기하 분포를 따른다고 가정할 때, 이미 어느 정도 시간이 지났다 하여도 다음 요청이 도착할 때까지의 기대 시간은 변하지 않는다. 이는 대기 시간, 시스템의 처리량, 자원 할당 전략을 최적화하는데 중요한 역할을 한다. 직관적 기하 분포 기하 분포는 ‘성공’이 발생할 때까지 기다리는 관찰에 따른 결과이다. 이러한 특징은 웹사이트에서 사용자가 처음으로 구매를 하는데 필요한 페이지 방문 횟수, 즉, 실패 횟수를 분석하거나, 어떤 제품이나 서비스가 특정 기간 동안 실패하지 않고 지속될 확률을 계산하는 데에도 사용될 수 있다. 또한 A/B테스팅에서 특정 전략이 성공을 보이기까지의 시도 횟수를 분석하고 그 적략의 효율성을 평가할 수도 있다. 참조 binomial and geometric distribution(pthao_nguyen, Zoran)]]></summary></entry><entry xml:lang="ko"><title type="html">Binomial Distribution</title><link href="http://localhost:4000/2024/03/27/binomial_distribution_en.html" rel="alternate" type="text/html" title="Binomial Distribution" /><published>2024-03-27T00:00:00+09:00</published><updated>2024-03-27T00:00:00+09:00</updated><id>http://localhost:4000/2024/03/27/binomial_distribution_en</id><content type="html" xml:base="http://localhost:4000/2024/03/27/binomial_distribution_en.html"><![CDATA[<p>Before diving into the binomial distribution, let’s briefly summarize the Bernoulli distribution and explore its relationship with the binomial distribution.</p>

<h2 id="bernoulli-distribution">Bernoulli Distribution</h2>
<p>A Bernoulli experiment refers to a probability experiment where the outcome can either be a success or a failure. The probability distribution that represents the number of successes in a Bernoulli experiment, with a fixed success probability \(p\), is known as the <strong>Bernoulli distribution</strong>. Therefore, the Bernoulli distribution is a probability distribution where the value of the random variable is either a success or a failure. Since <strong>the outcome can only be one of two values, success or failure</strong>, a Bernoulli random variable is classified as a <strong>discrete random variable</strong>.</p>

<p>one where the outcome can either be a success or a failure. The probability distribution that accounts for the number of successes in a Bernoulli experiment, with a fixed probability of success \(p\), is the Bernoulli distribution.</p>

\[x  \{ \text{success, fail} \} \rightarrow \{0, 1\}\]

\[\begin{equation}
\begin{aligned}
&amp; P(x=0) = 1-p \\
&amp; P(x=1) = p \\ \end{aligned}
\end{equation}\]

<p>If the random variable \(X\) follows a Bernoulli distribution, it can be expressed as follows:</p>

\[\begin{equation} 
 \begin{aligned} 
&amp; x \sim \text{Bern}(p)
\end{aligned}   
\end{equation}\]

<p>And its Probability Mass Function (PMF) can be represented by the following formula:</p>

\[\begin{split}
\begin{align}
\text{Bern}(x; p) = 
\begin{cases} 
p   &amp; \text{if }x=1, \\
1-p &amp; \text{if }x=0
\end{cases}
\tag{8.2.2}
\end{align}
\end{split}\]

<p>It is important to note that the Bernoulli distribution focuses on observational data from the result of <strong>a single trial</strong>, emphasizing the <strong>probability of success \(p\)</strong>. This aspect explains how the binomial distribution differs from the Bernoulli distribution.</p>

<h2 id="definition-of-binomial-distribution">Definition of Binomial Distribution</h2>

<table>
  <thead>
    <tr>
      <th>DEFINITION</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>The Binomial Distribution</strong> models the number of successes in a fixed number \(n\) of repeated Bernoulli trials, each with the same success probability \(p\).</td>
    </tr>
  </tbody>
</table>

<p>The binomial distribution is the probability distribution obtained by repeating a Bernoulli trial \(n\) times. In other words, <strong>the binomial distribution is an extension of the Bernoulli trial</strong>. It models the probability distribution of the number of successes in \(n\) repeated Bernoulli trials, not just a single Bernoulli trial. 
For example, consider the example of flipping a coin. When you perform a single coin toss with the probability of getting heads being \(p=1/2\); the outcome follows a Bernoulli distribution. However, if the same coin is flipped 10 times, and the number of times heads appears is observed, this scenario follows a binomial distribution. The key here is that during the 10 flips, <strong>each flip is independent, and the probability of success for each trial remains constant at \(p\)</strong> (as is the case with a fixed \(p\) in a Bernoulli trial).</p>

<p>The binomial distribution can be expressed as follows,
\(\begin{equation} 
 \begin{aligned} 
x \sim \text{Bin}(n,p)
\end{aligned}   
\end{equation}\)</p>

<p>ans its Probability Mass Function (PMF) is defined as follows.</p>

\[\begin{equation} 
P_X(x) = \ _{n}C_{x} p^k (1-p)^{n-x} \quad \text{ for } x =0,1,\cdots,n
\end{equation}\]

<h2 id="real-insights-into-the-binomial-distribution">Real Insights into the Binomial Distribution</h2>
<h3 id="example-of-flipping-a-coin-10-times">Example of Flipping a Coin 10 Times</h3>

<p>To grasp the Probability Mass Function, let’s calculate the probability of outcomes in the scenario of flipping a coin 10 times.
Consider a success as the coin landing on heads, and let \(x\) be the number of successes. Thus, \(x=0,1,2,⋯,10\), representing the scenarios where the coin lands on heads 0 times, 1 time, 2 times, … up to 10 times. Let’s consider the probability when \(x=2\), that is, the probability of the coin landing on heads 2 times in 10 flips.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/coin k=2.png" />
</p>

<p>As illustrated, each independent event of the coin landing on heads 2 times out of 10 flips has a probability of \((\frac{1}{2})^2(1-\frac{1}{2})^{8}\). This can occur in \(_{10}C_{2}\) different ways. The calculation is as follows:</p>

\[_{10}C_{2}\left(\frac{1}{2}\right)^2 \left(1-\frac{1}{2}\right)^{8} = 0.0439\]

<p>Using the same method, calculating the probabilities for all values of \(x\) yields the following results:</p>

\[x=0 ;  \frac{10!}{1!\cdot9!}
\left(\frac{1}{2}\right)^0 \left(1-\frac{1}{2}\right)^{10} = 0.0010\]

\[x=1 ;  \frac{10!}{1!\cdot9!}
\left(\frac{1}{2}\right)^1 \left(1-\frac{1}{2}\right)^{9} = 0.0098\]

\[x=2 ; \frac{10!}{2! 8!}\left(\frac{1}{2}\right)^2 \left(1-\frac{1}{2}\right)^{8} = 0.0439\]

<center>⋮</center>

\[x=10 ; \frac{10!}{10! 0!}\left(\frac{1}{2}\right)^{10} \left(1-\frac{1}{2}\right)^{0} = 0.0010\]

<p>If represented as a histogram, it would appear as follows.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/coin distribution.png" />
</p>

<h3 id="an-intuitive-look-at-binomial-distribution">An Intuitive Look at Binomial Distribution</h3>

<p>The binomial distribution is used to calculate the probability of obtaining certain outcomes from repeating a probabilistic event, like flipping a coin, that has two possible results, multiple times.</p>

<p>To understand how it can be applied in practice for a more intuitive comprehension, let’s look into scenarios where the binomial distribution is considered.</p>

<ul>
  <li>Example 1<br />
Suppose a marketing team sends emails to 1,000 customers individually. Based on previous experience, let’s assume the probability of receiving a reply is 0.5. What then is the probability of receiving replies from 50 customers out of the 1,000 emails sent?</li>
</ul>

<p>This is a simple problem of calculating the binomial distribution probability \(P_X(50)\) with \(n=1,000\), \(p=0.5\). The binomial distribution fundamentally <strong>utilizes the number of trials and the fixed probability of success</strong> to calculate the <strong>probability of success occurring</strong>.</p>

<p>Furthermore, the concept of the binomial distribution can be utilized in conducting A/B tests. Consider the example below.</p>

<ul>
  <li>Example 2<br />
Let’s assume an A/B test is conducted to compare the effectiveness of two designs (A and B) in increasing the click-through rate on a website. Suppose design B was shown to 1,000 visitors to the website, and 150 clicked on it. We want to assess whether the click-through rate for design B is statistically significantly different from a 10% click-through rate for design A.</li>
</ul>

<p>Assuming the independence of each visitor’s click action, the action of clicking by each website visitor results in a binomial outcome of click (success) or no click (failure). With the success probability \(p\) set to 10%, the number of trials \(n\) to 1,000, and the number of successes to 150, we can perform a binomial test.</p>

<h2 id="mean-and-variance-of-binomial-distribution">Mean and Variance of Binomial Distribution</h2>
<p>For a random variable \(X\) following a binomial distribution with a total number of trials \(n\) and a success probability \(p\),</p>

<p>the mean are</p>

\[E(X) = np\]

<p>and the variance are</p>

\[Var(X) = np(1-p)\]

<p>The proofs for each are as follows:</p>

<p>\(\begin{split}
\begin{align}
\begin{aligned}
\text{E}[X] 
&amp;= \sum_{x_i \in \Omega} x_i p(x_i) \\
&amp;= 1 \cdot \mu + 0 \cdot (1 - \mu) \\
&amp;= \mu
\end{aligned}
\end{align}
\end{split}\)
<br /></p>

\[\begin{split}
\begin{align}
\begin{aligned}
\text{Var}[X] 
&amp;= \sum_{x_i \in \Omega} (x_i - \mu)^2 p(x_i) \\
&amp;= (1 - \mu)^2 \cdot \mu + (0 - \mu)^2 \cdot (1 - \mu) \\
&amp;= \mu(1-\mu)
\end{aligned}
\end{align}
\end{split}\]

<h2 id="the-normal-approximation-to-the-binomial-distribution">The Normal Approximation to the Binomial Distribution</h2>
<p>As we adjust the parameters of the binomial distribution, let’s explore the various shapes it can exhibit. There are numerous simulatiors accessible online for this purpose, such as the “Parameters of the Binomial Distribution” simulation by shanlee on GeoGebra.
What transformation does the binomial distribution undergo as \(n\), the number of trials, continues to increase?</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/binomial distribution to normal distribution.png" />
</p>

<p>When conducting 50 coin flips, one can observe that the resulting distribution resembles the <strong>bell shape</strong> of a normal distribution. However, by operating the simulation directly, it’s discernible that this approximation is <strong>only feasible when the values of \(n\) and \(p\) are not extreme</strong>. If \(n\) is too small, or if \(n\) is sufficiently large but \(p\) is too small or too large, the shape deviates significantly from that of a normal distribution.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/small n.png" />
</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/small p.png" />
</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/huge p.png" />
</p>

<p>Mathetically, if the number of trials \(n\) in a binomial distribution is sufficiently large such that \(np≥5\) and \(np(1−p)≥5\), then the binomial distribution can be approximated by a normal distribution with mean \(np\) and variance \(np(1−p)\). This can be intuitively understood through simulation. Directly operating the simulation reveals that the approximation to a normal distribution becomes <strong>more accurate as \(n\) increases, and as \(p\) is not too close to 0 or 1 but closer to 0.5</strong>.</p>

<p>How many hits might a baseball player with a .300 batting average get in 100 at-bats? How many people might actually die if 100 people were infected with a disease with a 30% mortality rate? Many real-world events can be said to follow a binomial distribution. If the normal distribution can represent an approximation of the binomial distribution, then the normal distribution can also describe many events.</p>

<p><br /><br />
<strong>References</strong></p>

<p><a href="https://www.geogebra.org/m/hGkW4vwJ">Parameters of the Binomial Distribution(shanlee)</a><br />
<a href="https://datascienceschool.net/02%20mathematics/08.02%20%EB%B2%A0%EB%A5%B4%EB%88%84%EC%9D%B4%EB%B6%84%ED%8F%AC%EC%99%80%20%EC%9D%B4%ED%95%AD%EB%B6%84%ED%8F%AC.html">데이터 사이언스 스쿨</a><br />
<a href="https://bookdown.org/mathemedicine/Stat_book/normal-distribution.html#-1">기초통계 개념정리(김진섭)</a><br /></p>]]></content><author><name>Jenny Won (Dajeong Won)</name></author><category term="Statistics" /><summary type="html"><![CDATA[Before diving into the binomial distribution, let’s briefly summarize the Bernoulli distribution and explore its relationship with the binomial distribution. Bernoulli Distribution A Bernoulli experiment refers to a probability experiment where the outcome can either be a success or a failure. The probability distribution that represents the number of successes in a Bernoulli experiment, with a fixed success probability \(p\), is known as the Bernoulli distribution. Therefore, the Bernoulli distribution is a probability distribution where the value of the random variable is either a success or a failure. Since the outcome can only be one of two values, success or failure, a Bernoulli random variable is classified as a discrete random variable. one where the outcome can either be a success or a failure. The probability distribution that accounts for the number of successes in a Bernoulli experiment, with a fixed probability of success \(p\), is the Bernoulli distribution. \[x  \{ \text{success, fail} \} \rightarrow \{0, 1\}\] \[\begin{equation} \begin{aligned} &amp; P(x=0) = 1-p \\ &amp; P(x=1) = p \\ \end{aligned} \end{equation}\] If the random variable \(X\) follows a Bernoulli distribution, it can be expressed as follows: \[\begin{equation}   \begin{aligned}  &amp; x \sim \text{Bern}(p) \end{aligned}    \end{equation}\] And its Probability Mass Function (PMF) can be represented by the following formula: \[\begin{split} \begin{align} \text{Bern}(x; p) = \begin{cases} p &amp; \text{if }x=1, \\ 1-p &amp; \text{if }x=0 \end{cases} \tag{8.2.2} \end{align} \end{split}\] It is important to note that the Bernoulli distribution focuses on observational data from the result of a single trial, emphasizing the probability of success \(p\). This aspect explains how the binomial distribution differs from the Bernoulli distribution. Definition of Binomial Distribution DEFINITION The Binomial Distribution models the number of successes in a fixed number \(n\) of repeated Bernoulli trials, each with the same success probability \(p\). The binomial distribution is the probability distribution obtained by repeating a Bernoulli trial \(n\) times. In other words, the binomial distribution is an extension of the Bernoulli trial. It models the probability distribution of the number of successes in \(n\) repeated Bernoulli trials, not just a single Bernoulli trial. For example, consider the example of flipping a coin. When you perform a single coin toss with the probability of getting heads being \(p=1/2\); the outcome follows a Bernoulli distribution. However, if the same coin is flipped 10 times, and the number of times heads appears is observed, this scenario follows a binomial distribution. The key here is that during the 10 flips, each flip is independent, and the probability of success for each trial remains constant at \(p\) (as is the case with a fixed \(p\) in a Bernoulli trial). The binomial distribution can be expressed as follows, \(\begin{equation}   \begin{aligned}  x \sim \text{Bin}(n,p) \end{aligned}    \end{equation}\) ans its Probability Mass Function (PMF) is defined as follows. \[\begin{equation}  P_X(x) = \ _{n}C_{x} p^k (1-p)^{n-x} \quad \text{ for } x =0,1,\cdots,n \end{equation}\] Real Insights into the Binomial Distribution Example of Flipping a Coin 10 Times To grasp the Probability Mass Function, let’s calculate the probability of outcomes in the scenario of flipping a coin 10 times. Consider a success as the coin landing on heads, and let \(x\) be the number of successes. Thus, \(x=0,1,2,⋯,10\), representing the scenarios where the coin lands on heads 0 times, 1 time, 2 times, … up to 10 times. Let’s consider the probability when \(x=2\), that is, the probability of the coin landing on heads 2 times in 10 flips. As illustrated, each independent event of the coin landing on heads 2 times out of 10 flips has a probability of \((\frac{1}{2})^2(1-\frac{1}{2})^{8}\). This can occur in \(_{10}C_{2}\) different ways. The calculation is as follows: \[_{10}C_{2}\left(\frac{1}{2}\right)^2 \left(1-\frac{1}{2}\right)^{8} = 0.0439\] Using the same method, calculating the probabilities for all values of \(x\) yields the following results: \[x=0 ; \frac{10!}{1!\cdot9!} \left(\frac{1}{2}\right)^0 \left(1-\frac{1}{2}\right)^{10} = 0.0010\] \[x=1 ; \frac{10!}{1!\cdot9!} \left(\frac{1}{2}\right)^1 \left(1-\frac{1}{2}\right)^{9} = 0.0098\] \[x=2 ; \frac{10!}{2! 8!}\left(\frac{1}{2}\right)^2 \left(1-\frac{1}{2}\right)^{8} = 0.0439\] ⋮ \[x=10 ; \frac{10!}{10! 0!}\left(\frac{1}{2}\right)^{10} \left(1-\frac{1}{2}\right)^{0} = 0.0010\] If represented as a histogram, it would appear as follows. An Intuitive Look at Binomial Distribution The binomial distribution is used to calculate the probability of obtaining certain outcomes from repeating a probabilistic event, like flipping a coin, that has two possible results, multiple times. To understand how it can be applied in practice for a more intuitive comprehension, let’s look into scenarios where the binomial distribution is considered. Example 1 Suppose a marketing team sends emails to 1,000 customers individually. Based on previous experience, let’s assume the probability of receiving a reply is 0.5. What then is the probability of receiving replies from 50 customers out of the 1,000 emails sent? This is a simple problem of calculating the binomial distribution probability \(P_X(50)\) with \(n=1,000\), \(p=0.5\). The binomial distribution fundamentally utilizes the number of trials and the fixed probability of success to calculate the probability of success occurring. Furthermore, the concept of the binomial distribution can be utilized in conducting A/B tests. Consider the example below. Example 2 Let’s assume an A/B test is conducted to compare the effectiveness of two designs (A and B) in increasing the click-through rate on a website. Suppose design B was shown to 1,000 visitors to the website, and 150 clicked on it. We want to assess whether the click-through rate for design B is statistically significantly different from a 10% click-through rate for design A. Assuming the independence of each visitor’s click action, the action of clicking by each website visitor results in a binomial outcome of click (success) or no click (failure). With the success probability \(p\) set to 10%, the number of trials \(n\) to 1,000, and the number of successes to 150, we can perform a binomial test. Mean and Variance of Binomial Distribution For a random variable \(X\) following a binomial distribution with a total number of trials \(n\) and a success probability \(p\), the mean are \[E(X) = np\] and the variance are \[Var(X) = np(1-p)\] The proofs for each are as follows: \(\begin{split} \begin{align} \begin{aligned} \text{E}[X] &amp;= \sum_{x_i \in \Omega} x_i p(x_i) \\ &amp;= 1 \cdot \mu + 0 \cdot (1 - \mu) \\ &amp;= \mu \end{aligned} \end{align} \end{split}\) \[\begin{split} \begin{align} \begin{aligned} \text{Var}[X] &amp;= \sum_{x_i \in \Omega} (x_i - \mu)^2 p(x_i) \\ &amp;= (1 - \mu)^2 \cdot \mu + (0 - \mu)^2 \cdot (1 - \mu) \\ &amp;= \mu(1-\mu) \end{aligned} \end{align} \end{split}\] The Normal Approximation to the Binomial Distribution As we adjust the parameters of the binomial distribution, let’s explore the various shapes it can exhibit. There are numerous simulatiors accessible online for this purpose, such as the “Parameters of the Binomial Distribution” simulation by shanlee on GeoGebra. What transformation does the binomial distribution undergo as \(n\), the number of trials, continues to increase? When conducting 50 coin flips, one can observe that the resulting distribution resembles the bell shape of a normal distribution. However, by operating the simulation directly, it’s discernible that this approximation is only feasible when the values of \(n\) and \(p\) are not extreme. If \(n\) is too small, or if \(n\) is sufficiently large but \(p\) is too small or too large, the shape deviates significantly from that of a normal distribution. Mathetically, if the number of trials \(n\) in a binomial distribution is sufficiently large such that \(np≥5\) and \(np(1−p)≥5\), then the binomial distribution can be approximated by a normal distribution with mean \(np\) and variance \(np(1−p)\). This can be intuitively understood through simulation. Directly operating the simulation reveals that the approximation to a normal distribution becomes more accurate as \(n\) increases, and as \(p\) is not too close to 0 or 1 but closer to 0.5. How many hits might a baseball player with a .300 batting average get in 100 at-bats? How many people might actually die if 100 people were infected with a disease with a 30% mortality rate? Many real-world events can be said to follow a binomial distribution. If the normal distribution can represent an approximation of the binomial distribution, then the normal distribution can also describe many events. References Parameters of the Binomial Distribution(shanlee) 데이터 사이언스 스쿨 기초통계 개념정리(김진섭)]]></summary></entry><entry xml:lang="ko"><title type="html">이항 분포</title><link href="http://localhost:4000/2024/03/27/binomial_distribution_ko.html" rel="alternate" type="text/html" title="이항 분포" /><published>2024-03-27T00:00:00+09:00</published><updated>2024-03-27T00:00:00+09:00</updated><id>http://localhost:4000/2024/03/27/binomial_distribution_ko</id><content type="html" xml:base="http://localhost:4000/2024/03/27/binomial_distribution_ko.html"><![CDATA[<p>이항 분포에 앞서, 베르누이 분포에 대해 간략히 정리하고, 이항 분포와 베르누이 분포가 어떤 관계가 있는지 알아보자.</p>
<h2 id="베르누이-분포">베르누이 분포</h2>
<p>확률 실험의 결과가 성공 혹은 실패로 나타나는 실험을 베르누이 실험(Bernoulli Experiment)라고 한다. 그리고 성공 확률이 \(p\)로 고정된 베르누이 실험에서 성공의 횟수를 나타내는 확률 분포가 바로 <strong>베르누이 분포</strong>이다. 즉, 베르누이 분포는 <strong>확률 변수의 값이 성공 혹은 실패로 나타나는 확률 분포</strong>이며, 그 결과가 성공 혹은 실패, 두 값 중 하나만 가지므로 베르누이 확률 변수는 <strong>이산 확률 변수</strong>라고 할 수 있다.</p>

\[x  \{ \text{success, fail} \} \rightarrow \{0, 1\}\]

\[\begin{equation}
\begin{aligned}
&amp; P(x=0) = 1-p \\
&amp; P(x=1) = p \\ \end{aligned}
\end{equation}\]

<p>확률 변수 \(X\)가 베르누이 분포에 의해 발생된다면 다음과 같이 표현할 수 있다.</p>

\[\begin{equation} 
 \begin{aligned} 
&amp; x \sim \text{Bern}(p)
\end{aligned}   
\end{equation}\]

<p>그리고 그 확률 질량 함수(PMF)는 다음과 같이 수식으로 나타낼 수 있다. 
\(\begin{split}
\begin{align}
\text{Bern}(x; p) = 
\begin{cases} 
p   &amp; \text{if }x=1, \\
1-p &amp; \text{if }x=0
\end{cases}
\tag{8.2.2}
\end{align}
\end{split}\)</p>

<p>여기서 주목해야 할 점은, 베르누이 분포는 <strong>한번의 시행</strong>에 대한 결과에서 <strong>성공 확률 \(p\)</strong>에 집중한 관찰 데이터라는 점이다. 이 점은 이항 분포가 베르누이 분포와 어떻게 다른지를 설명하게 된다.</p>

<h2 id="이항-분포의-정의">이항 분포의 정의</h2>

<table>
  <thead>
    <tr>
      <th>DEFINITION</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>이항 분포(Binomial Distribution)</strong>은 동일한 확률 \(p\) 로 성공하는 베르누이 시행을 고정된 수 \(n\) 번을 반복할 때의 성공 횟수를 모델링하는 확률 분포이다.</td>
    </tr>
  </tbody>
</table>

<p>이항 분포는 베르누이 시행을 \(n\)번 반복하여 얻게된 확률 분포이다. 다시말해, <strong>이항분포는 베르누이 시행의 확장</strong>이라고 할 수 있다. 단 한 번의 베르누이 시행이 아닌, \(n\)번의 반복된 베르누이 시행에서 성공 횟수에 대한 확률 분포를 모델링한 것이 바로 이항 분포이다.
동전 던지기의 예를 들어보자. 앞면이 나올 확률이 \(p=1/2\)인 동전 던지기를 한번 시행 했을때, 그 결과는 베르누이 분포를 따르게 된다. 하지만 동일한 동전을 10번 던지고 앞면이 나온 횟수를 관찰하는 경우, 이 시나리오는 이항 분포를 따르게 된다. 여기서 핵심은 10번 던지는 동안 <strong>각각의 던지기가 독립적이며, 각 시행의 성공 확률은 \(p\) 로 동일해야 한다</strong>는 점이다.(원래 베르누이 시행의 성공확률은 고정된 \(p\)를 갖는다.)</p>

<p>이항 분포는 다음과 같이 표현할 수 있으며,</p>

\[\begin{equation} 
 \begin{aligned} 
x \sim \text{Bin}(n,p)
\end{aligned}   
\end{equation}\]

<p>이항 분포의 확률 질량 함수(PMF)는 다음과 같이 정의된다.</p>

\[\begin{equation} 
P_X(x) = \ _{n}C_{x} p^k (1-p)^{n-x} \quad \text{ for } x =0,1,\cdots,n
\end{equation}\]

<h2 id="이항-분포의-이해">이항 분포의 이해</h2>
<h3 id="10번의-동전-던지기-예시">10번의 동전 던지기 예시</h3>
<p>확률 질량 함수를 이해하기 위해서, 앞선 10번의 동전 던지기의 확률을 직접 구해보자.
앞면이 나오는 경우를 성공이라 하고, \(x\)를 성공 횟수라고 하자. 즉, \(x = 0, 1, 2, \cdots, 10\) 이고, 각각은 앞면이 0번, 1번, 2번, … 10번 나오는 경우를 의미할 것이다. \(x=2\)일 떄, 즉 10번의 시행 중 동전의 앞면이 2번 나오는 확률을 생각해 보자.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/coin k=2.png" />
</p>

<p>그림과 같이 각각의 독립된 \((\frac{1}{2})^2(1-\frac{1}{2})^{8}\)의 확률이 \( _{10}C_{2}\)의 경우의 수로 출현할 수 있다. 이것은 다음과 같이 계산된다.</p>

\[_{10}C_{2}\left(\frac{1}{2}\right)^2 \left(1-\frac{1}{2}\right)^{8} = 0.0439\]

<p>같은 방법으로, 모든 x에 대해서 그 확률을 계산해 보면 다음과 같다.</p>

\[x=0 ;  \frac{10!}{1!\cdot9!}
\left(\frac{1}{2}\right)^0 \left(1-\frac{1}{2}\right)^{10} = 0.0010\]

\[x=1 ;  \frac{10!}{1!\cdot9!}
\left(\frac{1}{2}\right)^1 \left(1-\frac{1}{2}\right)^{9} = 0.0098\]

\[x=2 ; \frac{10!}{2! 8!}\left(\frac{1}{2}\right)^2 \left(1-\frac{1}{2}\right)^{8} = 0.0439\]

<center>⋮</center>

\[x=10 ; \frac{10!}{10! 0!}\left(\frac{1}{2}\right)^{10} \left(1-\frac{1}{2}\right)^{0} = 0.0010\]

<p>이것을 히스토그램으로 나타내면 다음과 같다.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/coin distribution.png" />
</p>

<h3 id="직관적-이항-분포">직관적 이항 분포</h3>
<p>이항 분포는 동전 던지기처럼 두 가지 결과가 있는 확률적 사건을 몇 번 반복했을 때, 어떤 결과를 얻을 확률을 구하기 위해 사용된다.</p>

<p>실제로 어떻게 활용될 수 있는 지, 보다 직관적인 이해를 위해 실제로 이항 분포의 활용이 고려되는 알아보자.</p>

<ul>
  <li>예시 1<br />
마케팅 팀에서 1,000명의 고객에게 메일을 각각 발송했다. 이전의 경험을 토대로 회신을 받을 수 있는 확률이 0.5라고 가정하자. 자, 발송된 1,000개의 메일에 대해 50명의 고객으로 부터 회신을 받을 확률은 어떻게 될까?</li>
</ul>

<p>아주 간단한 \(n=1,000\), \(p=0.5\)인 이항 분포의 확률 \(P_X(50)\)을 구하는 문제이다.
이처럼 이항 분포는 기본적으로 <strong>시행 횟수와 성공 확률이 고정</strong>되었을 때, <strong>성공이 출현할 확률</strong>을 구할 때 활용될 수 있다.</p>

<p>또한, A/B테스를 진행하며 이항 분포의 개념이 활용될 수 있다. 아래 예시를 보자.</p>
<ul>
  <li>예시 2<br />
웹사이트의 버튼 클릭률을 높이기 위해 두 가지 디자인(A와 B)의 효과를 비교하는 A/B테스트를 수행한다고 가정해 보자. 웹사이트 방문자 1,000명에게 B디자인을 노출시킨 후, 150명이 클릭했다. 우리는 디자인 B의 클릭률이 디자인 A의 클릭률 10%와 통계적으로 유의미하게 다른지를 평가하고자 한다.</li>
</ul>

<p>방문자의 클릭 여부가 독립이라는 가정 하에, 각 웹사이트 방문자가 클릭하는 행위는 클릭(성공) 또는 비클릭(실패)의 이항 결과를 갖는다. 우리는 성공 확률 p를 10%, 시도 횟수 n은 1,000명, 성공 횟수 150명으로 설정하고 이항 검정을 수행할 수 있다.</p>

<h2 id="이항-분포의-평균과-분산">이항 분포의 평균과 분산</h2>
<p>총 시행 횟수가 \(n\), 성공 확률이 \(p\)인 이항 분포를 따르는 확률 변수 X에 대해,</p>

<p>기댓값은</p>

\[E(X) = np\]

<p>분산은</p>

\[Var(X) = np(1-p)\]

<p>이다. 각각의 증명은 다음과 같다.</p>

<p>\(\begin{split}
\begin{align}
\begin{aligned}
\text{E}[X] 
&amp;= \sum_{x_i \in \Omega} x_i p(x_i) \\
&amp;= 1 \cdot \mu + 0 \cdot (1 - \mu) \\
&amp;= \mu
\end{aligned}
\end{align}
\end{split}\)
<br /></p>

\[\begin{split}
\begin{align}
\begin{aligned}
\text{Var}[X] 
&amp;= \sum_{x_i \in \Omega} (x_i - \mu)^2 p(x_i) \\
&amp;= (1 - \mu)^2 \cdot \mu + (0 - \mu)^2 \cdot (1 - \mu) \\
&amp;= \mu(1-\mu)
\end{aligned}
\end{align}
\end{split}\]

<h2 id="이항-분포의-정규-분포-근사">이항 분포의 정규 분포 근사</h2>
<p>자, 그럼 이항 분포의 파라미터를 자유롭게 변경하며 이항 분포의 여러 모양을 관찰해 보자. 
이러한 결과를 쉽게 확인할 수 있는 다양한 시뮬레이션이 온라인에 공개되어 있고, 그 중  GeoGebra에서 Parameters of the Binomial Distribution(shanlee) 시뮬레이션을 활용했다.
n이 계속 증가한다면, 즉 시행을 많이 한다면 이항 분포는 어떻게 변할까?</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/binomial distribution to normal distribution.png" />
</p>

<p>50번의 동전 던지기를 시행했을 때 <strong>종모양(bell shape)</strong>의 정규 분포와 유사한 형태를 띄는 것을 확인할 수 있다. 하지만 시뮬레이션을 직접 작동해보면, <strong>$n$ 과 $p$ 의 값이 극단적이지 않은 경우에만 가능</strong>하다는 것을 알 수 있다. $n$ 이 너무 작거나, $n$ 이 충분히 크지만 $p$ 가 너무 작거나 클 경우 정규 분포의 모양과 많이 벗어나게 된다.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/small n.png" />
</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/small p.png" />
</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/huge p.png" />
</p>

<p>수학적으로 이항 분포의 $n$ 이 충분히 커서 $np&gt;=5$, $np(1-p)&gt;=5$ 조건을 만족하면, 이항 분포의 평균이 $np$, 분산이 $np(1-p)$ 인 정규 분포에 근사할 수 있다고 한다. 이는 실제로 시뮬레이션을 통해 직관적으로 이해할 수 있다. 시뮬레이션을 직접 작동해 보면, <strong>$n$ 이 클수록, $p$ 가 0이나 1에 가깝지 않고, 0.5에 가까울수록 정규 분포로의 근사가 더욱 정확</strong>해지는 것을 확인할 수 있다.</p>

<p>타율 3할인 타자가 100번 타석에 들어서면 안타를 얼마나 칠까? 사망률이 30%인 감염병에 100명이 걸렸을 때 실제로 얼마나 사망할까? 등 실제 많은 사건들 이항 분포를 따른다고 할 수 있다. 정규 분포가 이항 분포의 근사값으로 표현된다면 정규 분포 역시 많은 사건을 설명할 수 있는 분포가 될 것이다.</p>

<p><br /><br />
<strong>참조</strong></p>

<p><a href="https://www.geogebra.org/m/hGkW4vwJ">Parameters of the Binomial Distribution(shanlee)</a><br />
<a href="https://datascienceschool.net/02%20mathematics/08.02%20%EB%B2%A0%EB%A5%B4%EB%88%84%EC%9D%B4%EB%B6%84%ED%8F%AC%EC%99%80%20%EC%9D%B4%ED%95%AD%EB%B6%84%ED%8F%AC.html">데이터 사이언스 스쿨</a><br />
<a href="https://bookdown.org/mathemedicine/Stat_book/normal-distribution.html#-1">기초통계 개념정리(김진섭)</a><br /></p>]]></content><author><name>Jenny Won (Dajeong Won)</name></author><category term="통계학" /><summary type="html"><![CDATA[이항 분포에 앞서, 베르누이 분포에 대해 간략히 정리하고, 이항 분포와 베르누이 분포가 어떤 관계가 있는지 알아보자. 베르누이 분포 확률 실험의 결과가 성공 혹은 실패로 나타나는 실험을 베르누이 실험(Bernoulli Experiment)라고 한다. 그리고 성공 확률이 \(p\)로 고정된 베르누이 실험에서 성공의 횟수를 나타내는 확률 분포가 바로 베르누이 분포이다. 즉, 베르누이 분포는 확률 변수의 값이 성공 혹은 실패로 나타나는 확률 분포이며, 그 결과가 성공 혹은 실패, 두 값 중 하나만 가지므로 베르누이 확률 변수는 이산 확률 변수라고 할 수 있다. \[x  \{ \text{success, fail} \} \rightarrow \{0, 1\}\] \[\begin{equation} \begin{aligned} &amp; P(x=0) = 1-p \\ &amp; P(x=1) = p \\ \end{aligned} \end{equation}\] 확률 변수 \(X\)가 베르누이 분포에 의해 발생된다면 다음과 같이 표현할 수 있다. \[\begin{equation}   \begin{aligned}  &amp; x \sim \text{Bern}(p) \end{aligned}    \end{equation}\] 그리고 그 확률 질량 함수(PMF)는 다음과 같이 수식으로 나타낼 수 있다. \(\begin{split} \begin{align} \text{Bern}(x; p) = \begin{cases} p &amp; \text{if }x=1, \\ 1-p &amp; \text{if }x=0 \end{cases} \tag{8.2.2} \end{align} \end{split}\) 여기서 주목해야 할 점은, 베르누이 분포는 한번의 시행에 대한 결과에서 성공 확률 \(p\)에 집중한 관찰 데이터라는 점이다. 이 점은 이항 분포가 베르누이 분포와 어떻게 다른지를 설명하게 된다. 이항 분포의 정의 DEFINITION 이항 분포(Binomial Distribution)은 동일한 확률 \(p\) 로 성공하는 베르누이 시행을 고정된 수 \(n\) 번을 반복할 때의 성공 횟수를 모델링하는 확률 분포이다. 이항 분포는 베르누이 시행을 \(n\)번 반복하여 얻게된 확률 분포이다. 다시말해, 이항분포는 베르누이 시행의 확장이라고 할 수 있다. 단 한 번의 베르누이 시행이 아닌, \(n\)번의 반복된 베르누이 시행에서 성공 횟수에 대한 확률 분포를 모델링한 것이 바로 이항 분포이다. 동전 던지기의 예를 들어보자. 앞면이 나올 확률이 \(p=1/2\)인 동전 던지기를 한번 시행 했을때, 그 결과는 베르누이 분포를 따르게 된다. 하지만 동일한 동전을 10번 던지고 앞면이 나온 횟수를 관찰하는 경우, 이 시나리오는 이항 분포를 따르게 된다. 여기서 핵심은 10번 던지는 동안 각각의 던지기가 독립적이며, 각 시행의 성공 확률은 \(p\) 로 동일해야 한다는 점이다.(원래 베르누이 시행의 성공확률은 고정된 \(p\)를 갖는다.) 이항 분포는 다음과 같이 표현할 수 있으며, \[\begin{equation}   \begin{aligned}  x \sim \text{Bin}(n,p) \end{aligned}    \end{equation}\] 이항 분포의 확률 질량 함수(PMF)는 다음과 같이 정의된다. \[\begin{equation}  P_X(x) = \ _{n}C_{x} p^k (1-p)^{n-x} \quad \text{ for } x =0,1,\cdots,n \end{equation}\] 이항 분포의 이해 10번의 동전 던지기 예시 확률 질량 함수를 이해하기 위해서, 앞선 10번의 동전 던지기의 확률을 직접 구해보자. 앞면이 나오는 경우를 성공이라 하고, \(x\)를 성공 횟수라고 하자. 즉, \(x = 0, 1, 2, \cdots, 10\) 이고, 각각은 앞면이 0번, 1번, 2번, … 10번 나오는 경우를 의미할 것이다. \(x=2\)일 떄, 즉 10번의 시행 중 동전의 앞면이 2번 나오는 확률을 생각해 보자. 그림과 같이 각각의 독립된 \((\frac{1}{2})^2(1-\frac{1}{2})^{8}\)의 확률이 \( _{10}C_{2}\)의 경우의 수로 출현할 수 있다. 이것은 다음과 같이 계산된다. \[_{10}C_{2}\left(\frac{1}{2}\right)^2 \left(1-\frac{1}{2}\right)^{8} = 0.0439\] 같은 방법으로, 모든 x에 대해서 그 확률을 계산해 보면 다음과 같다. \[x=0 ; \frac{10!}{1!\cdot9!} \left(\frac{1}{2}\right)^0 \left(1-\frac{1}{2}\right)^{10} = 0.0010\] \[x=1 ; \frac{10!}{1!\cdot9!} \left(\frac{1}{2}\right)^1 \left(1-\frac{1}{2}\right)^{9} = 0.0098\] \[x=2 ; \frac{10!}{2! 8!}\left(\frac{1}{2}\right)^2 \left(1-\frac{1}{2}\right)^{8} = 0.0439\] ⋮ \[x=10 ; \frac{10!}{10! 0!}\left(\frac{1}{2}\right)^{10} \left(1-\frac{1}{2}\right)^{0} = 0.0010\] 이것을 히스토그램으로 나타내면 다음과 같다. 직관적 이항 분포 이항 분포는 동전 던지기처럼 두 가지 결과가 있는 확률적 사건을 몇 번 반복했을 때, 어떤 결과를 얻을 확률을 구하기 위해 사용된다. 실제로 어떻게 활용될 수 있는 지, 보다 직관적인 이해를 위해 실제로 이항 분포의 활용이 고려되는 알아보자. 예시 1 마케팅 팀에서 1,000명의 고객에게 메일을 각각 발송했다. 이전의 경험을 토대로 회신을 받을 수 있는 확률이 0.5라고 가정하자. 자, 발송된 1,000개의 메일에 대해 50명의 고객으로 부터 회신을 받을 확률은 어떻게 될까? 아주 간단한 \(n=1,000\), \(p=0.5\)인 이항 분포의 확률 \(P_X(50)\)을 구하는 문제이다. 이처럼 이항 분포는 기본적으로 시행 횟수와 성공 확률이 고정되었을 때, 성공이 출현할 확률을 구할 때 활용될 수 있다. 또한, A/B테스를 진행하며 이항 분포의 개념이 활용될 수 있다. 아래 예시를 보자. 예시 2 웹사이트의 버튼 클릭률을 높이기 위해 두 가지 디자인(A와 B)의 효과를 비교하는 A/B테스트를 수행한다고 가정해 보자. 웹사이트 방문자 1,000명에게 B디자인을 노출시킨 후, 150명이 클릭했다. 우리는 디자인 B의 클릭률이 디자인 A의 클릭률 10%와 통계적으로 유의미하게 다른지를 평가하고자 한다. 방문자의 클릭 여부가 독립이라는 가정 하에, 각 웹사이트 방문자가 클릭하는 행위는 클릭(성공) 또는 비클릭(실패)의 이항 결과를 갖는다. 우리는 성공 확률 p를 10%, 시도 횟수 n은 1,000명, 성공 횟수 150명으로 설정하고 이항 검정을 수행할 수 있다. 이항 분포의 평균과 분산 총 시행 횟수가 \(n\), 성공 확률이 \(p\)인 이항 분포를 따르는 확률 변수 X에 대해, 기댓값은 \[E(X) = np\] 분산은 \[Var(X) = np(1-p)\] 이다. 각각의 증명은 다음과 같다. \(\begin{split} \begin{align} \begin{aligned} \text{E}[X] &amp;= \sum_{x_i \in \Omega} x_i p(x_i) \\ &amp;= 1 \cdot \mu + 0 \cdot (1 - \mu) \\ &amp;= \mu \end{aligned} \end{align} \end{split}\) \[\begin{split} \begin{align} \begin{aligned} \text{Var}[X] &amp;= \sum_{x_i \in \Omega} (x_i - \mu)^2 p(x_i) \\ &amp;= (1 - \mu)^2 \cdot \mu + (0 - \mu)^2 \cdot (1 - \mu) \\ &amp;= \mu(1-\mu) \end{aligned} \end{align} \end{split}\] 이항 분포의 정규 분포 근사 자, 그럼 이항 분포의 파라미터를 자유롭게 변경하며 이항 분포의 여러 모양을 관찰해 보자. 이러한 결과를 쉽게 확인할 수 있는 다양한 시뮬레이션이 온라인에 공개되어 있고, 그 중 GeoGebra에서 Parameters of the Binomial Distribution(shanlee) 시뮬레이션을 활용했다. n이 계속 증가한다면, 즉 시행을 많이 한다면 이항 분포는 어떻게 변할까? 50번의 동전 던지기를 시행했을 때 종모양(bell shape)의 정규 분포와 유사한 형태를 띄는 것을 확인할 수 있다. 하지만 시뮬레이션을 직접 작동해보면, $n$ 과 $p$ 의 값이 극단적이지 않은 경우에만 가능하다는 것을 알 수 있다. $n$ 이 너무 작거나, $n$ 이 충분히 크지만 $p$ 가 너무 작거나 클 경우 정규 분포의 모양과 많이 벗어나게 된다. 수학적으로 이항 분포의 $n$ 이 충분히 커서 $np&gt;=5$, $np(1-p)&gt;=5$ 조건을 만족하면, 이항 분포의 평균이 $np$, 분산이 $np(1-p)$ 인 정규 분포에 근사할 수 있다고 한다. 이는 실제로 시뮬레이션을 통해 직관적으로 이해할 수 있다. 시뮬레이션을 직접 작동해 보면, $n$ 이 클수록, $p$ 가 0이나 1에 가깝지 않고, 0.5에 가까울수록 정규 분포로의 근사가 더욱 정확해지는 것을 확인할 수 있다. 타율 3할인 타자가 100번 타석에 들어서면 안타를 얼마나 칠까? 사망률이 30%인 감염병에 100명이 걸렸을 때 실제로 얼마나 사망할까? 등 실제 많은 사건들 이항 분포를 따른다고 할 수 있다. 정규 분포가 이항 분포의 근사값으로 표현된다면 정규 분포 역시 많은 사건을 설명할 수 있는 분포가 될 것이다. 참조 Parameters of the Binomial Distribution(shanlee) 데이터 사이언스 스쿨 기초통계 개념정리(김진섭)]]></summary></entry><entry xml:lang="en"><title type="html">Probability Distribution</title><link href="http://localhost:4000/2024/03/26/random_variables_en.html" rel="alternate" type="text/html" title="Probability Distribution" /><published>2024-03-26T00:00:00+09:00</published><updated>2024-03-26T00:00:00+09:00</updated><id>http://localhost:4000/2024/03/26/random_variables_en</id><content type="html" xml:base="http://localhost:4000/2024/03/26/random_variables_en.html"><![CDATA[<p>A simple explanation of a random variable is that it connects <strong><u>the outcome</u> of <u>a random preocess</u> to a number</strong>. A common example is flipping a coin. Flipping a coin 5 times at random and the total number of heads obtained can be considered a random variable. Understanding that flipping a coin 5 times is a random process is not difficult, making it an intuitive concept. So, what does it mean to connect such results to a number?</p>

<p>To understand this, let’s discuss ‘magnitude or scale’ from a mathematical perspective. The outcome of random processes, like rolling dice, carries uncertainty. Can we mathematically express the ‘how much’ of this uncertainty? If the outcome is expressed numerically, it would allow for the most intuitive interpretation. What if it could even be operated on?… From this approach, we can appreciate the value of defining a random variable. In fact, this level of understanding might be sufficient. However, for those who wish to delve deeper into academic study, we can explore the concept of a random variable more mathematically.</p>

<p><br /></p>
<h2 id="mathematical-approach">Mathematical Approach</h2>
<p>To delve into the concept of a random variable as defined in probability theory, it’s necessary to start with some foundational concepts. Although this requires a deep mathematical understanding, I will attempt to approach it in as intuitive a manner as possible. Let’s approach the mathematical definition of a random variable step by step</p>

<h3 id="measure-theory">Measure Theory</h3>
<p>To grasp the concept of measure, let’s first imagine <strong>“a scenario where a cap is filled with water”.</strong></p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/random_variables/water_glass.jpeg" />
</p>

<p><br />To answer the question “How much water is in the cup?”, we <u>define and measure 'volume'</u>. If we assign a ‘volume’ to a certain set, such as a three-dimentional object, it means we are <u>assigning a concept of 'size' to that set</u>. This concept is referred to as <strong>measure</strong> in mathematics. Measure theory deals with the generalized concept of measure, including size, area, volume, etc., and is a theory that measures and analyzes the size of sets and functions. This theory plays a crucial role, especially in probability theory and functional analysis, which explains why we frequently encounter sets in our study of probability. <strong>What’s important to note is that the ‘probability’ we discuss prepresents this concept of size as a ‘measure’.</strong> Therefore, we can only truly understand the definition of probability based on measure theory.</p>

<p><br /></p>
<h3 id="probability">Probability</h3>
<p>When we conduct an experiment to obtain results from a certain phenomenon, we achieve what are called realization. This term ‘realization’ might feel unfamiliar. If you think of it as the outcome which is the result of the experiment, it becomes easier to understand. Now, let’s delve into the concept of probability based on measure theory through the example of rolling dice, which is a type of random experiment.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/random_variables/definition_random_variable_1.png" />
</p>

<p><br /> 
In the sample space \(\Omega = \{1,2,3,4,5,6\}\), to mathematically discuss the magnitude of the event (\(\mathcal{F}\)) where a die lands on 2, we utilize a measure called probability, denoted by \(Pr(\cdot)\). Through this definition, we articulate that the probability of the event where the die shows a 2 is \(Pr(2) = \frac{1}{6}\).</p>

\[\begin{equation} 
\begin{aligned} 
&amp; Pr(1) = Pr(2) = Pr(3) = Pr(4) = Pr(5) = Pr(6) = 1/6
\end{aligned} 
\end{equation}\]

<p>In other words, <strong>“probability is a measure for the realization from a random experiment”</strong>, and by using the measure known as probability $Pr(\cdot)$$, we can obtain the measured realization of the size of elements within the space.</p>

<h3 id="sigma-field-mathcalb">\(\sigma\)-field \(\mathcal{B}\)</h3>
<p>To define probability without contradictions by introducing the concept of measure, it’s necessary to precisely define the objects of measurement. This is where the \(\sigma\)-field comes in. A \(\sigma\)-field is defined as a collection of sets that satisfies certain conditions.</p>

<p>(i) $\emptyset \in \mathcal{B}$  <br />
(ii) $A \in \mathcal{B} \Rightarrow A^c \in \mathcal{B}$ <br />
(iii) $A_i \in \mathcal{B} \Rightarrow \cup_{i=1}^{\infty}A_i \in \mathcal{B}$ <br /></p>

<p>(i) It includes the non-empty set, (ii) the complement, and (iii) is closed under countable unions and intersections of sets \(S\), defined as a collection of subsets. Given such a collection of sets, we can define a measurable space, which allows for the consistent definition of measure and probability.</p>

<p><br /></p>
<ul>
  <li><strong>Measure</strong><br />
A measure \(\mu\) is a type of set function in a measurable space \((U, \mathcal{B})\) that assigns elements in \([0,\infty]\) to elements of the \(\sigma\)-field.
\begin{equation} 
\begin{aligned} 
\mu : \mathcal{B} \rightarrow [0, \infty]
\end{aligned} 
\end{equation}
    <ul>
      <li>\(\mu(\emptyset) = 0\): The measure of the empty set is 0.<br /></li>
      <li>For any sequence of mutually exclusive sets \(A_j\), \(A_j\), the measure of their union is equal to the sum of their measures : \(\mu(\cup_{i=1}^{\infty} A_i) = \sum_{i=1}^{\infty} \mu(A_i)\).</li>
    </ul>
  </li>
</ul>

<p><br /></p>
<ul>
  <li><strong>Probability</strong><br />
Probability refers to a normalized measure on the extire set \(U\) such that \(\mu(U)=1\), indicating that the measure satisfies the condition of the total measure of the sample space being 1.</li>
</ul>

<p>Probability can be described as a measure where the total probability across the entire sample space equals 1.</p>

<hr />

<h3 id="definition-of-a-random-variable">Definition of a Random Variable</h3>
<p>Noew, it’s time to examine the definition of a random variable.</p>

<table>
  <thead>
    <tr>
      <th>DEFINITION</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>A random variable</strong> \(x\) is a function defined on the sample space \(\Omega\). This function serves to transform an element of the probability space \((\Omega, \mathcal{F}, P)\) into an element of the Boral measurable space \((\mathbb{R}, \mathcal{B})\) <br /><br />Here, the space created by the set of real numbers is referred to as the BOrel measurable space, and the associated \(\sigma\)-field in this context is termed the Borel set.</td>
    </tr>
  </tbody>
</table>

<details>
<summary>Borel Measurable Space</summary>
<div>

    <p><strong>Borel Measurable Space</strong>: Consists of the set of real numbers \(\mathbb{R}\) and the Borel \(\sigma\) algebra \(\mathcall{B}\). The Borel \(\sigma\)-algebra includes open intervals on the real line and encompasses all sets that can be generated from these intervals. Essentially, this makes it possible to measure events in the commonly dealt with real number space.</p>

  </div>
</details>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/random_variables/definition_random_variable_2.png" />
</p>

<ul>
  <li>\(\Omega\) : Known as the Space, this represents the entire set of possible elements or outcomes.</li>
  <li>\(\mathcal{F}\) : Signifies the subsets of the sample space, referred to as Events.</li>
  <li>\(Pr\) : Acts as the operator that performs measurement, assigning probabilites to elements of the sample space.</li>
</ul>

<p>Through these complex concepts, we conclude that a random variable is essentially a function that transforms an element of the sample space into a real number. By defining this, we become interested in practically applying the probability of a random variable \(x\), denoted as \(Pr(x)\)</p>

<h2 id="types-of-random-variables">Types of Random Variables</h2>

<p>Random variables are broadly classified into discrete and continuous types. A random variable that can take on either a finite number of values or a countably infinite number of values, such as the outcome of rolling a dice or baseball game socres, is called a <strong>discrete random variables</strong>. The Probability Mass Function(PMF) of a discrete random variable can assign a clear probability to each value. On the other hand, a random variable that can take values in a continuous range, such as temperature, stock prices, duration, speed, or measurements of an object’s length, is called a <strong>continuous random variable</strong>. Although the Probability Density Function(PDF) of a continuous random variable cannot assign a probability to each specific value, it can express the probability over a range of values.</p>

<p>Discrete probability distributions include, notably, the binomial distribution, Poisson distribution, and geometric distribution, while continuous probability distributions include the normal distribution, uniform distribution, and exponential distribution. The following outlines the relations among various probability distributions.</p>

<p><br /><br />
<strong>Reference</strong></p>

<p><a href="https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf">Probability and Statistics for Data Science (Carlos Fernandez-Granda)</a><br />
<a href="https://alida.tistory.com/84">ALIDA (Gyubeom Edward Im)</a><br />
<a href="https://jagan-singhh.medium.com/types-of-probability-distributions-9333d18ed817">Types of Probability Distributions (Jagandeep Singh)</a></p>]]></content><author><name>Jenny Won (Dajeong Won)</name></author><category term="Statistics" /><summary type="html"><![CDATA[A simple explanation of a random variable is that it connects the outcome of a random preocess to a number. A common example is flipping a coin. Flipping a coin 5 times at random and the total number of heads obtained can be considered a random variable. Understanding that flipping a coin 5 times is a random process is not difficult, making it an intuitive concept. So, what does it mean to connect such results to a number? To understand this, let’s discuss ‘magnitude or scale’ from a mathematical perspective. The outcome of random processes, like rolling dice, carries uncertainty. Can we mathematically express the ‘how much’ of this uncertainty? If the outcome is expressed numerically, it would allow for the most intuitive interpretation. What if it could even be operated on?… From this approach, we can appreciate the value of defining a random variable. In fact, this level of understanding might be sufficient. However, for those who wish to delve deeper into academic study, we can explore the concept of a random variable more mathematically. Mathematical Approach To delve into the concept of a random variable as defined in probability theory, it’s necessary to start with some foundational concepts. Although this requires a deep mathematical understanding, I will attempt to approach it in as intuitive a manner as possible. Let’s approach the mathematical definition of a random variable step by step Measure Theory To grasp the concept of measure, let’s first imagine “a scenario where a cap is filled with water”. To answer the question “How much water is in the cup?”, we define and measure 'volume'. If we assign a ‘volume’ to a certain set, such as a three-dimentional object, it means we are assigning a concept of 'size' to that set. This concept is referred to as measure in mathematics. Measure theory deals with the generalized concept of measure, including size, area, volume, etc., and is a theory that measures and analyzes the size of sets and functions. This theory plays a crucial role, especially in probability theory and functional analysis, which explains why we frequently encounter sets in our study of probability. What’s important to note is that the ‘probability’ we discuss prepresents this concept of size as a ‘measure’. Therefore, we can only truly understand the definition of probability based on measure theory. Probability When we conduct an experiment to obtain results from a certain phenomenon, we achieve what are called realization. This term ‘realization’ might feel unfamiliar. If you think of it as the outcome which is the result of the experiment, it becomes easier to understand. Now, let’s delve into the concept of probability based on measure theory through the example of rolling dice, which is a type of random experiment. In the sample space \(\Omega = \{1,2,3,4,5,6\}\), to mathematically discuss the magnitude of the event (\(\mathcal{F}\)) where a die lands on 2, we utilize a measure called probability, denoted by \(Pr(\cdot)\). Through this definition, we articulate that the probability of the event where the die shows a 2 is \(Pr(2) = \frac{1}{6}\). \[\begin{equation}  \begin{aligned}  &amp; Pr(1) = Pr(2) = Pr(3) = Pr(4) = Pr(5) = Pr(6) = 1/6 \end{aligned}  \end{equation}\] In other words, “probability is a measure for the realization from a random experiment”, and by using the measure known as probability $Pr(\cdot)$$, we can obtain the measured realization of the size of elements within the space. \(\sigma\)-field \(\mathcal{B}\) To define probability without contradictions by introducing the concept of measure, it’s necessary to precisely define the objects of measurement. This is where the \(\sigma\)-field comes in. A \(\sigma\)-field is defined as a collection of sets that satisfies certain conditions. (i) $\emptyset \in \mathcal{B}$ (ii) $A \in \mathcal{B} \Rightarrow A^c \in \mathcal{B}$ (iii) $A_i \in \mathcal{B} \Rightarrow \cup_{i=1}^{\infty}A_i \in \mathcal{B}$ (i) It includes the non-empty set, (ii) the complement, and (iii) is closed under countable unions and intersections of sets \(S\), defined as a collection of subsets. Given such a collection of sets, we can define a measurable space, which allows for the consistent definition of measure and probability. Measure A measure \(\mu\) is a type of set function in a measurable space \((U, \mathcal{B})\) that assigns elements in \([0,\infty]\) to elements of the \(\sigma\)-field. \begin{equation}  \begin{aligned}  \mu : \mathcal{B} \rightarrow [0, \infty] \end{aligned}  \end{equation} \(\mu(\emptyset) = 0\): The measure of the empty set is 0. For any sequence of mutually exclusive sets \(A_j\), \(A_j\), the measure of their union is equal to the sum of their measures : \(\mu(\cup_{i=1}^{\infty} A_i) = \sum_{i=1}^{\infty} \mu(A_i)\). Probability Probability refers to a normalized measure on the extire set \(U\) such that \(\mu(U)=1\), indicating that the measure satisfies the condition of the total measure of the sample space being 1. Probability can be described as a measure where the total probability across the entire sample space equals 1. Definition of a Random Variable Noew, it’s time to examine the definition of a random variable. DEFINITION A random variable \(x\) is a function defined on the sample space \(\Omega\). This function serves to transform an element of the probability space \((\Omega, \mathcal{F}, P)\) into an element of the Boral measurable space \((\mathbb{R}, \mathcal{B})\) Here, the space created by the set of real numbers is referred to as the BOrel measurable space, and the associated \(\sigma\)-field in this context is termed the Borel set. Borel Measurable Space Borel Measurable Space: Consists of the set of real numbers \(\mathbb{R}\) and the Borel \(\sigma\) algebra \(\mathcall{B}\). The Borel \(\sigma\)-algebra includes open intervals on the real line and encompasses all sets that can be generated from these intervals. Essentially, this makes it possible to measure events in the commonly dealt with real number space. \(\Omega\) : Known as the Space, this represents the entire set of possible elements or outcomes. \(\mathcal{F}\) : Signifies the subsets of the sample space, referred to as Events. \(Pr\) : Acts as the operator that performs measurement, assigning probabilites to elements of the sample space. Through these complex concepts, we conclude that a random variable is essentially a function that transforms an element of the sample space into a real number. By defining this, we become interested in practically applying the probability of a random variable \(x\), denoted as \(Pr(x)\) Types of Random Variables Random variables are broadly classified into discrete and continuous types. A random variable that can take on either a finite number of values or a countably infinite number of values, such as the outcome of rolling a dice or baseball game socres, is called a discrete random variables. The Probability Mass Function(PMF) of a discrete random variable can assign a clear probability to each value. On the other hand, a random variable that can take values in a continuous range, such as temperature, stock prices, duration, speed, or measurements of an object’s length, is called a continuous random variable. Although the Probability Density Function(PDF) of a continuous random variable cannot assign a probability to each specific value, it can express the probability over a range of values. Discrete probability distributions include, notably, the binomial distribution, Poisson distribution, and geometric distribution, while continuous probability distributions include the normal distribution, uniform distribution, and exponential distribution. The following outlines the relations among various probability distributions. Reference Probability and Statistics for Data Science (Carlos Fernandez-Granda) ALIDA (Gyubeom Edward Im) Types of Probability Distributions (Jagandeep Singh)]]></summary></entry><entry xml:lang="ko"><title type="html">확률 변수</title><link href="http://localhost:4000/2024/03/26/random_variables_ko.html" rel="alternate" type="text/html" title="확률 변수" /><published>2024-03-26T00:00:00+09:00</published><updated>2024-03-26T00:00:00+09:00</updated><id>http://localhost:4000/2024/03/26/random_variables_ko</id><content type="html" xml:base="http://localhost:4000/2024/03/26/random_variables_ko.html"><![CDATA[<p>확률 변수를 쉽게 설명하자면 <strong><u>무작위적인 시행(Random Process)</u>에 따른 <u>결과를 숫자로 연결</u>하는 것</strong>이라고 이해할 수 있다. 가장 일반적인  예로 동전 던지기가 있다. <u>임의로 동전을 5번 던져서</u> 나온 <u>앞면의 합계</u>는 확률 변수라고 할 수 있다. 동전을 5번 던지는 행위가 무작위 시행이라는 것을 이해하기 어렵지 않은, 꽤나 직관적인 개념이다. 그렇다면 이러한 결과를 수치로 연결한다는 것은 어떤 의미가 있을까?</p>

<p>이를 이해하기 위해 수학의 입장에서 ‘크기 혹은 규모’에 대해서 이야기 해보려고 한다. 주사위 던지기와 같은 무작위적 시행의 결과는 <strong>불확실성</strong>을 갖는다. 이러한 ‘얼마나’라는 불확실성의 크기를 수학적으로 표현할 수 있을까? 물론 그 결과가 수치로써 표현된다면 가장 직관적인 해석이 가능할 것이다. 심지어 연산도 가능하다면?… 이러한 접근에서 확률 변수를 정의하는 것의 가치를 이해해 볼 수 있다. 사실 이 정도의 이해만으로도 충분할 수 있다. 하지만 보다 학문적 공부를 진행해보고자 확률 변수의 개념을 수학적으로 탐색해 보고자 한다.</p>

<p><br /></p>
<h2 id="수학적-접근">수학적 접근</h2>

<p>확률론에서 정의하는 확률 변수를 이해하기 위해서는 선행되어야 할 개념들이 있다. 수학적으로 꽤나 심도있는 이해를 요구하지만 가능하다면 직관적으로 이해해 보려고 한다. 차근차근 확률 변수의 수학적 정의에 접근해보자.</p>

<p><br /></p>
<h3 id="측도론measure-theory">측도론(Measure Theory)</h3>
<p>측도(Measure)라는 개념을 먼저 이해하기 위해 <strong>‘컵에 물이 담겨져 있는 상황’</strong>을 가정해보자. 
<br /></p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/random_variables/water_glass.jpeg" />
</p>

<p><br />‘물이 얼마나 담겨 있을까?’라는 질문에 답을 하기 위해 우리는 <u>'부피'를 정의하고 측정</u>한다. 3차원 입체라는 어떠한 집합에 ‘부피’라는 크기를 부여하게 된다면, 이는 그 <u>집합에 '크기'라는 개념을 부여하는 것</u>이 된다. 이를 수학에서 <strong>측도(Measure)</strong>라고 한다. 측도론은 크기, 면적, 부피 등의 일반화한 측도(Measure)의 개념을 다루는 분야로, 집합과 함수의 크기를 측정하고 분석하는 이론이다. 이 이론은 특히 확률론과 함수해석학에서 중요한 역할을 하는데, 우리가 확률을 공부하면서 자꾸만 집합을 마주치는 이유이기도 하다. <strong>중요한 것은, 우리가 이야기하는 ‘확률’이 바로 이러한 크기라는 속성을 나타내는 ‘측도’라는 것이다.</strong> 따라서 측도론에 기반하여 확률을 이해할 수 있어서야 비로소 그 정의를 이해할 수 있다.</p>

<p><br /></p>
<h3 id="확률probability">확률(Probability)</h3>

<p>우리는 어떠한 현상으로부터 결과를 얻기 위해 실험(experiment)을 하고, 실현값(outcome)을 얻을 수 있다. 실현값이라는 단어가 다소 생소하게 느껴질 수 있다. 이는 결과값 즉, outcome이라고 생각한다면 이해가 쉬워진다. 자, 그럼 주사위 던지기라는 확률 실험(Random Experiment)을 통해 측도론에 기반한 확률의 개념을 이해해 보자.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/random_variables/definition_random_variable_1.png" />
</p>

<p><br /> 
표본공간 \(\Omega=\{1,2,3,4,5,6\}\) 에서 주사위의 눈이 2가 나오는 사건(Event, \(\mathcal{F}\))의 크기를 수학적으로 말하기 위해, 우리는 확률 \(Pr(\cdot)\) 라는 측도를 사용할 수 있다. 그리고 이를 정의함으로써 \(Pr(2) = 1/6\) 와 같은 실현값(outcome)을 얻을 수 있게 된다.</p>

\[\begin{equation} 
\begin{aligned} 
&amp; Pr(1) = Pr(2) = Pr(3) = Pr(4) = Pr(5) = Pr(6) = 1/6
\end{aligned} 
\end{equation}\]

<p>다시말해, <strong>‘확률’은 이러한 확률 실험(Random Experiment)의 실현값(Realization)에 대한 측도(Masure)</strong>이며, 우리는 확률 \(Pr(\cdot)\)이라는 측도를 사용하여 공간 내 원소의 크기를 측정한 실현값(Realization)을 얻을 수 있다.</p>

<h3 id="sigma-field-mathcalb">\(\sigma\)-field \(\mathcal{B}\)</h3>
<p>이렇게 측도라는 개념을 도입하여 확률을 모순없이 정의하기 위해서는 측정 대상을 엄밀히 정의하는 과정이 필요한데, 그러한 측정대상을 정의하는 것이 바로 \(\sigma\)-field이다. \(\sigma\)-field는 다음과 같이 정의되는 집합들의 모입이다.</p>

<p>(i) $\emptyset \in \mathcal{B}$  <br />
(ii) $A \in \mathcal{B} \Rightarrow A^c \in \mathcal{B}$ <br />
(iii) $A_i \in \mathcal{B} \Rightarrow \cup_{i=1}^{\infty}A_i \in \mathcal{B}$ <br /></p>

<p>(i)공집합이 아니면서, (ii)여집합, 그리고 (iii) 셀 수 있는 합집합, 교집합에 대하여 닫혀있는 집합 \(S\)의 부분집합의 모임이라고 정의된다. 이러한 집합의 모입이 주어졌을 때, 측정할 수 있는 공간, 즉 가측공간(Measurable Space)를 정의할 수 있고, 측도와 확률을 모순없이 정의할 수 있다.</p>

<p><br /></p>
<ul>
  <li><strong>측도(Measure)</strong><br />
측도\(\mu\)란 가측공간 \((U, \mathcal{B})\)에서 \(\sigma\)-field의 원소를 사용하여 \([0,\infty]\)의 값을 반환하는 일종의 집합 합수(set function)이다.<br />
\begin{equation} 
\begin{aligned} 
\mu : \mathcal{B} \rightarrow [0, \infty]
\end{aligned} 
\end{equation}
    <ul>
      <li>\(\mu(\emptyset) = 0\): 공집합에 대한 측도응 0이다.<br /></li>
      <li>서로소 집합들 \(A_j\), \(A_j\) 들에 대하여 \(\mu(\cup_{i=1}^{\infty} A_i) = \sum_{i=1}^{\infty} \mu(A_i)\)이 성립한다.</li>
    </ul>
  </li>
</ul>

<p><br /></p>
<ul>
  <li><strong>확률(Probability)</strong><br />
확률(Probability)이란 전체집합 \(U\)에 대하여 \(\mu(U)=1\)의 크기를 만족하도록 정규화된 측도(Nomarlized Measure)를 의미한다.</li>
</ul>

<p><br /></p>

<p>확률은 전체 표본공간에 대한 확률의 총량이 1인 측도라고 할 수 있다.</p>

<hr />

<h3 id="확률-변수의-정의">확률 변수의 정의</h3>
<p>이제 확률 변수의 정의를 살펴볼 시간이다.</p>

<table>
  <thead>
    <tr>
      <th>DEFINITION</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>확률 변수</strong> \(x\)는 표본공간 \(\Omega\) 에 정의된 함수를 의미한다. 이 함수는 확률공간\((\Omega, \mathcal{F}, P)\) 의 하나의 원소를 Borel 가측공간 \((\mathbb{R}, \mathcal{B})\) 의 원소로 변환하는 역할을 수행한다. <br /><br />여기서, 실수들의 집합으로 만들어진 공간을 Borel 가측공간(Mesurable Space)라고 하며, 이 때 \(\sigma\)-field를 Borel set이라고 한다.</td>
    </tr>
  </tbody>
</table>

<details>
<summary>Borel 가측공간</summary>
<div>

    <p><strong>Borel 가측공간 (Borel Measurable Space)</strong>: 실수 집합 \(\mathbb{R}\) 과 Borel 시그마-대수 \(\mathcal{B}\) 로 구성된다. Borel 시그마-대수는 실수선 위에서 열린 구간을 포함하고, 이로부터 생성될 수 있는 모든 집합의 컬렉션이다. 이것은 기본적으로 우리가 흔히 다루는 실수 세계의 사건들을 측정 가능하게 한다.</p>

  </div>
</details>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/random_variables/definition_random_variable_2.png" />
</p>

<ul>
  <li>\(\Omega\) : 표본공간(Sample Space)라고 하며, 나올 수 있는 원소들의 전체 집합(Set)을 의미한다</li>
  <li>\(\mathcal{F}\) : 표본공간의 부분집합을 의미하며 사건(Event)이라고 부른다.</li>
  <li>\(Pr\) : 측도(Measure)를 수행하는 연산자로써 표본공간의 원소에 확률을 부여하는 역할한다.</li>
</ul>

<p>꽤나 어려운 개념들을 거쳐왔지만 결론적으로 확률 변수란 <strong>표본공간의 하나의 원소를 실수값으로 변환해주는 함수</strong>이다. 또한 이를 정의함으로써 우리는 실직절으로 확률 변수$x$의 확률인 $Pr(x)$의 활용에 관심을 갖게 된다.</p>

<h2 id="확률-변수의-유형">확률 변수의 유형</h2>
<p>확률 변수는 크게 이산형 확률 변수와 연속형 확률 변수로 분류된다.
주사위 던지기, 야구경기 점수와 같이 <u>유한하거나 셀 수 있는 무한한 값을 가지는 확률 변수</u>를 <strong>이산확률변수</strong>라고 한다. 이산확률변수의 확률밀도함수(Probability Mass Function, PMF)은 각 값에 대한 명확한 확률을 할당할 수 있다. 반면에 온도, 주식 가격, 기간, 속력, 물체의 길이 측정 등 <u>연속적인 범위의 값을 가는 확률 변수</u>를 <strong>연속확률변수</strong>라 한다. 연속확률변수의 확률밀도함수(Probability Mass Function, PMF)는 각 값에 대한 확률을 표현할 수는 없지만, 범위에 대한 확률을 표현할 수 있다.</p>

<p>이산확률분포에는 대표적으로 이항분포, 포아송분포, 기하분포 등이 있으며, 연속확률분포에는 정규분포, 균일분포, 지수분포 등이 있다. 다음은 다양한 확률분포 간의 관계를 나타낸다.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/random_variables/types of random variables.webp" />
</p>

<p><br /><br />
<strong>참조</strong></p>

<p><a href="https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf">Probability and Statistics for Data Science (Carlos Fernandez-Granda)</a><br />
<a href="https://alida.tistory.com/84">ALIDA (Gyubeom Edward Im)</a><br />
<a href="https://jagan-singhh.medium.com/types-of-probability-distributions-9333d18ed817">Types of Probability Distributions (Jagandeep Singh)</a></p>]]></content><author><name>Jenny Won (Dajeong Won)</name></author><category term="통계학" /><summary type="html"><![CDATA[확률 변수를 쉽게 설명하자면 무작위적인 시행(Random Process)에 따른 결과를 숫자로 연결하는 것이라고 이해할 수 있다. 가장 일반적인 예로 동전 던지기가 있다. 임의로 동전을 5번 던져서 나온 앞면의 합계는 확률 변수라고 할 수 있다. 동전을 5번 던지는 행위가 무작위 시행이라는 것을 이해하기 어렵지 않은, 꽤나 직관적인 개념이다. 그렇다면 이러한 결과를 수치로 연결한다는 것은 어떤 의미가 있을까? 이를 이해하기 위해 수학의 입장에서 ‘크기 혹은 규모’에 대해서 이야기 해보려고 한다. 주사위 던지기와 같은 무작위적 시행의 결과는 불확실성을 갖는다. 이러한 ‘얼마나’라는 불확실성의 크기를 수학적으로 표현할 수 있을까? 물론 그 결과가 수치로써 표현된다면 가장 직관적인 해석이 가능할 것이다. 심지어 연산도 가능하다면?… 이러한 접근에서 확률 변수를 정의하는 것의 가치를 이해해 볼 수 있다. 사실 이 정도의 이해만으로도 충분할 수 있다. 하지만 보다 학문적 공부를 진행해보고자 확률 변수의 개념을 수학적으로 탐색해 보고자 한다. 수학적 접근 확률론에서 정의하는 확률 변수를 이해하기 위해서는 선행되어야 할 개념들이 있다. 수학적으로 꽤나 심도있는 이해를 요구하지만 가능하다면 직관적으로 이해해 보려고 한다. 차근차근 확률 변수의 수학적 정의에 접근해보자. 측도론(Measure Theory) 측도(Measure)라는 개념을 먼저 이해하기 위해 ‘컵에 물이 담겨져 있는 상황’을 가정해보자. ‘물이 얼마나 담겨 있을까?’라는 질문에 답을 하기 위해 우리는 '부피'를 정의하고 측정한다. 3차원 입체라는 어떠한 집합에 ‘부피’라는 크기를 부여하게 된다면, 이는 그 집합에 '크기'라는 개념을 부여하는 것이 된다. 이를 수학에서 측도(Measure)라고 한다. 측도론은 크기, 면적, 부피 등의 일반화한 측도(Measure)의 개념을 다루는 분야로, 집합과 함수의 크기를 측정하고 분석하는 이론이다. 이 이론은 특히 확률론과 함수해석학에서 중요한 역할을 하는데, 우리가 확률을 공부하면서 자꾸만 집합을 마주치는 이유이기도 하다. 중요한 것은, 우리가 이야기하는 ‘확률’이 바로 이러한 크기라는 속성을 나타내는 ‘측도’라는 것이다. 따라서 측도론에 기반하여 확률을 이해할 수 있어서야 비로소 그 정의를 이해할 수 있다. 확률(Probability) 우리는 어떠한 현상으로부터 결과를 얻기 위해 실험(experiment)을 하고, 실현값(outcome)을 얻을 수 있다. 실현값이라는 단어가 다소 생소하게 느껴질 수 있다. 이는 결과값 즉, outcome이라고 생각한다면 이해가 쉬워진다. 자, 그럼 주사위 던지기라는 확률 실험(Random Experiment)을 통해 측도론에 기반한 확률의 개념을 이해해 보자. 표본공간 \(\Omega=\{1,2,3,4,5,6\}\) 에서 주사위의 눈이 2가 나오는 사건(Event, \(\mathcal{F}\))의 크기를 수학적으로 말하기 위해, 우리는 확률 \(Pr(\cdot)\) 라는 측도를 사용할 수 있다. 그리고 이를 정의함으로써 \(Pr(2) = 1/6\) 와 같은 실현값(outcome)을 얻을 수 있게 된다. \[\begin{equation}  \begin{aligned}  &amp; Pr(1) = Pr(2) = Pr(3) = Pr(4) = Pr(5) = Pr(6) = 1/6 \end{aligned}  \end{equation}\] 다시말해, ‘확률’은 이러한 확률 실험(Random Experiment)의 실현값(Realization)에 대한 측도(Masure)이며, 우리는 확률 \(Pr(\cdot)\)이라는 측도를 사용하여 공간 내 원소의 크기를 측정한 실현값(Realization)을 얻을 수 있다. \(\sigma\)-field \(\mathcal{B}\) 이렇게 측도라는 개념을 도입하여 확률을 모순없이 정의하기 위해서는 측정 대상을 엄밀히 정의하는 과정이 필요한데, 그러한 측정대상을 정의하는 것이 바로 \(\sigma\)-field이다. \(\sigma\)-field는 다음과 같이 정의되는 집합들의 모입이다. (i) $\emptyset \in \mathcal{B}$ (ii) $A \in \mathcal{B} \Rightarrow A^c \in \mathcal{B}$ (iii) $A_i \in \mathcal{B} \Rightarrow \cup_{i=1}^{\infty}A_i \in \mathcal{B}$ (i)공집합이 아니면서, (ii)여집합, 그리고 (iii) 셀 수 있는 합집합, 교집합에 대하여 닫혀있는 집합 \(S\)의 부분집합의 모임이라고 정의된다. 이러한 집합의 모입이 주어졌을 때, 측정할 수 있는 공간, 즉 가측공간(Measurable Space)를 정의할 수 있고, 측도와 확률을 모순없이 정의할 수 있다. 측도(Measure) 측도\(\mu\)란 가측공간 \((U, \mathcal{B})\)에서 \(\sigma\)-field의 원소를 사용하여 \([0,\infty]\)의 값을 반환하는 일종의 집합 합수(set function)이다. \begin{equation}  \begin{aligned}  \mu : \mathcal{B} \rightarrow [0, \infty] \end{aligned}  \end{equation} \(\mu(\emptyset) = 0\): 공집합에 대한 측도응 0이다. 서로소 집합들 \(A_j\), \(A_j\) 들에 대하여 \(\mu(\cup_{i=1}^{\infty} A_i) = \sum_{i=1}^{\infty} \mu(A_i)\)이 성립한다. 확률(Probability) 확률(Probability)이란 전체집합 \(U\)에 대하여 \(\mu(U)=1\)의 크기를 만족하도록 정규화된 측도(Nomarlized Measure)를 의미한다. 확률은 전체 표본공간에 대한 확률의 총량이 1인 측도라고 할 수 있다. 확률 변수의 정의 이제 확률 변수의 정의를 살펴볼 시간이다. DEFINITION 확률 변수 \(x\)는 표본공간 \(\Omega\) 에 정의된 함수를 의미한다. 이 함수는 확률공간\((\Omega, \mathcal{F}, P)\) 의 하나의 원소를 Borel 가측공간 \((\mathbb{R}, \mathcal{B})\) 의 원소로 변환하는 역할을 수행한다. 여기서, 실수들의 집합으로 만들어진 공간을 Borel 가측공간(Mesurable Space)라고 하며, 이 때 \(\sigma\)-field를 Borel set이라고 한다. Borel 가측공간 Borel 가측공간 (Borel Measurable Space): 실수 집합 \(\mathbb{R}\) 과 Borel 시그마-대수 \(\mathcal{B}\) 로 구성된다. Borel 시그마-대수는 실수선 위에서 열린 구간을 포함하고, 이로부터 생성될 수 있는 모든 집합의 컬렉션이다. 이것은 기본적으로 우리가 흔히 다루는 실수 세계의 사건들을 측정 가능하게 한다. \(\Omega\) : 표본공간(Sample Space)라고 하며, 나올 수 있는 원소들의 전체 집합(Set)을 의미한다 \(\mathcal{F}\) : 표본공간의 부분집합을 의미하며 사건(Event)이라고 부른다. \(Pr\) : 측도(Measure)를 수행하는 연산자로써 표본공간의 원소에 확률을 부여하는 역할한다. 꽤나 어려운 개념들을 거쳐왔지만 결론적으로 확률 변수란 표본공간의 하나의 원소를 실수값으로 변환해주는 함수이다. 또한 이를 정의함으로써 우리는 실직절으로 확률 변수$x$의 확률인 $Pr(x)$의 활용에 관심을 갖게 된다. 확률 변수의 유형 확률 변수는 크게 이산형 확률 변수와 연속형 확률 변수로 분류된다. 주사위 던지기, 야구경기 점수와 같이 유한하거나 셀 수 있는 무한한 값을 가지는 확률 변수를 이산확률변수라고 한다. 이산확률변수의 확률밀도함수(Probability Mass Function, PMF)은 각 값에 대한 명확한 확률을 할당할 수 있다. 반면에 온도, 주식 가격, 기간, 속력, 물체의 길이 측정 등 연속적인 범위의 값을 가는 확률 변수를 연속확률변수라 한다. 연속확률변수의 확률밀도함수(Probability Mass Function, PMF)는 각 값에 대한 확률을 표현할 수는 없지만, 범위에 대한 확률을 표현할 수 있다. 이산확률분포에는 대표적으로 이항분포, 포아송분포, 기하분포 등이 있으며, 연속확률분포에는 정규분포, 균일분포, 지수분포 등이 있다. 다음은 다양한 확률분포 간의 관계를 나타낸다. 참조 Probability and Statistics for Data Science (Carlos Fernandez-Granda) ALIDA (Gyubeom Edward Im) Types of Probability Distributions (Jagandeep Singh)]]></summary></entry></feed>