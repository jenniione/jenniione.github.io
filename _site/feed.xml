<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-03-28T21:54:06+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">JenDS</title><subtitle>JenDS by Jenny Won
</subtitle><author><name>Jenny Won (Dajeong Won)</name></author><entry xml:lang="ko"><title type="html">이항 분포</title><link href="http://localhost:4000/2024/03/27/binomial_distribution_ko.html" rel="alternate" type="text/html" title="이항 분포" /><published>2024-03-27T00:00:00+09:00</published><updated>2024-03-27T00:00:00+09:00</updated><id>http://localhost:4000/2024/03/27/binomial_distribution_ko</id><content type="html" xml:base="http://localhost:4000/2024/03/27/binomial_distribution_ko.html"><![CDATA[<p>이항 분포에 앞서, 베르누이 분포에 대해 간략히 정리하고, 이항 분포와 베르누이 분포가 어떤 관계가 있는지 알아보자.</p>
<h2 id="베르누이-분포">베르누이 분포</h2>
<p>확률 실험의 결과가 성공 혹은 실패로 나타나는 실험을 베르누이 실험(Bernoulli Experiment)라고 한다. 그리고 성공 확률이 \(p\)로 고정된 베르누이 실험에서 성공의 횟수를 나타내는 확률 분포가 바로 <strong>베르누이 분포</strong>이다. 즉, 베르누이 분포는 <strong>확률 변수의 값이 성공 혹은 실패로 나타나는 확률 분포</strong>이며, 그 결과가 성공 혹은 실패, 두 값 중 하나만 가지므로 베르누이 확률 변수는 <strong>이산 확률 변수</strong>라고 할 수 있다.</p>

\[x  \{ \text{success, fail} \} \rightarrow \{0, 1\}\]

\[\begin{equation}
\begin{aligned}
&amp; P(x=0) = 1-p \\
&amp; P(x=1) = p \\ \end{aligned}
\end{equation}\]

<p>확률 변수 \(X\)가 베르누이 분포에 의해 발생된다면 다음과 같이 표현할 수 있다.</p>

\[\begin{equation} 
 \begin{aligned} 
&amp; x \sim \text{Bern}(p)
\end{aligned}   
\end{equation}\]

<p>그리고 그 확률 질량 함수(PMF)는 다음과 같이 수식으로 나타낼 수 있다. 
\(\begin{split}
\begin{align}
\text{Bern}(x; p) = 
\begin{cases} 
p   &amp; \text{if }x=1, \\
1-p &amp; \text{if }x=0
\end{cases}
\tag{8.2.2}
\end{align}
\end{split}\)</p>

<p>여기서 주목해야 할 점은, 베르누이 분포는 <strong>한번의 시행</strong>에 대한 결과에서 <strong>성공 확률 \(p\)</strong>에 집중한 관찰 데이터라는 점이다. 이 점은 이항 분포가 베르누이 분포와 어떻게 다른지를 설명하게 된다.</p>

<h2 id="이항-분포의-정의">이항 분포의 정의</h2>
<p class="info"><strong>정의</strong>   이항 분포(Binomial Distribution)은 동일한 확률 \(p\) 로 성공하는 베르누이 시행을 고정된 수 \(n\) 번을 반복할 때의 성공 횟수를 모델링하는 확률 분포이다.</p>

<p>이항 분포는 베르누이 시행을 \(n\)번 반복하여 얻게된 확률 분포이다. 다시말해, <strong>이항분포는 베르누이 시행의 확장</strong>이라고 할 수 있다. 단 한 번의 베르누이 시행이 아닌, \(n\)번의 반복된 베르누이 시행에서 성공 횟수에 대한 확률 분포를 모델링한 것이 바로 이항 분포이다.
동전 던지기의 예를 들어보자. 앞면이 나올 확률이 \(p=1/2\)이라 했을 때, 그 결과는 베르누이 분포를 따르게 된다. 하지만 동일한 동전을 10번 던지고 앞면이 나온 횟수를 관찰하는 경우, 이 시나리오는 이항 분포를 따르게 된다. 여기서 핵심은 10번 던지는 동안 <strong>각각의 던지기가 독립적이며, 각 시행의 성공 확률은 \(p\) 로 동일해야 한다</strong>는 점이다.(원래 베르누이 시행의 성공확률은 고정된 \(p\)를 갖는다.)</p>

<p>이항 분포는 다음과 같이 표현할 수 있으며,</p>

\[\begin{equation} 
 \begin{aligned} 
x \sim \text{Bin}(n,p)
\end{aligned}   
\end{equation}\]

<p>이항 분포의 <strong>확률 밀도 함수(PMF)</strong>는 다음과 같이 정의된다.</p>

\[\begin{equation} 
P_X(x) = \ _{n}C_{x} p^k (1-p)^{n-x} \quad \text{ for } x =0,1,\cdots,n
\end{equation}\]

<h2 id="이항-분포의-이해">이항 분포의 이해</h2>
<h3 id="10번의-동전-던지기-예시">10번의 동전 던지기 예시</h3>
<p>확률 질량 함수를 이해하기 위해서, 앞선 10번의 동전 던지기의 확률을 직접 구해보자.
앞면이 나오는 경우를 성공이라 하고, \(x\)를 성공 횟수라고 하자. 즉, \(x = 0, 1, 2, \cdots, 10\) 이고, 각각은 앞면이 0번, 1번, 2번, … 10번 나오는 경우를 의미할 것이다. \(x=2\)일 떄, 즉 10번의 시행 중 동전의 앞면이 2번 나오는 확률을 생각해 보자.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/coin k=2.png" />
</p>

<p>그림과 같이 각각의 독립된 \((\frac{1}{2})^2\cdot(1-\frac{1}{2})^{8}\)의 확률이 \( _{10}C_{2}\)의 경우의 수로 출현할 수 있다. 이것은 다음과 같이 계산된다.</p>

\[_{10}C_{2}\left(\frac{1}{2}\right)^2\cdot \left(1-\frac{1}{2}\right)^{8} = 0.0439\]

<p>같은 방법으로, 모든 x에 대해서 그 확률을 계산해 보면 다음과 같다.</p>

\[x=0 ;  \frac{10!}{1!\cdot9!}
\left(\frac{1}{2}\right)^0 \left(1-\frac{1}{2}\right)^{10} = 0.0010\]

\[x=1 ;  \frac{10!}{1!\cdot9!}
\left(\frac{1}{2}\right)^1 \left(1-\frac{1}{2}\right)^{9} = 0.0098\]

\[x=2 ; \frac{10!}{2! 8!}\left(\frac{1}{2}\right)^2\cdot \left(1-\frac{1}{2}\right)^{8} = 0.0439\]

<center>⋮</center>

\[x=10 ; \frac{10!}{10! 0!}\left(\frac{1}{2}\right)^{10} \left(1-\frac{1}{2}\right)^{0} = 0.0010\]

<p>이것을 히스토그램으로 나타내면 다음과 같다.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/coin distribution.png" />
</p>

<h3 id="직관적-이항-분포">직관적 이항 분포</h3>
<p>이항 분포는 동전 던지기처럼 두 가지 결과가 있는 확률적 사건을 몇 번 반복했을 때, 어떤 결과를 얻을 확률을 구하기 위해 사용된다.</p>

<p>실제로 어떻게 활용될 수 있는 지, 보다 직관적인 이해를 위해 실제로 이항 분포의 활용이 고려되는 알아보자.</p>

<ul>
  <li>예시 1<br />
마케팅 팀에서 1,000명의 고객에게 메일을 각각 발송했다. 이전의 경험을 토대로 회신을 받을 수 있는 확률이 0.5라고 가정하자. 자, 발송된 1,000개의 메일에 대해 50명의 고객으로 부터 회신을 받을 확률은 어떻게 될까?</li>
</ul>

<p>아주 간단한 \(n=1,000\), \(p=0.5\)인 이항 분포의 확률 \(P_X(50)\)을 구하는 문제이다.
이처럼 이항 분포는 기본적으로 <strong>시행 횟수와 성공 확률이 고정</strong>되었을 때, <strong>성공이 출현할 확률</strong>을 구할 때 활용될 수 있다.</p>

<p>또한, A/B테스를 진행하며 이항 분포의 개념이 활용될 수 있다. 아래 예시를 보자.</p>
<ul>
  <li>예시 2<br />
웹사이트의 버튼 클릭률을 높이기 위해 두 가지 디자인(A와 B)의 효과를 비교하는 A/B테스트를 수행한다고 가정해 보자. 웹사이트 방문자 1,000명에게 B디자인을 노출시킨 후, 150명이 클릭했다. 우리는 디자인 B의 클릭률이 디자인 A의 클릭률 10%와 통계적으로 유의미하게 다른지를 평가하고자 한다.</li>
</ul>

<p>방문자의 클릭 여부가 독립이라는 가정 하에, 각 웹사이트 방문자가 클릭하는 행위는 클릭(성공) 또는 비클릭(실패)의 이항 결과를 갖는다. 우리는 성공 확률 p를 10%, 시도 횟수 n은 1,000명, 성공 횟수 150명으로 설정하고 이항 검정을 수행할 수 있다.</p>

<h2 id="이항-분포의-평균과-분산">이항 분포의 평균과 분산</h2>
<p>총 시행 횟수가 \(n\), 성공 확률이 \(p\)인 이항 분포를 따르는 확률 변수 X에 대해,</p>

<p>기댓값은</p>

\[E(X) = np\]

<p>분산은</p>

\[Var(X) = np(1-p)\]

<p>이다. 각각의 증명은 다음과 같다.</p>

<p>\(\begin{split}
\begin{align}
\begin{aligned}
\text{E}[X] 
&amp;= \sum_{x_i \in \Omega} x_i p(x_i) \\
&amp;= 1 \cdot \mu + 0 \cdot (1 - \mu) \\
&amp;= \mu
\end{aligned}
\end{align}
\end{split}\)
<br /></p>

\[\begin{split}
\begin{align}
\begin{aligned}
\text{Var}[X] 
&amp;= \sum_{x_i \in \Omega} (x_i - \mu)^2 p(x_i) \\
&amp;= (1 - \mu)^2 \cdot \mu + (0 - \mu)^2 \cdot (1 - \mu) \\
&amp;= \mu(1-\mu)
\end{aligned}
\end{align}
\end{split}\]

<h2 id="이항-분포의-정규-분포-근사">이항 분포의 정규 분포 근사</h2>
<p>자, 그럼 이항 분포의 파라미터를 자유롭게 변경하며 이항 분포의 여러 모양을 관찰해 보자. 
이러한 결과를 쉽게 확인할 수 있는 다양한 시뮬레이션이 온라인에 공개되어 있고, 그 중  GeoGebra에서 Parameters of the Binomial Distribution(shanlee) 시뮬레이션을 활용했다.
n이 계속 증가한다면, 즉 시행을 많이 한다면 이항 분포는 어떻게 변할까?</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/binomial distribution to normal distribution.png" />
</p>

<p>종모양의 정규 분포와 유사한 형태를 띄는 것을 확인할 수 있다. 하지만 $n$ 과 $p$ 의 값이 극단적이지 않은 경우에만 가능하다. $n$ 이 너무 작거나, $n$ 이 충분히 크지만 $p$ 가 너무 작거나 클 경우 정규 분포의 모양과 많이 벗어나는 것을 확인 할 수 있다.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/small n.png" />
</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/small p.png" />
</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/huge p.png" />
</p>

<p>이항 분포의 $n$ 이 충분히 커서 $np&gt;=5$, $np(1-p)&gt;=5$ 조건을 만족하면, 이항 분포의 평균이 $np$, 분산이 $np(1-p)$ 인 정규 분포에 근사할 수 있다고 한다. 이런 규칙은 대략적인 지침이고 실제로는 앞선 시뮬레이션에서와 같이 $n$ 이 클수록, $p$ 가 0이나 1에 가깝지 않고, 0.5에 가까울수록 정규 분포로의 근사가 더욱 정확해지는 것을 볼 수 있다.</p>

<p>타율 3할인 타자가 100번 타석에 들어서면 안타를 얼마나 칠까? 사망률이 30%인 감염병에 100명이 걸렸을 때 실제로 얼마나 사망할까? 등 실제 많은 사건들 이항 분포를 따른다고 할 수 있다. 정규 분포가 이항 분포의 근사값으로 표현된다면 정규 분포 역시 많은 사건을 설명할 수 있는 분포가 될 것이다.</p>

<p><br /><br />
<strong>참조</strong></p>

<p><a href="https://www.geogebra.org/m/hMuamz5w">Binomial Distribution Image Generator(Michael Borcherds)</a>)<br />
<a href="https://www.geogebra.org/m/hGkW4vwJ">Parameters of the Binomial Distribution(shanlee)</a>)<br />
<a href="https://datascienceschool.net/02%20mathematics/08.02%20%EB%B2%A0%EB%A5%B4%EB%88%84%EC%9D%B4%EB%B6%84%ED%8F%AC%EC%99%80%20%EC%9D%B4%ED%95%AD%EB%B6%84%ED%8F%AC.html">데이터 사이언스 스쿨</a><br />
<a href="https://bookdown.org/mathemedicine/Stat_book/normal-distribution.html#-1">기초통계 개념정리(김진섭)</a><br /></p>]]></content><author><name>Jenny Won (Dajeong Won)</name></author><category term="통계학" /><summary type="html"><![CDATA[이항 분포에 앞서, 베르누이 분포에 대해 간략히 정리하고, 이항 분포와 베르누이 분포가 어떤 관계가 있는지 알아보자. 베르누이 분포 확률 실험의 결과가 성공 혹은 실패로 나타나는 실험을 베르누이 실험(Bernoulli Experiment)라고 한다. 그리고 성공 확률이 \(p\)로 고정된 베르누이 실험에서 성공의 횟수를 나타내는 확률 분포가 바로 베르누이 분포이다. 즉, 베르누이 분포는 확률 변수의 값이 성공 혹은 실패로 나타나는 확률 분포이며, 그 결과가 성공 혹은 실패, 두 값 중 하나만 가지므로 베르누이 확률 변수는 이산 확률 변수라고 할 수 있다. \[x  \{ \text{success, fail} \} \rightarrow \{0, 1\}\] \[\begin{equation} \begin{aligned} &amp; P(x=0) = 1-p \\ &amp; P(x=1) = p \\ \end{aligned} \end{equation}\] 확률 변수 \(X\)가 베르누이 분포에 의해 발생된다면 다음과 같이 표현할 수 있다. \[\begin{equation}   \begin{aligned}  &amp; x \sim \text{Bern}(p) \end{aligned}    \end{equation}\] 그리고 그 확률 질량 함수(PMF)는 다음과 같이 수식으로 나타낼 수 있다. \(\begin{split} \begin{align} \text{Bern}(x; p) = \begin{cases} p &amp; \text{if }x=1, \\ 1-p &amp; \text{if }x=0 \end{cases} \tag{8.2.2} \end{align} \end{split}\) 여기서 주목해야 할 점은, 베르누이 분포는 한번의 시행에 대한 결과에서 성공 확률 \(p\)에 집중한 관찰 데이터라는 점이다. 이 점은 이항 분포가 베르누이 분포와 어떻게 다른지를 설명하게 된다. 이항 분포의 정의 정의   이항 분포(Binomial Distribution)은 동일한 확률 \(p\) 로 성공하는 베르누이 시행을 고정된 수 \(n\) 번을 반복할 때의 성공 횟수를 모델링하는 확률 분포이다. 이항 분포는 베르누이 시행을 \(n\)번 반복하여 얻게된 확률 분포이다. 다시말해, 이항분포는 베르누이 시행의 확장이라고 할 수 있다. 단 한 번의 베르누이 시행이 아닌, \(n\)번의 반복된 베르누이 시행에서 성공 횟수에 대한 확률 분포를 모델링한 것이 바로 이항 분포이다. 동전 던지기의 예를 들어보자. 앞면이 나올 확률이 \(p=1/2\)이라 했을 때, 그 결과는 베르누이 분포를 따르게 된다. 하지만 동일한 동전을 10번 던지고 앞면이 나온 횟수를 관찰하는 경우, 이 시나리오는 이항 분포를 따르게 된다. 여기서 핵심은 10번 던지는 동안 각각의 던지기가 독립적이며, 각 시행의 성공 확률은 \(p\) 로 동일해야 한다는 점이다.(원래 베르누이 시행의 성공확률은 고정된 \(p\)를 갖는다.) 이항 분포는 다음과 같이 표현할 수 있으며, \[\begin{equation}   \begin{aligned}  x \sim \text{Bin}(n,p) \end{aligned}    \end{equation}\] 이항 분포의 확률 밀도 함수(PMF)는 다음과 같이 정의된다. \[\begin{equation}  P_X(x) = \ _{n}C_{x} p^k (1-p)^{n-x} \quad \text{ for } x =0,1,\cdots,n \end{equation}\] 이항 분포의 이해 10번의 동전 던지기 예시 확률 질량 함수를 이해하기 위해서, 앞선 10번의 동전 던지기의 확률을 직접 구해보자. 앞면이 나오는 경우를 성공이라 하고, \(x\)를 성공 횟수라고 하자. 즉, \(x = 0, 1, 2, \cdots, 10\) 이고, 각각은 앞면이 0번, 1번, 2번, … 10번 나오는 경우를 의미할 것이다. \(x=2\)일 떄, 즉 10번의 시행 중 동전의 앞면이 2번 나오는 확률을 생각해 보자. 그림과 같이 각각의 독립된 \((\frac{1}{2})^2\cdot(1-\frac{1}{2})^{8}\)의 확률이 \( _{10}C_{2}\)의 경우의 수로 출현할 수 있다. 이것은 다음과 같이 계산된다. \[_{10}C_{2}\left(\frac{1}{2}\right)^2\cdot \left(1-\frac{1}{2}\right)^{8} = 0.0439\] 같은 방법으로, 모든 x에 대해서 그 확률을 계산해 보면 다음과 같다. \[x=0 ; \frac{10!}{1!\cdot9!} \left(\frac{1}{2}\right)^0 \left(1-\frac{1}{2}\right)^{10} = 0.0010\] \[x=1 ; \frac{10!}{1!\cdot9!} \left(\frac{1}{2}\right)^1 \left(1-\frac{1}{2}\right)^{9} = 0.0098\] \[x=2 ; \frac{10!}{2! 8!}\left(\frac{1}{2}\right)^2\cdot \left(1-\frac{1}{2}\right)^{8} = 0.0439\] ⋮ \[x=10 ; \frac{10!}{10! 0!}\left(\frac{1}{2}\right)^{10} \left(1-\frac{1}{2}\right)^{0} = 0.0010\] 이것을 히스토그램으로 나타내면 다음과 같다. 직관적 이항 분포 이항 분포는 동전 던지기처럼 두 가지 결과가 있는 확률적 사건을 몇 번 반복했을 때, 어떤 결과를 얻을 확률을 구하기 위해 사용된다. 실제로 어떻게 활용될 수 있는 지, 보다 직관적인 이해를 위해 실제로 이항 분포의 활용이 고려되는 알아보자. 예시 1 마케팅 팀에서 1,000명의 고객에게 메일을 각각 발송했다. 이전의 경험을 토대로 회신을 받을 수 있는 확률이 0.5라고 가정하자. 자, 발송된 1,000개의 메일에 대해 50명의 고객으로 부터 회신을 받을 확률은 어떻게 될까? 아주 간단한 \(n=1,000\), \(p=0.5\)인 이항 분포의 확률 \(P_X(50)\)을 구하는 문제이다. 이처럼 이항 분포는 기본적으로 시행 횟수와 성공 확률이 고정되었을 때, 성공이 출현할 확률을 구할 때 활용될 수 있다. 또한, A/B테스를 진행하며 이항 분포의 개념이 활용될 수 있다. 아래 예시를 보자. 예시 2 웹사이트의 버튼 클릭률을 높이기 위해 두 가지 디자인(A와 B)의 효과를 비교하는 A/B테스트를 수행한다고 가정해 보자. 웹사이트 방문자 1,000명에게 B디자인을 노출시킨 후, 150명이 클릭했다. 우리는 디자인 B의 클릭률이 디자인 A의 클릭률 10%와 통계적으로 유의미하게 다른지를 평가하고자 한다. 방문자의 클릭 여부가 독립이라는 가정 하에, 각 웹사이트 방문자가 클릭하는 행위는 클릭(성공) 또는 비클릭(실패)의 이항 결과를 갖는다. 우리는 성공 확률 p를 10%, 시도 횟수 n은 1,000명, 성공 횟수 150명으로 설정하고 이항 검정을 수행할 수 있다. 이항 분포의 평균과 분산 총 시행 횟수가 \(n\), 성공 확률이 \(p\)인 이항 분포를 따르는 확률 변수 X에 대해, 기댓값은 \[E(X) = np\] 분산은 \[Var(X) = np(1-p)\] 이다. 각각의 증명은 다음과 같다. \(\begin{split} \begin{align} \begin{aligned} \text{E}[X] &amp;= \sum_{x_i \in \Omega} x_i p(x_i) \\ &amp;= 1 \cdot \mu + 0 \cdot (1 - \mu) \\ &amp;= \mu \end{aligned} \end{align} \end{split}\) \[\begin{split} \begin{align} \begin{aligned} \text{Var}[X] &amp;= \sum_{x_i \in \Omega} (x_i - \mu)^2 p(x_i) \\ &amp;= (1 - \mu)^2 \cdot \mu + (0 - \mu)^2 \cdot (1 - \mu) \\ &amp;= \mu(1-\mu) \end{aligned} \end{align} \end{split}\] 이항 분포의 정규 분포 근사 자, 그럼 이항 분포의 파라미터를 자유롭게 변경하며 이항 분포의 여러 모양을 관찰해 보자. 이러한 결과를 쉽게 확인할 수 있는 다양한 시뮬레이션이 온라인에 공개되어 있고, 그 중 GeoGebra에서 Parameters of the Binomial Distribution(shanlee) 시뮬레이션을 활용했다. n이 계속 증가한다면, 즉 시행을 많이 한다면 이항 분포는 어떻게 변할까? 종모양의 정규 분포와 유사한 형태를 띄는 것을 확인할 수 있다. 하지만 $n$ 과 $p$ 의 값이 극단적이지 않은 경우에만 가능하다. $n$ 이 너무 작거나, $n$ 이 충분히 크지만 $p$ 가 너무 작거나 클 경우 정규 분포의 모양과 많이 벗어나는 것을 확인 할 수 있다. 이항 분포의 $n$ 이 충분히 커서 $np&gt;=5$, $np(1-p)&gt;=5$ 조건을 만족하면, 이항 분포의 평균이 $np$, 분산이 $np(1-p)$ 인 정규 분포에 근사할 수 있다고 한다. 이런 규칙은 대략적인 지침이고 실제로는 앞선 시뮬레이션에서와 같이 $n$ 이 클수록, $p$ 가 0이나 1에 가깝지 않고, 0.5에 가까울수록 정규 분포로의 근사가 더욱 정확해지는 것을 볼 수 있다. 타율 3할인 타자가 100번 타석에 들어서면 안타를 얼마나 칠까? 사망률이 30%인 감염병에 100명이 걸렸을 때 실제로 얼마나 사망할까? 등 실제 많은 사건들 이항 분포를 따른다고 할 수 있다. 정규 분포가 이항 분포의 근사값으로 표현된다면 정규 분포 역시 많은 사건을 설명할 수 있는 분포가 될 것이다. 참조 Binomial Distribution Image Generator(Michael Borcherds)) Parameters of the Binomial Distribution(shanlee)) 데이터 사이언스 스쿨 기초통계 개념정리(김진섭)]]></summary></entry><entry xml:lang="en"><title type="html">Probability Distribution</title><link href="http://localhost:4000/2024/03/26/random_variables_en.html" rel="alternate" type="text/html" title="Probability Distribution" /><published>2024-03-26T00:00:00+09:00</published><updated>2024-03-26T00:00:00+09:00</updated><id>http://localhost:4000/2024/03/26/random_variables_en</id><content type="html" xml:base="http://localhost:4000/2024/03/26/random_variables_en.html"><![CDATA[]]></content><author><name>Jenny Won (Dajeong Won)</name></author><category term="Stastistics" /><summary type="html"><![CDATA[]]></summary></entry><entry xml:lang="ko"><title type="html">확률 변수</title><link href="http://localhost:4000/2024/03/26/random_variables_ko.html" rel="alternate" type="text/html" title="확률 변수" /><published>2024-03-26T00:00:00+09:00</published><updated>2024-03-26T00:00:00+09:00</updated><id>http://localhost:4000/2024/03/26/random_variables_ko</id><content type="html" xml:base="http://localhost:4000/2024/03/26/random_variables_ko.html"><![CDATA[<p>확률 변수를 쉽게 설명하자면 <strong><u>무작위적인 시행(Random Process)</u>에 따른 <u>결과를 숫자로 연결</u>하는 것</strong>이라고 이해할 수 있다. 가장 일반적인  예로 동전 던지기가 있다. <u>임의로 동전을 5번 던져서</u> 나온 <u>앞면의 합계</u>는 확률 변수라고 할 수 있다. 동전을 5번 던지는 행위가 무작위 시행이라는 것을 이해하기 어렵지 않은, 꽤나 직관적인 개념이다. 그렇다면 이러한 결과를 수치로 연결한다는 것은 어떤 의미가 있을까?</p>

<p>이를 이해하기 위해 수학의 입장에서 ‘크기 혹은 규모’에 대해서 이야기 해보려고 한다. 주사위 던지기와 같은 무작위적 시행의 결과는 <strong>불확실성</strong>을 갖는다. 이러한 ‘얼마나’라는 불확실성의 크기를 수학적으로 표현할 수 있을까? 물론 그 결과가 수치로써 표현된다면 가장 직관적인 해석이 가능할 것이다. 심지어 연산도 가능하다면?… 이러한 접근에서 확률 변수를 정의하는 것의 가치를 이해해 볼 수 있다. 사실 이 정도의 이해만으로도 충분할 수 있다. 하지만 보다 학문적 공부를 진행해보고자 확률 변수의 개념을 수학적으로 탐색해 보고자 한다.</p>

<p><br /></p>
<h2 id="수학적-접근">수학적 접근</h2>

<p>확률론에서 정의하는 확률 변수를 이해하기 위해서는 선행되어야 할 개념들이 있다. 수학적으로 꽤나 심도있는 이해를 요구하지만 가능하다면 직관적으로 이해해 보려고 한다. 차근차근 확률 변수의 수학적 정의에 접근해보자.</p>

<p><br /></p>
<h3 id="측도론measure-theory">측도론(Measure Theory)</h3>
<p>측도(Measure)라는 개념을 먼저 이해하기 위해 <strong>‘컵에 물이 담겨져 있는 상황’</strong>을 가정해보자. 
<br /></p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/random_variables/water_glass.png" />
</p>

<p><br />‘물이 얼마나 담겨 있을까?’라는 질문에 답을 하기 위해 우리는 <u>'부피'를 정의하고 측정</u>한다. 3차원 입체라는 어떠한 집합에 ‘부피’라는 크기를 부여하게 된다면, 이는 그 <u>집합에 '크기'라는 개념을 부여하는 것</u>이 된다. 이를 수학에서 <strong>측도(Measure)</strong>라고 한다. 측도론은 크기, 면적, 부피 등의 일반화한 측도(Measure)의 개념을 다루는 분야로, 집합과 함수의 크기를 측정하고 분석하는 이론이다. 이 이론은 특히 확률론과 함수해석학에서 중요한 역할을 하는데, 우리가 확률을 공부하면서 자꾸만 집합을 마주치는 이유이기도 하다. <strong>중요한 것은, 우리가 이야기하는 ‘확률’이 바로 이러한 크기라는 속성을 나타내는 ‘측도’라는 것이다.</strong> 따라서 측도론에 기반하여 확률을 이해할 수 있어서야 비로소 그 정의를 이해할 수 있다.</p>

<p><br /></p>
<h3 id="확률probability">확률(Probability)</h3>

<p>우리는 어떠한 현상으로부터 결과를 얻기 위해 실험(Experiment)을 하고, 실현값(Outcome)을 얻을 수 있다. 실현값이라는 단어가 다소 생소하게 느껴질 수 있다. 이는 결과값 즉, Outcome이라고 생각한다면 이해가 쉬워진다. 자, 그럼 주사위 던지기라는 확률 실험(Random Experiment)을 통해 측도론에 기반한 확률의 개념을 이해해 보자.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/random_variables/definition_random_variable_1.png" />
</p>

<p><br /> 
표본공간 \(\Omega=\{1,2,3,4,5,6\}\) 에서 주사위의 눈이 2가 나오는 사건(Event, \(\mathcal{F}\))의 크기를 수학적으로 말하기 위해, 우리는 확률 \(Pr(\cdot)\) 라는 측도를 사용할 수 있다. 그리고 이를 정의함으로써 \(Pr(2) = 1/6\) 와 같은 실현값(Outcome)을 얻을 수 있게 된다.</p>

\[\begin{equation} 
\begin{aligned} 
&amp; Pr(1) = Pr(2) = Pr(3) = Pr(4) = Pr(5) = Pr(6) = 1/6
\end{aligned} 
\end{equation}\]

<p>다시말해, <strong>‘확률’은 이러한 확률 실험(Random Experiment)의 실현값(Realization)에 대한 측도(Measure)</strong>이며, 우리는 확률 \(Pr(\cdot)\)이라는 측도를 사용하여 공간 내 원소의 크기를 측정한 실현값(Realization)을 얻을 수 있다.</p>

<h3 id="sigma-field-mathcalb">\(\sigma\)-field \(\mathcal{B}\)</h3>
<p>이렇게 측도라는 개념을 도입하여 확률을 모순없이 정의하기 위해서는 측정 대상을 엄밀히 정의하는 과정이 필요한데, 그러한 측정대상을 정의하는 것이 바로 \(\sigma\)-field이다. \(\sigma\)-field는 다음과 같이 정의되는 집합들의 모입이다.</p>

<p>(i) $\emptyset \in \mathcal{B}$  <br />
(ii) $A \in \mathcal{B} \Rightarrow A^c \in \mathcal{B}$ <br />
(iii) $A_i \in \mathcal{B} \Rightarrow \cup_{i=1}^{\infty}A_i \in \mathcal{B}$ <br /></p>

<p>(i)공집합이 아니면서, (ii)여집합, 그리고 (iii) 셀 수 있는 합집합, 교집합에 대하여 닫혀있는 집합 S의 부분집합의 모임이라고 정의된다. 이러한 집합의 모입이 주어졌을 때, 측정할 수 있는 공간, 즉 가측공간(Measurable Space)를 정의할 수 있고, 측도와 확률을 모순없이 정의할 수 있다.</p>

<p><br /></p>
<ul>
  <li><strong>측도(Measure)</strong><br />
측도\(\mu\)란 가측공간 \((U, \mathcal{B})\)에서 \(\sigma\)-field의 원소를 사용하여 \([0,\infty]\)의 값을 반환하는 일종의 집합 합수(set function)이다.<br />
\begin{equation} 
\begin{aligned} 
\mu : \mathcal{B} \rightarrow [0, \infty]
\end{aligned} 
\end{equation}
    <ul>
      <li>\(\mu(\emptyset) = 0\): 공집합에 대한 측도응 0이다.<br /></li>
      <li>서로소 집합들 \(A_j\), \(A_j\) 들에 대하여 \(\mu(\cup_{i=1}^{\infty} A_i) = \sum_{i=1}^{\infty} \mu(A_i)\)이 성립한다.</li>
    </ul>
  </li>
</ul>

<p><br /></p>
<ul>
  <li><strong>확률(Probability)</strong><br />
확률(Probability)이란 전체집합 \(U\)에 대하여 \(\mu(U)=1\)의 크기를 만족하도록 정규화된 측도(Nomarlized Measure)를 의미한다.</li>
</ul>

<p><br /></p>

<p>확률은 전체 표본공간에 대한 확률의 총량이 1인 측도라고 할 수 있다.</p>

<hr />

<h3 id="확률-변수의-정의">확률 변수의 정의</h3>
<p>이제 확률 변수의 정의를 살펴볼 시간이다.</p>

<p class="info"><strong>정의</strong>   확률 변수 \(x\)는 표본공간 \(\Omega\) 에 정의된 함수를 의미한다. 이 함수는 확률공간\((\Omega, \mathcal{F}, P)\) 의 하나의 원소를 Borel 가측공간 \((\mathbb{R}, \mathcal{B})\) 의 원소로 변환하는 역할을 수행한다.<br /></p>

<p>여기서, 실수들의 집합으로 만들어진 공간을 Borel 가측공간(mesurable space)라고 하며, 이 때 \(\sigma\)-field를 Borel set이라고 한다.</p>

<details>
<summary>Borel 가측공간</summary>
<div>

    <p><strong>Borel 가측공간 (Borel Measurable Space)</strong>: 실수 집합 \(\mathbb{R}\) 과 Borel 시그마-대수 \(\mathcal{B}\) 로 구성된다. Borel 시그마-대수는 실수선 위에서 열린 구간을 포함하고, 이로부터 생성될 수 있는 모든 집합의 컬렉션이다. 이것은 기본적으로 우리가 흔히 다루는 실수 세계의 사건들을 측정 가능하게 한다.</p>

  </div>
</details>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/random_variables/definition_random_variable_2.png" />
</p>

<ul>
  <li>\(\Omega\) : 표본공간(sample space)라고 하며, 나올 수 있는 원소들의 전체 집합(=set)을 의미한다</li>
  <li>\(\mathcal{F}\) : 표본공간의 부분집합을 의미하며 사건(event)이라고 부른다.</li>
  <li>\(Pr\) : 측도(measure)를 수행하는 연산자로써 표본공간의 원소에 확률을 부여하는 역할한다.</li>
</ul>

<p>꽤나 어려운 개념들을 거쳐왔지만 결론적으로 확률 변수란 <strong>표본공간의 하나의 원소를 실수값으로 변환해주는 함수</strong>이다. 또한 이를 정의함으로써 우리는 실직절으로 확률 변수$x$의 확률인 $Pr(x)$의 활용에 관심을 갖게 된다.</p>

<h2 id="확률-변수의-유형">확률 변수의 유형</h2>
<p>확률 변수는 크게 이산형 확률 변수와 연속형 확률 변수로 분류된다.
주사위 던지기, 야구경기 점수와 같이 유한하거나 셀 수 있는 무한한 값을 가지는 확률 변수를 이산형 확률변수라고 한다.
반면에 온도, 기간, 속력, 무게 등</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/random_variables/types of random variables.webp" />
</p>
<!-- <p align="center">
  <img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rIxj8CrYFPE9bT2d.png">
</p> -->

<p><br /><br />
<strong>참조</strong></p>

<p><a href="https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf">Probability and Statistics for Data Science (Carlos Fernandez-Granda)</a><br />
<a href="https://alida.tistory.com/84">ALIDA (Gyubeom Edward Im)</a><br />
<a href="https://jagan-singhh.medium.com/types-of-probability-distributions-9333d18ed817">Types of Probability Distributions (Jagandeep Singh)</a></p>]]></content><author><name>Jenny Won (Dajeong Won)</name></author><category term="통계학" /><summary type="html"><![CDATA[확률 변수를 쉽게 설명하자면 무작위적인 시행(Random Process)에 따른 결과를 숫자로 연결하는 것이라고 이해할 수 있다. 가장 일반적인 예로 동전 던지기가 있다. 임의로 동전을 5번 던져서 나온 앞면의 합계는 확률 변수라고 할 수 있다. 동전을 5번 던지는 행위가 무작위 시행이라는 것을 이해하기 어렵지 않은, 꽤나 직관적인 개념이다. 그렇다면 이러한 결과를 수치로 연결한다는 것은 어떤 의미가 있을까? 이를 이해하기 위해 수학의 입장에서 ‘크기 혹은 규모’에 대해서 이야기 해보려고 한다. 주사위 던지기와 같은 무작위적 시행의 결과는 불확실성을 갖는다. 이러한 ‘얼마나’라는 불확실성의 크기를 수학적으로 표현할 수 있을까? 물론 그 결과가 수치로써 표현된다면 가장 직관적인 해석이 가능할 것이다. 심지어 연산도 가능하다면?… 이러한 접근에서 확률 변수를 정의하는 것의 가치를 이해해 볼 수 있다. 사실 이 정도의 이해만으로도 충분할 수 있다. 하지만 보다 학문적 공부를 진행해보고자 확률 변수의 개념을 수학적으로 탐색해 보고자 한다. 수학적 접근 확률론에서 정의하는 확률 변수를 이해하기 위해서는 선행되어야 할 개념들이 있다. 수학적으로 꽤나 심도있는 이해를 요구하지만 가능하다면 직관적으로 이해해 보려고 한다. 차근차근 확률 변수의 수학적 정의에 접근해보자. 측도론(Measure Theory) 측도(Measure)라는 개념을 먼저 이해하기 위해 ‘컵에 물이 담겨져 있는 상황’을 가정해보자. ‘물이 얼마나 담겨 있을까?’라는 질문에 답을 하기 위해 우리는 '부피'를 정의하고 측정한다. 3차원 입체라는 어떠한 집합에 ‘부피’라는 크기를 부여하게 된다면, 이는 그 집합에 '크기'라는 개념을 부여하는 것이 된다. 이를 수학에서 측도(Measure)라고 한다. 측도론은 크기, 면적, 부피 등의 일반화한 측도(Measure)의 개념을 다루는 분야로, 집합과 함수의 크기를 측정하고 분석하는 이론이다. 이 이론은 특히 확률론과 함수해석학에서 중요한 역할을 하는데, 우리가 확률을 공부하면서 자꾸만 집합을 마주치는 이유이기도 하다. 중요한 것은, 우리가 이야기하는 ‘확률’이 바로 이러한 크기라는 속성을 나타내는 ‘측도’라는 것이다. 따라서 측도론에 기반하여 확률을 이해할 수 있어서야 비로소 그 정의를 이해할 수 있다. 확률(Probability) 우리는 어떠한 현상으로부터 결과를 얻기 위해 실험(Experiment)을 하고, 실현값(Outcome)을 얻을 수 있다. 실현값이라는 단어가 다소 생소하게 느껴질 수 있다. 이는 결과값 즉, Outcome이라고 생각한다면 이해가 쉬워진다. 자, 그럼 주사위 던지기라는 확률 실험(Random Experiment)을 통해 측도론에 기반한 확률의 개념을 이해해 보자. 표본공간 \(\Omega=\{1,2,3,4,5,6\}\) 에서 주사위의 눈이 2가 나오는 사건(Event, \(\mathcal{F}\))의 크기를 수학적으로 말하기 위해, 우리는 확률 \(Pr(\cdot)\) 라는 측도를 사용할 수 있다. 그리고 이를 정의함으로써 \(Pr(2) = 1/6\) 와 같은 실현값(Outcome)을 얻을 수 있게 된다. \[\begin{equation}  \begin{aligned}  &amp; Pr(1) = Pr(2) = Pr(3) = Pr(4) = Pr(5) = Pr(6) = 1/6 \end{aligned}  \end{equation}\] 다시말해, ‘확률’은 이러한 확률 실험(Random Experiment)의 실현값(Realization)에 대한 측도(Measure)이며, 우리는 확률 \(Pr(\cdot)\)이라는 측도를 사용하여 공간 내 원소의 크기를 측정한 실현값(Realization)을 얻을 수 있다. \(\sigma\)-field \(\mathcal{B}\) 이렇게 측도라는 개념을 도입하여 확률을 모순없이 정의하기 위해서는 측정 대상을 엄밀히 정의하는 과정이 필요한데, 그러한 측정대상을 정의하는 것이 바로 \(\sigma\)-field이다. \(\sigma\)-field는 다음과 같이 정의되는 집합들의 모입이다. (i) $\emptyset \in \mathcal{B}$ (ii) $A \in \mathcal{B} \Rightarrow A^c \in \mathcal{B}$ (iii) $A_i \in \mathcal{B} \Rightarrow \cup_{i=1}^{\infty}A_i \in \mathcal{B}$ (i)공집합이 아니면서, (ii)여집합, 그리고 (iii) 셀 수 있는 합집합, 교집합에 대하여 닫혀있는 집합 S의 부분집합의 모임이라고 정의된다. 이러한 집합의 모입이 주어졌을 때, 측정할 수 있는 공간, 즉 가측공간(Measurable Space)를 정의할 수 있고, 측도와 확률을 모순없이 정의할 수 있다. 측도(Measure) 측도\(\mu\)란 가측공간 \((U, \mathcal{B})\)에서 \(\sigma\)-field의 원소를 사용하여 \([0,\infty]\)의 값을 반환하는 일종의 집합 합수(set function)이다. \begin{equation}  \begin{aligned}  \mu : \mathcal{B} \rightarrow [0, \infty] \end{aligned}  \end{equation} \(\mu(\emptyset) = 0\): 공집합에 대한 측도응 0이다. 서로소 집합들 \(A_j\), \(A_j\) 들에 대하여 \(\mu(\cup_{i=1}^{\infty} A_i) = \sum_{i=1}^{\infty} \mu(A_i)\)이 성립한다. 확률(Probability) 확률(Probability)이란 전체집합 \(U\)에 대하여 \(\mu(U)=1\)의 크기를 만족하도록 정규화된 측도(Nomarlized Measure)를 의미한다. 확률은 전체 표본공간에 대한 확률의 총량이 1인 측도라고 할 수 있다. 확률 변수의 정의 이제 확률 변수의 정의를 살펴볼 시간이다. 정의   확률 변수 \(x\)는 표본공간 \(\Omega\) 에 정의된 함수를 의미한다. 이 함수는 확률공간\((\Omega, \mathcal{F}, P)\) 의 하나의 원소를 Borel 가측공간 \((\mathbb{R}, \mathcal{B})\) 의 원소로 변환하는 역할을 수행한다. 여기서, 실수들의 집합으로 만들어진 공간을 Borel 가측공간(mesurable space)라고 하며, 이 때 \(\sigma\)-field를 Borel set이라고 한다. Borel 가측공간 Borel 가측공간 (Borel Measurable Space): 실수 집합 \(\mathbb{R}\) 과 Borel 시그마-대수 \(\mathcal{B}\) 로 구성된다. Borel 시그마-대수는 실수선 위에서 열린 구간을 포함하고, 이로부터 생성될 수 있는 모든 집합의 컬렉션이다. 이것은 기본적으로 우리가 흔히 다루는 실수 세계의 사건들을 측정 가능하게 한다. \(\Omega\) : 표본공간(sample space)라고 하며, 나올 수 있는 원소들의 전체 집합(=set)을 의미한다 \(\mathcal{F}\) : 표본공간의 부분집합을 의미하며 사건(event)이라고 부른다. \(Pr\) : 측도(measure)를 수행하는 연산자로써 표본공간의 원소에 확률을 부여하는 역할한다. 꽤나 어려운 개념들을 거쳐왔지만 결론적으로 확률 변수란 표본공간의 하나의 원소를 실수값으로 변환해주는 함수이다. 또한 이를 정의함으로써 우리는 실직절으로 확률 변수$x$의 확률인 $Pr(x)$의 활용에 관심을 갖게 된다. 확률 변수의 유형 확률 변수는 크게 이산형 확률 변수와 연속형 확률 변수로 분류된다. 주사위 던지기, 야구경기 점수와 같이 유한하거나 셀 수 있는 무한한 값을 가지는 확률 변수를 이산형 확률변수라고 한다. 반면에 온도, 기간, 속력, 무게 등 참조 Probability and Statistics for Data Science (Carlos Fernandez-Granda) ALIDA (Gyubeom Edward Im) Types of Probability Distributions (Jagandeep Singh)]]></summary></entry></feed>