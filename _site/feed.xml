<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-03-29T23:01:49+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">JenDS</title><subtitle>JenDS by Jenny Won
</subtitle><author><name>Jenny Won (Dajeong Won)</name></author><entry xml:lang="ko"><title type="html">기하 분포</title><link href="http://localhost:4000/2024/03/28/geometric_distribution_ko.html" rel="alternate" type="text/html" title="기하 분포" /><published>2024-03-28T00:00:00+09:00</published><updated>2024-03-28T00:00:00+09:00</updated><id>http://localhost:4000/2024/03/28/geometric_distribution_ko</id><content type="html" xml:base="http://localhost:4000/2024/03/28/geometric_distribution_ko.html"><![CDATA[<p><a href="https://jenniione.github.io/2024/03/27/binomial_distribution_ko.html">이항 분포</a>에 대한 개념을 잘 이해했다면 기하 분포를 그리 어려운 개념은 아니다.
이항 분포가 베르누이 시행에 따른 ‘성공’을 관찰하는 분포라면, 기하 분포는 <strong>‘성공할 때까지의 시행횟수’</strong> 혹은 <strong>‘성공할 때까지의 실패 횟수’</strong> 의 분포이다.</p>

<h2 id="기하-분포의-정의">기하 분포의 정의</h2>
<p class="info"><strong>정의(1)</strong>   기하 분포(Geometric Distribution)은 이항 분포와 같이 여러번의 베르누이 시행에서 처음 성공이 나타날 때까지의 시행 횟수 횟수를 모델링한 확률 분포이다.</p>
<p class="info"><strong>정의(2)</strong>   기하 분포(Geometric Distribution)은 이항 분포와 같이 여러번의 베르누이 시행에서 첫 번째 성공이 나타날 때까지의 (실패)시행 횟수를 모델링한 확률 분포이다.</p>

<p>기하 분포는 성공하기까지의 시도 횟수를 모델링하는 데 사용되며, 이에 대한 두 가지 정의가 있다. 이 두 정의의 주요 차이는 성공을 달성하기까지의 시도 횟수에 대한 계산 방법에 있다. 정의 (1)는 첫 성공이 포함된 전체 시도 횟수를 사용하는 반면, 정의 (2)는 첫 성공을 달성하기 전까지의 시도 횟수만을 고려한다.</p>

<p>동전 던지기를 예로 들면, 성공을 앞면이 나오는 경우로 정의할 때, ‘뒷면-뒷면-뒷면-앞면’이라는 결과가 나왔다고 가정하자. 이 상황에서 정의 (1)은 성공까지의 시도 횟수 $X$는 $4$가 된다. 반면에 정의 (2)를 적용하면, 첫 성공을 달성하기 전까지의 시도 횟수, 즉 3이 X의 값으로 사용된다. 이렇게 두 정의는 성공을 포함하는지 여부에 따라 1만큼의 차이를 보이며, 이는 기하 분포를 해석할 때 중요한 고려 사항이 된다.</p>

<p>기하 분포는 다음과 같이 표기하며,</p>

\[\begin{equation} 
 \begin{aligned} 
x \sim \text{Geom}(p)
\end{aligned}   
\end{equation}\]

<p>그 확률 질량 함수(PMF)는 다음과 같다.</p>

\[\begin{equation} 
\boxed{ \begin{aligned} 
P(x) = (1-p)^{k-1} p \quad \text{ for } k =1,2,\cdots
\end{aligned} }  
\end{equation}\]

<p>## 
확률 밀도 함수를 이해하기 위해, 10번의 동전 던지기 예시를 다시 보자. ‘성공’이라는 앞면이 나올 때까지 시행 횟수는 \(X=x\)라고 하자. \(x=3\)일 때, 그 확률은 (실패 확률) $\cdot$ (실패 확률) $\cdot$ (성공 확률), 즉 \((1-\frac{1}{2})^2(\frac{1}{2})=0.125\)이 된다.</p>

<h2 id="기하-분포의-무기억성">기하 분포의 무기억성</h2>
<p>기하 분포의 특징에는 무기억성이 있다. 수학적으로는 다음과 같이 표현할 수 있다.</p>

\[P(X &gt; s + t | X &gt; s) = P(X &gt; t)\]

<p>이것은 과거의 결과가 미래의 확률에 영향을 주지 않는다는 것을 의미한다. 동전 던지기를 통해 이미 6번의 뒷면이 나왔다고 하여도, 다음 동전 던지기의 앞면이 나올 확률은 여전히 \(1/2\)이다. 또한 7번째 던지기에서 이전에 6번을 던졌다는 사실은 영향을 미치지 않는다. 다시 처음부터 시작해도 첫 성공까지의 기대 시도 횟수는 변하지 않는다는 것이다.</p>

<p>이러한 기하 분포의 무기억성은 네트워크 트래픽 분석, 대기열 이론 등에 유용하게 활용될 수 있다. 웹 서버 요청이 도착하는 시간 간격이 기하 분포를 따른다고 가정할 때, 이미 어느 정도 시간이 지났다 하여도 다음 요청이 도착할 때까지의 기대 시간은 변하지 않는다. 이는 대기  시간, 시스템의 처리량, 자원 할당 전략을 최적화하는데 중요한 역할을 한다.</p>

<h2 id="직관적-기하-분포">직관적 기하 분포</h2>
<p>기하 분포는 ‘성공’이 발생할 때까지 기다리는 관찰에 따른 결과이다. 이러한 특징은 웹사이트에서 사용자가 처음으로 구매를 하는데 필요한 페이지 방문 횟수, 즉, 실패 횟수를 분석하거나, 어떤 제품이나 서비스가 특정 기간 동안 실패하지 않고 지속될 확률을 계산하는 데에도 사용될 수 있다. 또한 A/B테스팅에서 특정 전략이 성공을 보이기까지의 시도 횟수를 분석하고 그 적략의 효율성을 평가할 수도 있다.</p>

<p><br /><br />
<strong>참조</strong></p>

<p><a href="https://www.geogebra.org/m/twbv2tmk">binomial and geometric distribution(pthao_nguyen, Zoran)</a></p>]]></content><author><name>Jenny Won (Dajeong Won)</name></author><category term="통계학" /><summary type="html"><![CDATA[이항 분포에 대한 개념을 잘 이해했다면 기하 분포를 그리 어려운 개념은 아니다. 이항 분포가 베르누이 시행에 따른 ‘성공’을 관찰하는 분포라면, 기하 분포는 ‘성공할 때까지의 시행횟수’ 혹은 ‘성공할 때까지의 실패 횟수’ 의 분포이다. 기하 분포의 정의 정의(1)   기하 분포(Geometric Distribution)은 이항 분포와 같이 여러번의 베르누이 시행에서 처음 성공이 나타날 때까지의 시행 횟수 횟수를 모델링한 확률 분포이다. 정의(2)   기하 분포(Geometric Distribution)은 이항 분포와 같이 여러번의 베르누이 시행에서 첫 번째 성공이 나타날 때까지의 (실패)시행 횟수를 모델링한 확률 분포이다. 기하 분포는 성공하기까지의 시도 횟수를 모델링하는 데 사용되며, 이에 대한 두 가지 정의가 있다. 이 두 정의의 주요 차이는 성공을 달성하기까지의 시도 횟수에 대한 계산 방법에 있다. 정의 (1)는 첫 성공이 포함된 전체 시도 횟수를 사용하는 반면, 정의 (2)는 첫 성공을 달성하기 전까지의 시도 횟수만을 고려한다. 동전 던지기를 예로 들면, 성공을 앞면이 나오는 경우로 정의할 때, ‘뒷면-뒷면-뒷면-앞면’이라는 결과가 나왔다고 가정하자. 이 상황에서 정의 (1)은 성공까지의 시도 횟수 $X$는 $4$가 된다. 반면에 정의 (2)를 적용하면, 첫 성공을 달성하기 전까지의 시도 횟수, 즉 3이 X의 값으로 사용된다. 이렇게 두 정의는 성공을 포함하는지 여부에 따라 1만큼의 차이를 보이며, 이는 기하 분포를 해석할 때 중요한 고려 사항이 된다. 기하 분포는 다음과 같이 표기하며, \[\begin{equation}   \begin{aligned}  x \sim \text{Geom}(p) \end{aligned}    \end{equation}\] 그 확률 질량 함수(PMF)는 다음과 같다. \[\begin{equation}  \boxed{ \begin{aligned}  P(x) = (1-p)^{k-1} p \quad \text{ for } k =1,2,\cdots \end{aligned} }   \end{equation}\] ## 확률 밀도 함수를 이해하기 위해, 10번의 동전 던지기 예시를 다시 보자. ‘성공’이라는 앞면이 나올 때까지 시행 횟수는 \(X=x\)라고 하자. \(x=3\)일 때, 그 확률은 (실패 확률) $\cdot$ (실패 확률) $\cdot$ (성공 확률), 즉 \((1-\frac{1}{2})^2(\frac{1}{2})=0.125\)이 된다. 기하 분포의 무기억성 기하 분포의 특징에는 무기억성이 있다. 수학적으로는 다음과 같이 표현할 수 있다. \[P(X &gt; s + t | X &gt; s) = P(X &gt; t)\] 이것은 과거의 결과가 미래의 확률에 영향을 주지 않는다는 것을 의미한다. 동전 던지기를 통해 이미 6번의 뒷면이 나왔다고 하여도, 다음 동전 던지기의 앞면이 나올 확률은 여전히 \(1/2\)이다. 또한 7번째 던지기에서 이전에 6번을 던졌다는 사실은 영향을 미치지 않는다. 다시 처음부터 시작해도 첫 성공까지의 기대 시도 횟수는 변하지 않는다는 것이다. 이러한 기하 분포의 무기억성은 네트워크 트래픽 분석, 대기열 이론 등에 유용하게 활용될 수 있다. 웹 서버 요청이 도착하는 시간 간격이 기하 분포를 따른다고 가정할 때, 이미 어느 정도 시간이 지났다 하여도 다음 요청이 도착할 때까지의 기대 시간은 변하지 않는다. 이는 대기 시간, 시스템의 처리량, 자원 할당 전략을 최적화하는데 중요한 역할을 한다. 직관적 기하 분포 기하 분포는 ‘성공’이 발생할 때까지 기다리는 관찰에 따른 결과이다. 이러한 특징은 웹사이트에서 사용자가 처음으로 구매를 하는데 필요한 페이지 방문 횟수, 즉, 실패 횟수를 분석하거나, 어떤 제품이나 서비스가 특정 기간 동안 실패하지 않고 지속될 확률을 계산하는 데에도 사용될 수 있다. 또한 A/B테스팅에서 특정 전략이 성공을 보이기까지의 시도 횟수를 분석하고 그 적략의 효율성을 평가할 수도 있다. 참조 binomial and geometric distribution(pthao_nguyen, Zoran)]]></summary></entry><entry xml:lang="ko"><title type="html">Binomial Distribution</title><link href="http://localhost:4000/2024/03/27/binomial_distribution_en.html" rel="alternate" type="text/html" title="Binomial Distribution" /><published>2024-03-27T00:00:00+09:00</published><updated>2024-03-27T00:00:00+09:00</updated><id>http://localhost:4000/2024/03/27/binomial_distribution_en</id><content type="html" xml:base="http://localhost:4000/2024/03/27/binomial_distribution_en.html"><![CDATA[<p>Before diving into the binomial distribution, let’s briefly summarize the Bernoulli distribution and explore its relationship with the binomial distribution.</p>

<h2 id="bernoulli-distribution">Bernoulli Distribution</h2>
<p>A Bernoulli experiment refers to a probability experiment where the outcome can either be a success or a failure. The probability distribution that represents the number of successes in a Bernoulli experiment, with a fixed success probability \(p\), is known as the <strong>Bernoulli distribution</strong>. Therefore, the Bernoulli distribution is a probability distribution where the value of the random variable is either a success or a failure. Since <strong>the outcome can only be one of two values, success or failure</strong>, a Bernoulli random variable is classified as a <strong>discrete random variable</strong>.</p>

<p>one where the outcome can either be a success or a failure. The probability distribution that accounts for the number of successes in a Bernoulli experiment, with a fixed probability of success \(p\), is the Bernoulli distribution.</p>

\[x  \{ \text{success, fail} \} \rightarrow \{0, 1\}\]

\[\begin{equation}
\begin{aligned}
&amp; P(x=0) = 1-p \\
&amp; P(x=1) = p \\ \end{aligned}
\end{equation}\]

<p>If the random variable \(X\) follows a Bernoulli distribution, it can be expressed as follows:</p>

\[\begin{equation} 
 \begin{aligned} 
&amp; x \sim \text{Bern}(p)
\end{aligned}   
\end{equation}\]

<p>And its Probability Mass Function (PMF) can be represented by the following formula:</p>

\[\begin{split}
\begin{align}
\text{Bern}(x; p) = 
\begin{cases} 
p   &amp; \text{if }x=1, \\
1-p &amp; \text{if }x=0
\end{cases}
\tag{8.2.2}
\end{align}
\end{split}\]

<p>It is important to note that the Bernoulli distribution focuses on observational data from the result of <strong>a single trial</strong>, emphasizing the <strong>probability of success \(p\)</strong>. This aspect explains how the binomial distribution differs from the Bernoulli distribution.</p>

<h2 id="definition-of-binomial-distribution">Definition of Binomial Distribution</h2>
<p class="info"><strong>Definition</strong>   The Binomial Distribution models the number of successes in a fixed number \(n\) of repeated Bernoulli trials, each with the same success probability \(p\).</p>

<p>The binomial distribution is the probability distribution obtained by repeating a Bernoulli trial \(n\) times. In other words, <strong>the binomial distribution is an extension of the Bernoulli trial</strong>. It models the probability distribution of the number of successes in \(n\) repeated Bernoulli trials, not just a single Bernoulli trial. 
For example, consider the example of flipping a coin. When you perform a single coin toss with the probability of getting heads being \(p=1/2\); the outcome follows a Bernoulli distribution. However, if the same coin is flipped 10 times, and the number of times heads appears is observed, this scenario follows a binomial distribution. The key here is that during the 10 flips, <strong>each flip is independent, and the probability of success for each trial remains constant at \(p\)</strong> (as is the case with a fixed \(p\) in a Bernoulli trial).</p>

<p>The binomial distribution can be expressed as follows,
\(\begin{equation} 
 \begin{aligned} 
x \sim \text{Bin}(n,p)
\end{aligned}   
\end{equation}\)</p>

<p>ans its Probability Mass Function (PMF) is defined as follows.</p>

\[\begin{equation} 
P_X(x) = \ _{n}C_{x} p^k (1-p)^{n-x} \quad \text{ for } x =0,1,\cdots,n
\end{equation}\]

<h2 id="real-insights-into-the-binomial-distribution">Real Insights into the Binomial Distribution</h2>
<h3 id="example-of-flipping-a-coin-10-times">Example of Flipping a Coin 10 Times</h3>

<p>To grasp the Probability Mass Function, let’s calculate the probability of outcomes in the scenario of flipping a coin 10 times.
Consider a success as the coin landing on heads, and let \(x\) be the number of successes. Thus, \(x=0,1,2,⋯,10\), representing the scenarios where the coin lands on heads 0 times, 1 time, 2 times, … up to 10 times. Let’s consider the probability when \(x=2\), that is, the probability of the coin landing on heads 2 times in 10 flips.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/coin k=2.png" />
</p>

<p>As illustrated, each independent event of the coin landing on heads 2 times out of 10 flips has a probability of \((\frac{1}{2})^2(1-\frac{1}{2})^{8}\). This can occur in \(_{10}C_{2}\) different ways. The calculation is as follows:</p>

\[_{10}C_{2}\left(\frac{1}{2}\right)^2 \left(1-\frac{1}{2}\right)^{8} = 0.0439\]

<p>Using the same method, calculating the probabilities for all values of \(x\) yields the following results:</p>

\[x=0 ;  \frac{10!}{1!\cdot9!}
\left(\frac{1}{2}\right)^0 \left(1-\frac{1}{2}\right)^{10} = 0.0010\]

\[x=1 ;  \frac{10!}{1!\cdot9!}
\left(\frac{1}{2}\right)^1 \left(1-\frac{1}{2}\right)^{9} = 0.0098\]

\[x=2 ; \frac{10!}{2! 8!}\left(\frac{1}{2}\right)^2 \left(1-\frac{1}{2}\right)^{8} = 0.0439\]

<center>⋮</center>

\[x=10 ; \frac{10!}{10! 0!}\left(\frac{1}{2}\right)^{10} \left(1-\frac{1}{2}\right)^{0} = 0.0010\]

<p>If represented as a histogram, it would appear as follows.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/coin distribution.png" />
</p>

<h3 id="an-intuitive-look-at-binomial-distribution">An Intuitive Look at Binomial Distribution</h3>

<p>The binomial distribution is used to calculate the probability of obtaining certain outcomes from repeating a probabilistic event, like flipping a coin, that has two possible results, multiple times.</p>

<p>To understand how it can be applied in practice for a more intuitive comprehension, let’s look into scenarios where the binomial distribution is considered.</p>

<ul>
  <li>Example 1<br />
Suppose a marketing team sends emails to 1,000 customers individually. Based on previous experience, let’s assume the probability of receiving a reply is 0.5. What then is the probability of receiving replies from 50 customers out of the 1,000 emails sent?</li>
</ul>

<p>This is a simple problem of calculating the binomial distribution probability \(P_X(50)\) with \(n=1,000\), \(p=0.5\). The binomial distribution fundamentally <strong>utilizes the number of trials and the fixed probability of success</strong> to calculate the <strong>probability of success occurring</strong>.</p>

<p>Furthermore, the concept of the binomial distribution can be utilized in conducting A/B tests. Consider the example below.</p>

<ul>
  <li>Example 2<br />
Let’s assume an A/B test is conducted to compare the effectiveness of two designs (A and B) in increasing the click-through rate on a website. Suppose design B was shown to 1,000 visitors to the website, and 150 clicked on it. We want to assess whether the click-through rate for design B is statistically significantly different from a 10% click-through rate for design A.</li>
</ul>

<p>Assuming the independence of each visitor’s click action, the action of clicking by each website visitor results in a binomial outcome of click (success) or no click (failure). With the success probability \(p\) set to 10%, the number of trials \(n\) to 1,000, and the number of successes to 150, we can perform a binomial test.</p>

<h2 id="mean-and-variance-of-binomial-distribution">Mean and Variance of Binomial Distribution</h2>
<p>For a random variable \(X\) following a binomial distribution with a total number of trials \(n\) and a success probability \(p\),</p>

<p>the mean are</p>

\[E(X) = np\]

<p>and the variance are</p>

\[Var(X) = np(1-p)\]

<p>The proofs for each are as follows:</p>

<p>\(\begin{split}
\begin{align}
\begin{aligned}
\text{E}[X] 
&amp;= \sum_{x_i \in \Omega} x_i p(x_i) \\
&amp;= 1 \cdot \mu + 0 \cdot (1 - \mu) \\
&amp;= \mu
\end{aligned}
\end{align}
\end{split}\)
<br /></p>

\[\begin{split}
\begin{align}
\begin{aligned}
\text{Var}[X] 
&amp;= \sum_{x_i \in \Omega} (x_i - \mu)^2 p(x_i) \\
&amp;= (1 - \mu)^2 \cdot \mu + (0 - \mu)^2 \cdot (1 - \mu) \\
&amp;= \mu(1-\mu)
\end{aligned}
\end{align}
\end{split}\]

<h2 id="the-normal-approximation-to-the-binomial-distribution">The Normal Approximation to the Binomial Distribution</h2>
<p>As we adjust the parameters of the binomial distribution, let’s explore the various shapes it can exhibit. There are numerous simulatiors accessible online for this purpose, such as the “Parameters of the Binomial Distribution” simulation by shanlee on GeoGebra.
What transformation does the binomial distribution undergo as \(n\), the number of trials, continues to increase?</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/binomial distribution to normal distribution.png" />
</p>

<p>When conducting 50 coin flips, one can observe that the resulting distribution resembles the <strong>bell shape</strong> of a normal distribution. However, by operating the simulation directly, it’s discernible that this approximation is <strong>only feasible when the values of \(n\) and \(p\) are not extreme</strong>. If \(n\) is too small, or if \(n\) is sufficiently large but \(p\) is too small or too large, the shape deviates significantly from that of a normal distribution.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/small n.png" />
</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/small p.png" />
</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/huge p.png" />
</p>

<p>Mathetically, if the number of trials \(n\) in a binomial distribution is sufficiently large such that \(np≥5\) and \(np(1−p)≥5\), then the binomial distribution can be approximated by a normal distribution with mean \(np\) and variance \(np(1−p)\). This can be intuitively understood through simulation. Directly operating the simulation reveals that the approximation to a normal distribution becomes <strong>more accurate as \(n\) increases, and as \(p\) is not too close to 0 or 1 but closer to 0.5</strong>.</p>

<p>How many hits might a baseball player with a .300 batting average get in 100 at-bats? How many people might actually die if 100 people were infected with a disease with a 30% mortality rate? Many real-world events can be said to follow a binomial distribution. If the normal distribution can represent an approximation of the binomial distribution, then the normal distribution can also describe many events.</p>

<p><br /><br />
<strong>References</strong></p>

<p><a href="https://www.geogebra.org/m/hMuamz5w">Binomial Distribution Image Generator(Michael Borcherds)</a><br />
<a href="https://www.geogebra.org/m/hGkW4vwJ">Parameters of the Binomial Distribution(shanlee)</a><br />
<a href="https://datascienceschool.net/02%20mathematics/08.02%20%EB%B2%A0%EB%A5%B4%EB%88%84%EC%9D%B4%EB%B6%84%ED%8F%AC%EC%99%80%20%EC%9D%B4%ED%95%AD%EB%B6%84%ED%8F%AC.html">데이터 사이언스 스쿨</a><br />
<a href="https://bookdown.org/mathemedicine/Stat_book/normal-distribution.html#-1">기초통계 개념정리(김진섭)</a><br /></p>]]></content><author><name>Jenny Won (Dajeong Won)</name></author><category term="Statistics" /><summary type="html"><![CDATA[Before diving into the binomial distribution, let’s briefly summarize the Bernoulli distribution and explore its relationship with the binomial distribution. Bernoulli Distribution A Bernoulli experiment refers to a probability experiment where the outcome can either be a success or a failure. The probability distribution that represents the number of successes in a Bernoulli experiment, with a fixed success probability \(p\), is known as the Bernoulli distribution. Therefore, the Bernoulli distribution is a probability distribution where the value of the random variable is either a success or a failure. Since the outcome can only be one of two values, success or failure, a Bernoulli random variable is classified as a discrete random variable. one where the outcome can either be a success or a failure. The probability distribution that accounts for the number of successes in a Bernoulli experiment, with a fixed probability of success \(p\), is the Bernoulli distribution. \[x  \{ \text{success, fail} \} \rightarrow \{0, 1\}\] \[\begin{equation} \begin{aligned} &amp; P(x=0) = 1-p \\ &amp; P(x=1) = p \\ \end{aligned} \end{equation}\] If the random variable \(X\) follows a Bernoulli distribution, it can be expressed as follows: \[\begin{equation}   \begin{aligned}  &amp; x \sim \text{Bern}(p) \end{aligned}    \end{equation}\] And its Probability Mass Function (PMF) can be represented by the following formula: \[\begin{split} \begin{align} \text{Bern}(x; p) = \begin{cases} p &amp; \text{if }x=1, \\ 1-p &amp; \text{if }x=0 \end{cases} \tag{8.2.2} \end{align} \end{split}\] It is important to note that the Bernoulli distribution focuses on observational data from the result of a single trial, emphasizing the probability of success \(p\). This aspect explains how the binomial distribution differs from the Bernoulli distribution. Definition of Binomial Distribution Definition   The Binomial Distribution models the number of successes in a fixed number \(n\) of repeated Bernoulli trials, each with the same success probability \(p\). The binomial distribution is the probability distribution obtained by repeating a Bernoulli trial \(n\) times. In other words, the binomial distribution is an extension of the Bernoulli trial. It models the probability distribution of the number of successes in \(n\) repeated Bernoulli trials, not just a single Bernoulli trial. For example, consider the example of flipping a coin. When you perform a single coin toss with the probability of getting heads being \(p=1/2\); the outcome follows a Bernoulli distribution. However, if the same coin is flipped 10 times, and the number of times heads appears is observed, this scenario follows a binomial distribution. The key here is that during the 10 flips, each flip is independent, and the probability of success for each trial remains constant at \(p\) (as is the case with a fixed \(p\) in a Bernoulli trial). The binomial distribution can be expressed as follows, \(\begin{equation}   \begin{aligned}  x \sim \text{Bin}(n,p) \end{aligned}    \end{equation}\) ans its Probability Mass Function (PMF) is defined as follows. \[\begin{equation}  P_X(x) = \ _{n}C_{x} p^k (1-p)^{n-x} \quad \text{ for } x =0,1,\cdots,n \end{equation}\] Real Insights into the Binomial Distribution Example of Flipping a Coin 10 Times To grasp the Probability Mass Function, let’s calculate the probability of outcomes in the scenario of flipping a coin 10 times. Consider a success as the coin landing on heads, and let \(x\) be the number of successes. Thus, \(x=0,1,2,⋯,10\), representing the scenarios where the coin lands on heads 0 times, 1 time, 2 times, … up to 10 times. Let’s consider the probability when \(x=2\), that is, the probability of the coin landing on heads 2 times in 10 flips. As illustrated, each independent event of the coin landing on heads 2 times out of 10 flips has a probability of \((\frac{1}{2})^2(1-\frac{1}{2})^{8}\). This can occur in \(_{10}C_{2}\) different ways. The calculation is as follows: \[_{10}C_{2}\left(\frac{1}{2}\right)^2 \left(1-\frac{1}{2}\right)^{8} = 0.0439\] Using the same method, calculating the probabilities for all values of \(x\) yields the following results: \[x=0 ; \frac{10!}{1!\cdot9!} \left(\frac{1}{2}\right)^0 \left(1-\frac{1}{2}\right)^{10} = 0.0010\] \[x=1 ; \frac{10!}{1!\cdot9!} \left(\frac{1}{2}\right)^1 \left(1-\frac{1}{2}\right)^{9} = 0.0098\] \[x=2 ; \frac{10!}{2! 8!}\left(\frac{1}{2}\right)^2 \left(1-\frac{1}{2}\right)^{8} = 0.0439\] ⋮ \[x=10 ; \frac{10!}{10! 0!}\left(\frac{1}{2}\right)^{10} \left(1-\frac{1}{2}\right)^{0} = 0.0010\] If represented as a histogram, it would appear as follows. An Intuitive Look at Binomial Distribution The binomial distribution is used to calculate the probability of obtaining certain outcomes from repeating a probabilistic event, like flipping a coin, that has two possible results, multiple times. To understand how it can be applied in practice for a more intuitive comprehension, let’s look into scenarios where the binomial distribution is considered. Example 1 Suppose a marketing team sends emails to 1,000 customers individually. Based on previous experience, let’s assume the probability of receiving a reply is 0.5. What then is the probability of receiving replies from 50 customers out of the 1,000 emails sent? This is a simple problem of calculating the binomial distribution probability \(P_X(50)\) with \(n=1,000\), \(p=0.5\). The binomial distribution fundamentally utilizes the number of trials and the fixed probability of success to calculate the probability of success occurring. Furthermore, the concept of the binomial distribution can be utilized in conducting A/B tests. Consider the example below. Example 2 Let’s assume an A/B test is conducted to compare the effectiveness of two designs (A and B) in increasing the click-through rate on a website. Suppose design B was shown to 1,000 visitors to the website, and 150 clicked on it. We want to assess whether the click-through rate for design B is statistically significantly different from a 10% click-through rate for design A. Assuming the independence of each visitor’s click action, the action of clicking by each website visitor results in a binomial outcome of click (success) or no click (failure). With the success probability \(p\) set to 10%, the number of trials \(n\) to 1,000, and the number of successes to 150, we can perform a binomial test. Mean and Variance of Binomial Distribution For a random variable \(X\) following a binomial distribution with a total number of trials \(n\) and a success probability \(p\), the mean are \[E(X) = np\] and the variance are \[Var(X) = np(1-p)\] The proofs for each are as follows: \(\begin{split} \begin{align} \begin{aligned} \text{E}[X] &amp;= \sum_{x_i \in \Omega} x_i p(x_i) \\ &amp;= 1 \cdot \mu + 0 \cdot (1 - \mu) \\ &amp;= \mu \end{aligned} \end{align} \end{split}\) \[\begin{split} \begin{align} \begin{aligned} \text{Var}[X] &amp;= \sum_{x_i \in \Omega} (x_i - \mu)^2 p(x_i) \\ &amp;= (1 - \mu)^2 \cdot \mu + (0 - \mu)^2 \cdot (1 - \mu) \\ &amp;= \mu(1-\mu) \end{aligned} \end{align} \end{split}\] The Normal Approximation to the Binomial Distribution As we adjust the parameters of the binomial distribution, let’s explore the various shapes it can exhibit. There are numerous simulatiors accessible online for this purpose, such as the “Parameters of the Binomial Distribution” simulation by shanlee on GeoGebra. What transformation does the binomial distribution undergo as \(n\), the number of trials, continues to increase? When conducting 50 coin flips, one can observe that the resulting distribution resembles the bell shape of a normal distribution. However, by operating the simulation directly, it’s discernible that this approximation is only feasible when the values of \(n\) and \(p\) are not extreme. If \(n\) is too small, or if \(n\) is sufficiently large but \(p\) is too small or too large, the shape deviates significantly from that of a normal distribution. Mathetically, if the number of trials \(n\) in a binomial distribution is sufficiently large such that \(np≥5\) and \(np(1−p)≥5\), then the binomial distribution can be approximated by a normal distribution with mean \(np\) and variance \(np(1−p)\). This can be intuitively understood through simulation. Directly operating the simulation reveals that the approximation to a normal distribution becomes more accurate as \(n\) increases, and as \(p\) is not too close to 0 or 1 but closer to 0.5. How many hits might a baseball player with a .300 batting average get in 100 at-bats? How many people might actually die if 100 people were infected with a disease with a 30% mortality rate? Many real-world events can be said to follow a binomial distribution. If the normal distribution can represent an approximation of the binomial distribution, then the normal distribution can also describe many events. References Binomial Distribution Image Generator(Michael Borcherds) Parameters of the Binomial Distribution(shanlee) 데이터 사이언스 스쿨 기초통계 개념정리(김진섭)]]></summary></entry><entry xml:lang="ko"><title type="html">이항 분포</title><link href="http://localhost:4000/2024/03/27/binomial_distribution_ko.html" rel="alternate" type="text/html" title="이항 분포" /><published>2024-03-27T00:00:00+09:00</published><updated>2024-03-27T00:00:00+09:00</updated><id>http://localhost:4000/2024/03/27/binomial_distribution_ko</id><content type="html" xml:base="http://localhost:4000/2024/03/27/binomial_distribution_ko.html"><![CDATA[<p>이항 분포에 앞서, 베르누이 분포에 대해 간략히 정리하고, 이항 분포와 베르누이 분포가 어떤 관계가 있는지 알아보자.</p>
<h2 id="베르누이-분포">베르누이 분포</h2>
<p>확률 실험의 결과가 성공 혹은 실패로 나타나는 실험을 베르누이 실험(Bernoulli Experiment)라고 한다. 그리고 성공 확률이 \(p\)로 고정된 베르누이 실험에서 성공의 횟수를 나타내는 확률 분포가 바로 <strong>베르누이 분포</strong>이다. 즉, 베르누이 분포는 <strong>확률 변수의 값이 성공 혹은 실패로 나타나는 확률 분포</strong>이며, 그 결과가 성공 혹은 실패, 두 값 중 하나만 가지므로 베르누이 확률 변수는 <strong>이산 확률 변수</strong>라고 할 수 있다.</p>

\[x  \{ \text{success, fail} \} \rightarrow \{0, 1\}\]

\[\begin{equation}
\begin{aligned}
&amp; P(x=0) = 1-p \\
&amp; P(x=1) = p \\ \end{aligned}
\end{equation}\]

<p>확률 변수 \(X\)가 베르누이 분포에 의해 발생된다면 다음과 같이 표현할 수 있다.</p>

\[\begin{equation} 
 \begin{aligned} 
&amp; x \sim \text{Bern}(p)
\end{aligned}   
\end{equation}\]

<p>그리고 그 확률 질량 함수(PMF)는 다음과 같이 수식으로 나타낼 수 있다. 
\(\begin{split}
\begin{align}
\text{Bern}(x; p) = 
\begin{cases} 
p   &amp; \text{if }x=1, \\
1-p &amp; \text{if }x=0
\end{cases}
\tag{8.2.2}
\end{align}
\end{split}\)</p>

<p>여기서 주목해야 할 점은, 베르누이 분포는 <strong>한번의 시행</strong>에 대한 결과에서 <strong>성공 확률 \(p\)</strong>에 집중한 관찰 데이터라는 점이다. 이 점은 이항 분포가 베르누이 분포와 어떻게 다른지를 설명하게 된다.</p>

<h2 id="이항-분포의-정의">이항 분포의 정의</h2>
<p class="info"><strong>정의</strong>   이항 분포(Binomial Distribution)은 동일한 확률 \(p\) 로 성공하는 베르누이 시행을 고정된 수 \(n\) 번을 반복할 때의 성공 횟수를 모델링하는 확률 분포이다.</p>

<p>이항 분포는 베르누이 시행을 \(n\)번 반복하여 얻게된 확률 분포이다. 다시말해, <strong>이항분포는 베르누이 시행의 확장</strong>이라고 할 수 있다. 단 한 번의 베르누이 시행이 아닌, \(n\)번의 반복된 베르누이 시행에서 성공 횟수에 대한 확률 분포를 모델링한 것이 바로 이항 분포이다.
동전 던지기의 예를 들어보자. 앞면이 나올 확률이 \(p=1/2\)인 동전 던지기를 한번 시행 했을때, 그 결과는 베르누이 분포를 따르게 된다. 하지만 동일한 동전을 10번 던지고 앞면이 나온 횟수를 관찰하는 경우, 이 시나리오는 이항 분포를 따르게 된다. 여기서 핵심은 10번 던지는 동안 <strong>각각의 던지기가 독립적이며, 각 시행의 성공 확률은 \(p\) 로 동일해야 한다</strong>는 점이다.(원래 베르누이 시행의 성공확률은 고정된 \(p\)를 갖는다.)</p>

<p>이항 분포는 다음과 같이 표현할 수 있으며,</p>

\[\begin{equation} 
 \begin{aligned} 
x \sim \text{Bin}(n,p)
\end{aligned}   
\end{equation}\]

<p>이항 분포의 확률 밀도 함수(PMF)는 다음과 같이 정의된다.</p>

\[\begin{equation} 
P_X(x) = \ _{n}C_{x} p^k (1-p)^{n-x} \quad \text{ for } x =0,1,\cdots,n
\end{equation}\]

<h2 id="이항-분포의-이해">이항 분포의 이해</h2>
<h3 id="10번의-동전-던지기-예시">10번의 동전 던지기 예시</h3>
<p>확률 질량 함수를 이해하기 위해서, 앞선 10번의 동전 던지기의 확률을 직접 구해보자.
앞면이 나오는 경우를 성공이라 하고, \(x\)를 성공 횟수라고 하자. 즉, \(x = 0, 1, 2, \cdots, 10\) 이고, 각각은 앞면이 0번, 1번, 2번, … 10번 나오는 경우를 의미할 것이다. \(x=2\)일 떄, 즉 10번의 시행 중 동전의 앞면이 2번 나오는 확률을 생각해 보자.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/coin k=2.png" />
</p>

<p>그림과 같이 각각의 독립된 \((\frac{1}{2})^2(1-\frac{1}{2})^{8}\)의 확률이 \( _{10}C_{2}\)의 경우의 수로 출현할 수 있다. 이것은 다음과 같이 계산된다.</p>

\[_{10}C_{2}\left(\frac{1}{2}\right)^2 \left(1-\frac{1}{2}\right)^{8} = 0.0439\]

<p>같은 방법으로, 모든 x에 대해서 그 확률을 계산해 보면 다음과 같다.</p>

\[x=0 ;  \frac{10!}{1!\cdot9!}
\left(\frac{1}{2}\right)^0 \left(1-\frac{1}{2}\right)^{10} = 0.0010\]

\[x=1 ;  \frac{10!}{1!\cdot9!}
\left(\frac{1}{2}\right)^1 \left(1-\frac{1}{2}\right)^{9} = 0.0098\]

\[x=2 ; \frac{10!}{2! 8!}\left(\frac{1}{2}\right)^2 \left(1-\frac{1}{2}\right)^{8} = 0.0439\]

<center>⋮</center>

\[x=10 ; \frac{10!}{10! 0!}\left(\frac{1}{2}\right)^{10} \left(1-\frac{1}{2}\right)^{0} = 0.0010\]

<p>이것을 히스토그램으로 나타내면 다음과 같다.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/coin distribution.png" />
</p>

<h3 id="직관적-이항-분포">직관적 이항 분포</h3>
<p>이항 분포는 동전 던지기처럼 두 가지 결과가 있는 확률적 사건을 몇 번 반복했을 때, 어떤 결과를 얻을 확률을 구하기 위해 사용된다.</p>

<p>실제로 어떻게 활용될 수 있는 지, 보다 직관적인 이해를 위해 실제로 이항 분포의 활용이 고려되는 알아보자.</p>

<ul>
  <li>예시 1<br />
마케팅 팀에서 1,000명의 고객에게 메일을 각각 발송했다. 이전의 경험을 토대로 회신을 받을 수 있는 확률이 0.5라고 가정하자. 자, 발송된 1,000개의 메일에 대해 50명의 고객으로 부터 회신을 받을 확률은 어떻게 될까?</li>
</ul>

<p>아주 간단한 \(n=1,000\), \(p=0.5\)인 이항 분포의 확률 \(P_X(50)\)을 구하는 문제이다.
이처럼 이항 분포는 기본적으로 <strong>시행 횟수와 성공 확률이 고정</strong>되었을 때, <strong>성공이 출현할 확률</strong>을 구할 때 활용될 수 있다.</p>

<p>또한, A/B테스를 진행하며 이항 분포의 개념이 활용될 수 있다. 아래 예시를 보자.</p>
<ul>
  <li>예시 2<br />
웹사이트의 버튼 클릭률을 높이기 위해 두 가지 디자인(A와 B)의 효과를 비교하는 A/B테스트를 수행한다고 가정해 보자. 웹사이트 방문자 1,000명에게 B디자인을 노출시킨 후, 150명이 클릭했다. 우리는 디자인 B의 클릭률이 디자인 A의 클릭률 10%와 통계적으로 유의미하게 다른지를 평가하고자 한다.</li>
</ul>

<p>방문자의 클릭 여부가 독립이라는 가정 하에, 각 웹사이트 방문자가 클릭하는 행위는 클릭(성공) 또는 비클릭(실패)의 이항 결과를 갖는다. 우리는 성공 확률 p를 10%, 시도 횟수 n은 1,000명, 성공 횟수 150명으로 설정하고 이항 검정을 수행할 수 있다.</p>

<h2 id="이항-분포의-평균과-분산">이항 분포의 평균과 분산</h2>
<p>총 시행 횟수가 \(n\), 성공 확률이 \(p\)인 이항 분포를 따르는 확률 변수 X에 대해,</p>

<p>기댓값은</p>

\[E(X) = np\]

<p>분산은</p>

\[Var(X) = np(1-p)\]

<p>이다. 각각의 증명은 다음과 같다.</p>

<p>\(\begin{split}
\begin{align}
\begin{aligned}
\text{E}[X] 
&amp;= \sum_{x_i \in \Omega} x_i p(x_i) \\
&amp;= 1 \cdot \mu + 0 \cdot (1 - \mu) \\
&amp;= \mu
\end{aligned}
\end{align}
\end{split}\)
<br /></p>

\[\begin{split}
\begin{align}
\begin{aligned}
\text{Var}[X] 
&amp;= \sum_{x_i \in \Omega} (x_i - \mu)^2 p(x_i) \\
&amp;= (1 - \mu)^2 \cdot \mu + (0 - \mu)^2 \cdot (1 - \mu) \\
&amp;= \mu(1-\mu)
\end{aligned}
\end{align}
\end{split}\]

<h2 id="이항-분포의-정규-분포-근사">이항 분포의 정규 분포 근사</h2>
<p>자, 그럼 이항 분포의 파라미터를 자유롭게 변경하며 이항 분포의 여러 모양을 관찰해 보자. 
이러한 결과를 쉽게 확인할 수 있는 다양한 시뮬레이션이 온라인에 공개되어 있고, 그 중  GeoGebra에서 Parameters of the Binomial Distribution(shanlee) 시뮬레이션을 활용했다.
n이 계속 증가한다면, 즉 시행을 많이 한다면 이항 분포는 어떻게 변할까?</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/binomial distribution to normal distribution.png" />
</p>

<p>50번의 동전 던지기를 시행했을 때 <strong>종모양(bell shape)</strong>의 정규 분포와 유사한 형태를 띄는 것을 확인할 수 있다. 하지만 시뮬레이션을 직접 작동해보면, <strong>$n$ 과 $p$ 의 값이 극단적이지 않은 경우에만 가능</strong>하다는 것을 알 수 있다. $n$ 이 너무 작거나, $n$ 이 충분히 크지만 $p$ 가 너무 작거나 클 경우 정규 분포의 모양과 많이 벗어나게 된다.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/small n.png" />
</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/small p.png" />
</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/binomial_distribution/huge p.png" />
</p>

<p>수학적으로 이항 분포의 $n$ 이 충분히 커서 $np&gt;=5$, $np(1-p)&gt;=5$ 조건을 만족하면, 이항 분포의 평균이 $np$, 분산이 $np(1-p)$ 인 정규 분포에 근사할 수 있다고 한다. 이는 실제로 시뮬레이션을 통해 직관적으로 이해할 수 있다. 시뮬레이션을 직접 작동해 보면, <strong>$n$ 이 클수록, $p$ 가 0이나 1에 가깝지 않고, 0.5에 가까울수록 정규 분포로의 근사가 더욱 정확</strong>해지는 것을 확인할 수 있다.</p>

<p>타율 3할인 타자가 100번 타석에 들어서면 안타를 얼마나 칠까? 사망률이 30%인 감염병에 100명이 걸렸을 때 실제로 얼마나 사망할까? 등 실제 많은 사건들 이항 분포를 따른다고 할 수 있다. 정규 분포가 이항 분포의 근사값으로 표현된다면 정규 분포 역시 많은 사건을 설명할 수 있는 분포가 될 것이다.</p>

<p><br /><br />
<strong>참조</strong></p>

<p><a href="https://www.geogebra.org/m/hMuamz5w">Binomial Distribution Image Generator(Michael Borcherds)</a><br />
<a href="https://www.geogebra.org/m/hGkW4vwJ">Parameters of the Binomial Distribution(shanlee)</a><br />
<a href="https://datascienceschool.net/02%20mathematics/08.02%20%EB%B2%A0%EB%A5%B4%EB%88%84%EC%9D%B4%EB%B6%84%ED%8F%AC%EC%99%80%20%EC%9D%B4%ED%95%AD%EB%B6%84%ED%8F%AC.html">데이터 사이언스 스쿨</a><br />
<a href="https://bookdown.org/mathemedicine/Stat_book/normal-distribution.html#-1">기초통계 개념정리(김진섭)</a><br /></p>]]></content><author><name>Jenny Won (Dajeong Won)</name></author><category term="통계학" /><summary type="html"><![CDATA[이항 분포에 앞서, 베르누이 분포에 대해 간략히 정리하고, 이항 분포와 베르누이 분포가 어떤 관계가 있는지 알아보자. 베르누이 분포 확률 실험의 결과가 성공 혹은 실패로 나타나는 실험을 베르누이 실험(Bernoulli Experiment)라고 한다. 그리고 성공 확률이 \(p\)로 고정된 베르누이 실험에서 성공의 횟수를 나타내는 확률 분포가 바로 베르누이 분포이다. 즉, 베르누이 분포는 확률 변수의 값이 성공 혹은 실패로 나타나는 확률 분포이며, 그 결과가 성공 혹은 실패, 두 값 중 하나만 가지므로 베르누이 확률 변수는 이산 확률 변수라고 할 수 있다. \[x  \{ \text{success, fail} \} \rightarrow \{0, 1\}\] \[\begin{equation} \begin{aligned} &amp; P(x=0) = 1-p \\ &amp; P(x=1) = p \\ \end{aligned} \end{equation}\] 확률 변수 \(X\)가 베르누이 분포에 의해 발생된다면 다음과 같이 표현할 수 있다. \[\begin{equation}   \begin{aligned}  &amp; x \sim \text{Bern}(p) \end{aligned}    \end{equation}\] 그리고 그 확률 질량 함수(PMF)는 다음과 같이 수식으로 나타낼 수 있다. \(\begin{split} \begin{align} \text{Bern}(x; p) = \begin{cases} p &amp; \text{if }x=1, \\ 1-p &amp; \text{if }x=0 \end{cases} \tag{8.2.2} \end{align} \end{split}\) 여기서 주목해야 할 점은, 베르누이 분포는 한번의 시행에 대한 결과에서 성공 확률 \(p\)에 집중한 관찰 데이터라는 점이다. 이 점은 이항 분포가 베르누이 분포와 어떻게 다른지를 설명하게 된다. 이항 분포의 정의 정의   이항 분포(Binomial Distribution)은 동일한 확률 \(p\) 로 성공하는 베르누이 시행을 고정된 수 \(n\) 번을 반복할 때의 성공 횟수를 모델링하는 확률 분포이다. 이항 분포는 베르누이 시행을 \(n\)번 반복하여 얻게된 확률 분포이다. 다시말해, 이항분포는 베르누이 시행의 확장이라고 할 수 있다. 단 한 번의 베르누이 시행이 아닌, \(n\)번의 반복된 베르누이 시행에서 성공 횟수에 대한 확률 분포를 모델링한 것이 바로 이항 분포이다. 동전 던지기의 예를 들어보자. 앞면이 나올 확률이 \(p=1/2\)인 동전 던지기를 한번 시행 했을때, 그 결과는 베르누이 분포를 따르게 된다. 하지만 동일한 동전을 10번 던지고 앞면이 나온 횟수를 관찰하는 경우, 이 시나리오는 이항 분포를 따르게 된다. 여기서 핵심은 10번 던지는 동안 각각의 던지기가 독립적이며, 각 시행의 성공 확률은 \(p\) 로 동일해야 한다는 점이다.(원래 베르누이 시행의 성공확률은 고정된 \(p\)를 갖는다.) 이항 분포는 다음과 같이 표현할 수 있으며, \[\begin{equation}   \begin{aligned}  x \sim \text{Bin}(n,p) \end{aligned}    \end{equation}\] 이항 분포의 확률 밀도 함수(PMF)는 다음과 같이 정의된다. \[\begin{equation}  P_X(x) = \ _{n}C_{x} p^k (1-p)^{n-x} \quad \text{ for } x =0,1,\cdots,n \end{equation}\] 이항 분포의 이해 10번의 동전 던지기 예시 확률 질량 함수를 이해하기 위해서, 앞선 10번의 동전 던지기의 확률을 직접 구해보자. 앞면이 나오는 경우를 성공이라 하고, \(x\)를 성공 횟수라고 하자. 즉, \(x = 0, 1, 2, \cdots, 10\) 이고, 각각은 앞면이 0번, 1번, 2번, … 10번 나오는 경우를 의미할 것이다. \(x=2\)일 떄, 즉 10번의 시행 중 동전의 앞면이 2번 나오는 확률을 생각해 보자. 그림과 같이 각각의 독립된 \((\frac{1}{2})^2(1-\frac{1}{2})^{8}\)의 확률이 \( _{10}C_{2}\)의 경우의 수로 출현할 수 있다. 이것은 다음과 같이 계산된다. \[_{10}C_{2}\left(\frac{1}{2}\right)^2 \left(1-\frac{1}{2}\right)^{8} = 0.0439\] 같은 방법으로, 모든 x에 대해서 그 확률을 계산해 보면 다음과 같다. \[x=0 ; \frac{10!}{1!\cdot9!} \left(\frac{1}{2}\right)^0 \left(1-\frac{1}{2}\right)^{10} = 0.0010\] \[x=1 ; \frac{10!}{1!\cdot9!} \left(\frac{1}{2}\right)^1 \left(1-\frac{1}{2}\right)^{9} = 0.0098\] \[x=2 ; \frac{10!}{2! 8!}\left(\frac{1}{2}\right)^2 \left(1-\frac{1}{2}\right)^{8} = 0.0439\] ⋮ \[x=10 ; \frac{10!}{10! 0!}\left(\frac{1}{2}\right)^{10} \left(1-\frac{1}{2}\right)^{0} = 0.0010\] 이것을 히스토그램으로 나타내면 다음과 같다. 직관적 이항 분포 이항 분포는 동전 던지기처럼 두 가지 결과가 있는 확률적 사건을 몇 번 반복했을 때, 어떤 결과를 얻을 확률을 구하기 위해 사용된다. 실제로 어떻게 활용될 수 있는 지, 보다 직관적인 이해를 위해 실제로 이항 분포의 활용이 고려되는 알아보자. 예시 1 마케팅 팀에서 1,000명의 고객에게 메일을 각각 발송했다. 이전의 경험을 토대로 회신을 받을 수 있는 확률이 0.5라고 가정하자. 자, 발송된 1,000개의 메일에 대해 50명의 고객으로 부터 회신을 받을 확률은 어떻게 될까? 아주 간단한 \(n=1,000\), \(p=0.5\)인 이항 분포의 확률 \(P_X(50)\)을 구하는 문제이다. 이처럼 이항 분포는 기본적으로 시행 횟수와 성공 확률이 고정되었을 때, 성공이 출현할 확률을 구할 때 활용될 수 있다. 또한, A/B테스를 진행하며 이항 분포의 개념이 활용될 수 있다. 아래 예시를 보자. 예시 2 웹사이트의 버튼 클릭률을 높이기 위해 두 가지 디자인(A와 B)의 효과를 비교하는 A/B테스트를 수행한다고 가정해 보자. 웹사이트 방문자 1,000명에게 B디자인을 노출시킨 후, 150명이 클릭했다. 우리는 디자인 B의 클릭률이 디자인 A의 클릭률 10%와 통계적으로 유의미하게 다른지를 평가하고자 한다. 방문자의 클릭 여부가 독립이라는 가정 하에, 각 웹사이트 방문자가 클릭하는 행위는 클릭(성공) 또는 비클릭(실패)의 이항 결과를 갖는다. 우리는 성공 확률 p를 10%, 시도 횟수 n은 1,000명, 성공 횟수 150명으로 설정하고 이항 검정을 수행할 수 있다. 이항 분포의 평균과 분산 총 시행 횟수가 \(n\), 성공 확률이 \(p\)인 이항 분포를 따르는 확률 변수 X에 대해, 기댓값은 \[E(X) = np\] 분산은 \[Var(X) = np(1-p)\] 이다. 각각의 증명은 다음과 같다. \(\begin{split} \begin{align} \begin{aligned} \text{E}[X] &amp;= \sum_{x_i \in \Omega} x_i p(x_i) \\ &amp;= 1 \cdot \mu + 0 \cdot (1 - \mu) \\ &amp;= \mu \end{aligned} \end{align} \end{split}\) \[\begin{split} \begin{align} \begin{aligned} \text{Var}[X] &amp;= \sum_{x_i \in \Omega} (x_i - \mu)^2 p(x_i) \\ &amp;= (1 - \mu)^2 \cdot \mu + (0 - \mu)^2 \cdot (1 - \mu) \\ &amp;= \mu(1-\mu) \end{aligned} \end{align} \end{split}\] 이항 분포의 정규 분포 근사 자, 그럼 이항 분포의 파라미터를 자유롭게 변경하며 이항 분포의 여러 모양을 관찰해 보자. 이러한 결과를 쉽게 확인할 수 있는 다양한 시뮬레이션이 온라인에 공개되어 있고, 그 중 GeoGebra에서 Parameters of the Binomial Distribution(shanlee) 시뮬레이션을 활용했다. n이 계속 증가한다면, 즉 시행을 많이 한다면 이항 분포는 어떻게 변할까? 50번의 동전 던지기를 시행했을 때 종모양(bell shape)의 정규 분포와 유사한 형태를 띄는 것을 확인할 수 있다. 하지만 시뮬레이션을 직접 작동해보면, $n$ 과 $p$ 의 값이 극단적이지 않은 경우에만 가능하다는 것을 알 수 있다. $n$ 이 너무 작거나, $n$ 이 충분히 크지만 $p$ 가 너무 작거나 클 경우 정규 분포의 모양과 많이 벗어나게 된다. 수학적으로 이항 분포의 $n$ 이 충분히 커서 $np&gt;=5$, $np(1-p)&gt;=5$ 조건을 만족하면, 이항 분포의 평균이 $np$, 분산이 $np(1-p)$ 인 정규 분포에 근사할 수 있다고 한다. 이는 실제로 시뮬레이션을 통해 직관적으로 이해할 수 있다. 시뮬레이션을 직접 작동해 보면, $n$ 이 클수록, $p$ 가 0이나 1에 가깝지 않고, 0.5에 가까울수록 정규 분포로의 근사가 더욱 정확해지는 것을 확인할 수 있다. 타율 3할인 타자가 100번 타석에 들어서면 안타를 얼마나 칠까? 사망률이 30%인 감염병에 100명이 걸렸을 때 실제로 얼마나 사망할까? 등 실제 많은 사건들 이항 분포를 따른다고 할 수 있다. 정규 분포가 이항 분포의 근사값으로 표현된다면 정규 분포 역시 많은 사건을 설명할 수 있는 분포가 될 것이다. 참조 Binomial Distribution Image Generator(Michael Borcherds) Parameters of the Binomial Distribution(shanlee) 데이터 사이언스 스쿨 기초통계 개념정리(김진섭)]]></summary></entry><entry xml:lang="en"><title type="html">Probability Distribution</title><link href="http://localhost:4000/2024/03/26/random_variables_en.html" rel="alternate" type="text/html" title="Probability Distribution" /><published>2024-03-26T00:00:00+09:00</published><updated>2024-03-26T00:00:00+09:00</updated><id>http://localhost:4000/2024/03/26/random_variables_en</id><content type="html" xml:base="http://localhost:4000/2024/03/26/random_variables_en.html"><![CDATA[<p>A simple explanation of a random variable is that it connects <strong><u>the outcome</u> of <u>a random preocess</u> to a number</strong>. A common example is flipping a coin. Flipping a coin 5 times at random and the total number of heads obtained can be considered a random variable. Understanding that flipping a coin 5 times is a random process is not difficult, making it an intuitive concept. So, what does it mean to connect such results to a number?</p>

<p>To understand this, let’s discuss ‘magnitude or scale’ from a mathematical perspective. The outcome of random processes, like rolling dice, carries uncertainty. Can we mathematically express the ‘how much’ of this uncertainty? If the outcome is expressed numerically, it would allow for the most intuitive interpretation. What if it could even be operated on?… From this approach, we can appreciate the value of defining a random variable. In fact, this level of understanding might be sufficient. However, for those who wish to delve deeper into academic study, we can explore the concept of a random variable more mathematically.</p>

<p><br /></p>
<h2 id="mathematical-approach">Mathematical Approach</h2>
<p>To delve into the concept of a random variable as defined in probability theory, it’s necessary to start with some foundational concepts. Although this requires a deep mathematical understanding, I will attempt to approach it in as intuitive a manner as possible. Let’s approach the mathematical definition of a random variable step by step</p>

<h3 id="measure-theory">Measure Theory</h3>
<p>To grasp the concept of measure, let’s first imagine <strong>“a scenario where a cap is filled with water”.</strong></p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/random_variables/water_glass.jpeg" />
</p>

<p><br />To answer the question “How much water is in the cup?”, we <u>define and measure 'volume'</u>. If we assign a ‘volume’ to a certain set, such as a three-dimentional object, it means we are <u>assigning a concept of 'size' to that set</u>. This concept is referred to as <strong>measure</strong> in mathematics. Measure theory deals with the generalized concept of measure, including size, area, volume, etc., and is a theory that measures and analyzes the size of sets and functions. This theory plays a crucial role, especially in probability theory and functional analysis, which explains why we frequently encounter sets in our study of probability. <strong>What’s important to note is that the ‘probability’ we discuss prepresents this concept of size as a ‘measure’.</strong> Therefore, we can only truly understand the definition of probability based on measure theory.</p>

<p><br /></p>
<h3 id="probability">Probability</h3>
<p>When we conduct an experiment to obtain results from a certain phenomenon, we achieve what are called realization. This term ‘realization’ might feel unfamiliar. If you think of it as the outcome which is the result of the experiment, it becomes easier to understand. Now, let’s delve into the concept of probability based on measure theory through the example of rolling dice, which is a type of random experiment.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/random_variables/definition_random_variable_1.png" />
</p>

<p><br /> 
In the sample space \(\Omega = \{1,2,3,4,5,6\}\), to mathematically discuss the magnitude of the event (\(\mathcal{F}\)) where a die lands on 2, we utilize a measure called probability, denoted by \(Pr(\cdot)\). Through this definition, we articulate that the probability of the event where the die shows a 2 is \(Pr(2) = \frac{1}{6}\).</p>

\[\begin{equation} 
\begin{aligned} 
&amp; Pr(1) = Pr(2) = Pr(3) = Pr(4) = Pr(5) = Pr(6) = 1/6
\end{aligned} 
\end{equation}\]

<p>In other words, <strong>“probability is a measure for the realization from a random experiment”</strong>, and by using the measure known as probability $Pr(\cdot)$$, we can obtain the measured realization of the size of elements within the space.</p>

<h3 id="sigma-field-mathcalb">\(\sigma\)-field \(\mathcal{B}\)</h3>
<p>To define probability without contradictions by introducing the concept of measure, it’s necessary to precisely define the objects of measurement. This is where the \(\sigma\)-field comes in. A \(\sigma\)-field is defined as a collection of sets that satisfies certain conditions.</p>

<p>(i) $\emptyset \in \mathcal{B}$  <br />
(ii) $A \in \mathcal{B} \Rightarrow A^c \in \mathcal{B}$ <br />
(iii) $A_i \in \mathcal{B} \Rightarrow \cup_{i=1}^{\infty}A_i \in \mathcal{B}$ <br /></p>

<p>(i) It includes the non-empty set, (ii) the complement, and (iii) is closed under countable unions and intersections of sets \(S\), defined as a collection of subsets. Given such a collection of sets, we can define a measurable space, which allows for the consistent definition of measure and probability.</p>

<p><br /></p>
<ul>
  <li><strong>Measure</strong><br />
A measure \(\mu\) is a type of set function in a measurable space \((U, \mathcal{B})\) that assigns elements in \([0,\infty]\) to elements of the \(\sigma\)-field.
\begin{equation} 
\begin{aligned} 
\mu : \mathcal{B} \rightarrow [0, \infty]
\end{aligned} 
\end{equation}
    <ul>
      <li>\(\mu(\emptyset) = 0\): The measure of the empty set is 0.<br /></li>
      <li>For any sequence of mutually exclusive sets \(A_j\), \(A_j\), the measure of their union is equal to the sum of their measures : \(\mu(\cup_{i=1}^{\infty} A_i) = \sum_{i=1}^{\infty} \mu(A_i)\).</li>
    </ul>
  </li>
</ul>

<p><br /></p>
<ul>
  <li><strong>Probability</strong><br />
Probability refers to a normalized measure on the extire set \(U\) such that \(\mu(U)=1\), indicating that the measure satisfies the condition of the total measure of the sample space being 1.</li>
</ul>

<p>Probability can be described as a measure where the total probability across the entire sample space equals 1.</p>

<hr />

<h3 id="definition-of-a-random-variable">Definition of a Random Variable</h3>
<p>Noew, it’s time to examine the definition of a random variable.</p>

<p>**Definition   A random variable \(x\) is a function defined on the sample space \(\Omega\). This function serves to transform an element of the probability space \((\Omega, \mathcal{F}, P)\) into an element of the Boral measurable space \((\mathbb{R}, \mathcal{B})\)</p>

<p>Here, the space created by the set of real numbers is referred to as the BOrel measurable space, and the associated \(\sigma\)-field in this context is termed the Borel set.</p>

<details>
<summary>Borel Measurable Space</summary>
<div>

    <p><strong>Borel Measurable Space</strong>: Consists of the set of real numbers \(\mathbb{R}\) and the Borel \(\sigma\) algebra \(\mathcall{B}\). The Borel \(\sigma\)-algebra includes open intervals on the real line and encompasses all sets that can be generated from these intervals. Essentially, this makes it possible to measure events in the commonly dealt with real number space.</p>

  </div>
</details>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/random_variables/definition_random_variable_2.png" />
</p>

<ul>
  <li>\(\Omega\) : Known as the Space, this represents the entire set of possible elements or outcomes.</li>
  <li>\(\mathcal{F}\) : Signifies the subsets of the sample space, referred to as Events.</li>
  <li>\(Pr\) : Acts as the operator that performs measurement, assigning probabilites to elements of the sample space.</li>
</ul>

<p>Through these complex concepts, we conclude that a random variable is essentially a function that transforms an element of the sample space into a real number. By defining this, we become interested in practically applying the probability of a random variable \(x\), denoted as \(Pr(x)\)</p>

<h2 id="types-of-random-variables">Types of Random Variables</h2>

<p>Random variables are broadly classified into discrete and continuous types. A random variable that can take on either a finite number of values or a countably infinite number of values, such as the outcome of rolling a dice or baseball game socres, is called a <strong>discrete random variables</strong>. The Probability Mass Function(PMF) of a discrete random variable can assign a clear probability to each value. On the other hand, a random variable that can take values in a continuous range, such as temperature, stock prices, duration, speed, or measurements of an object’s length, is called a <strong>continuous random variable</strong>. Although the Probability Density Function(PDF) of a continuous random variable cannot assign a probability to each specific value, it can express the probability over a range of values.</p>

<p>Discrete probability distributions include, notably, the binomial distribution, Poisson distribution, and geometric distribution, while continuous probability distributions include the normal distribution, uniform distribution, and exponential distribution. The following outlines the relations among various probability distributions.</p>]]></content><author><name>Jenny Won (Dajeong Won)</name></author><category term="Stastistics" /><summary type="html"><![CDATA[A simple explanation of a random variable is that it connects the outcome of a random preocess to a number. A common example is flipping a coin. Flipping a coin 5 times at random and the total number of heads obtained can be considered a random variable. Understanding that flipping a coin 5 times is a random process is not difficult, making it an intuitive concept. So, what does it mean to connect such results to a number? To understand this, let’s discuss ‘magnitude or scale’ from a mathematical perspective. The outcome of random processes, like rolling dice, carries uncertainty. Can we mathematically express the ‘how much’ of this uncertainty? If the outcome is expressed numerically, it would allow for the most intuitive interpretation. What if it could even be operated on?… From this approach, we can appreciate the value of defining a random variable. In fact, this level of understanding might be sufficient. However, for those who wish to delve deeper into academic study, we can explore the concept of a random variable more mathematically. Mathematical Approach To delve into the concept of a random variable as defined in probability theory, it’s necessary to start with some foundational concepts. Although this requires a deep mathematical understanding, I will attempt to approach it in as intuitive a manner as possible. Let’s approach the mathematical definition of a random variable step by step Measure Theory To grasp the concept of measure, let’s first imagine “a scenario where a cap is filled with water”. To answer the question “How much water is in the cup?”, we define and measure 'volume'. If we assign a ‘volume’ to a certain set, such as a three-dimentional object, it means we are assigning a concept of 'size' to that set. This concept is referred to as measure in mathematics. Measure theory deals with the generalized concept of measure, including size, area, volume, etc., and is a theory that measures and analyzes the size of sets and functions. This theory plays a crucial role, especially in probability theory and functional analysis, which explains why we frequently encounter sets in our study of probability. What’s important to note is that the ‘probability’ we discuss prepresents this concept of size as a ‘measure’. Therefore, we can only truly understand the definition of probability based on measure theory. Probability When we conduct an experiment to obtain results from a certain phenomenon, we achieve what are called realization. This term ‘realization’ might feel unfamiliar. If you think of it as the outcome which is the result of the experiment, it becomes easier to understand. Now, let’s delve into the concept of probability based on measure theory through the example of rolling dice, which is a type of random experiment. In the sample space \(\Omega = \{1,2,3,4,5,6\}\), to mathematically discuss the magnitude of the event (\(\mathcal{F}\)) where a die lands on 2, we utilize a measure called probability, denoted by \(Pr(\cdot)\). Through this definition, we articulate that the probability of the event where the die shows a 2 is \(Pr(2) = \frac{1}{6}\). \[\begin{equation}  \begin{aligned}  &amp; Pr(1) = Pr(2) = Pr(3) = Pr(4) = Pr(5) = Pr(6) = 1/6 \end{aligned}  \end{equation}\] In other words, “probability is a measure for the realization from a random experiment”, and by using the measure known as probability $Pr(\cdot)$$, we can obtain the measured realization of the size of elements within the space. \(\sigma\)-field \(\mathcal{B}\) To define probability without contradictions by introducing the concept of measure, it’s necessary to precisely define the objects of measurement. This is where the \(\sigma\)-field comes in. A \(\sigma\)-field is defined as a collection of sets that satisfies certain conditions. (i) $\emptyset \in \mathcal{B}$ (ii) $A \in \mathcal{B} \Rightarrow A^c \in \mathcal{B}$ (iii) $A_i \in \mathcal{B} \Rightarrow \cup_{i=1}^{\infty}A_i \in \mathcal{B}$ (i) It includes the non-empty set, (ii) the complement, and (iii) is closed under countable unions and intersections of sets \(S\), defined as a collection of subsets. Given such a collection of sets, we can define a measurable space, which allows for the consistent definition of measure and probability. Measure A measure \(\mu\) is a type of set function in a measurable space \((U, \mathcal{B})\) that assigns elements in \([0,\infty]\) to elements of the \(\sigma\)-field. \begin{equation}  \begin{aligned}  \mu : \mathcal{B} \rightarrow [0, \infty] \end{aligned}  \end{equation} \(\mu(\emptyset) = 0\): The measure of the empty set is 0. For any sequence of mutually exclusive sets \(A_j\), \(A_j\), the measure of their union is equal to the sum of their measures : \(\mu(\cup_{i=1}^{\infty} A_i) = \sum_{i=1}^{\infty} \mu(A_i)\). Probability Probability refers to a normalized measure on the extire set \(U\) such that \(\mu(U)=1\), indicating that the measure satisfies the condition of the total measure of the sample space being 1. Probability can be described as a measure where the total probability across the entire sample space equals 1. Definition of a Random Variable Noew, it’s time to examine the definition of a random variable. **Definition   A random variable \(x\) is a function defined on the sample space \(\Omega\). This function serves to transform an element of the probability space \((\Omega, \mathcal{F}, P)\) into an element of the Boral measurable space \((\mathbb{R}, \mathcal{B})\) Here, the space created by the set of real numbers is referred to as the BOrel measurable space, and the associated \(\sigma\)-field in this context is termed the Borel set. Borel Measurable Space Borel Measurable Space: Consists of the set of real numbers \(\mathbb{R}\) and the Borel \(\sigma\) algebra \(\mathcall{B}\). The Borel \(\sigma\)-algebra includes open intervals on the real line and encompasses all sets that can be generated from these intervals. Essentially, this makes it possible to measure events in the commonly dealt with real number space. \(\Omega\) : Known as the Space, this represents the entire set of possible elements or outcomes. \(\mathcal{F}\) : Signifies the subsets of the sample space, referred to as Events. \(Pr\) : Acts as the operator that performs measurement, assigning probabilites to elements of the sample space. Through these complex concepts, we conclude that a random variable is essentially a function that transforms an element of the sample space into a real number. By defining this, we become interested in practically applying the probability of a random variable \(x\), denoted as \(Pr(x)\) Types of Random Variables Random variables are broadly classified into discrete and continuous types. A random variable that can take on either a finite number of values or a countably infinite number of values, such as the outcome of rolling a dice or baseball game socres, is called a discrete random variables. The Probability Mass Function(PMF) of a discrete random variable can assign a clear probability to each value. On the other hand, a random variable that can take values in a continuous range, such as temperature, stock prices, duration, speed, or measurements of an object’s length, is called a continuous random variable. Although the Probability Density Function(PDF) of a continuous random variable cannot assign a probability to each specific value, it can express the probability over a range of values. Discrete probability distributions include, notably, the binomial distribution, Poisson distribution, and geometric distribution, while continuous probability distributions include the normal distribution, uniform distribution, and exponential distribution. The following outlines the relations among various probability distributions.]]></summary></entry><entry xml:lang="ko"><title type="html">확률 변수</title><link href="http://localhost:4000/2024/03/26/random_variables_ko.html" rel="alternate" type="text/html" title="확률 변수" /><published>2024-03-26T00:00:00+09:00</published><updated>2024-03-26T00:00:00+09:00</updated><id>http://localhost:4000/2024/03/26/random_variables_ko</id><content type="html" xml:base="http://localhost:4000/2024/03/26/random_variables_ko.html"><![CDATA[<p>확률 변수를 쉽게 설명하자면 <strong><u>무작위적인 시행(Random Process)</u>에 따른 <u>결과를 숫자로 연결</u>하는 것</strong>이라고 이해할 수 있다. 가장 일반적인  예로 동전 던지기가 있다. <u>임의로 동전을 5번 던져서</u> 나온 <u>앞면의 합계</u>는 확률 변수라고 할 수 있다. 동전을 5번 던지는 행위가 무작위 시행이라는 것을 이해하기 어렵지 않은, 꽤나 직관적인 개념이다. 그렇다면 이러한 결과를 수치로 연결한다는 것은 어떤 의미가 있을까?</p>

<p>이를 이해하기 위해 수학의 입장에서 ‘크기 혹은 규모’에 대해서 이야기 해보려고 한다. 주사위 던지기와 같은 무작위적 시행의 결과는 <strong>불확실성</strong>을 갖는다. 이러한 ‘얼마나’라는 불확실성의 크기를 수학적으로 표현할 수 있을까? 물론 그 결과가 수치로써 표현된다면 가장 직관적인 해석이 가능할 것이다. 심지어 연산도 가능하다면?… 이러한 접근에서 확률 변수를 정의하는 것의 가치를 이해해 볼 수 있다. 사실 이 정도의 이해만으로도 충분할 수 있다. 하지만 보다 학문적 공부를 진행해보고자 확률 변수의 개념을 수학적으로 탐색해 보고자 한다.</p>

<p><br /></p>
<h2 id="수학적-접근">수학적 접근</h2>

<p>확률론에서 정의하는 확률 변수를 이해하기 위해서는 선행되어야 할 개념들이 있다. 수학적으로 꽤나 심도있는 이해를 요구하지만 가능하다면 직관적으로 이해해 보려고 한다. 차근차근 확률 변수의 수학적 정의에 접근해보자.</p>

<p><br /></p>
<h3 id="측도론measure-theory">측도론(Measure Theory)</h3>
<p>측도(Measure)라는 개념을 먼저 이해하기 위해 <strong>‘컵에 물이 담겨져 있는 상황’</strong>을 가정해보자. 
<br /></p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/random_variables/water_glass.jpeg" />
</p>

<p><br />‘물이 얼마나 담겨 있을까?’라는 질문에 답을 하기 위해 우리는 <u>'부피'를 정의하고 측정</u>한다. 3차원 입체라는 어떠한 집합에 ‘부피’라는 크기를 부여하게 된다면, 이는 그 <u>집합에 '크기'라는 개념을 부여하는 것</u>이 된다. 이를 수학에서 <strong>측도(Measure)</strong>라고 한다. 측도론은 크기, 면적, 부피 등의 일반화한 측도(Measure)의 개념을 다루는 분야로, 집합과 함수의 크기를 측정하고 분석하는 이론이다. 이 이론은 특히 확률론과 함수해석학에서 중요한 역할을 하는데, 우리가 확률을 공부하면서 자꾸만 집합을 마주치는 이유이기도 하다. <strong>중요한 것은, 우리가 이야기하는 ‘확률’이 바로 이러한 크기라는 속성을 나타내는 ‘측도’라는 것이다.</strong> 따라서 측도론에 기반하여 확률을 이해할 수 있어서야 비로소 그 정의를 이해할 수 있다.</p>

<p><br /></p>
<h3 id="확률probability">확률(Probability)</h3>

<p>우리는 어떠한 현상으로부터 결과를 얻기 위해 실험(experiment)을 하고, 실현값(outcome)을 얻을 수 있다. 실현값이라는 단어가 다소 생소하게 느껴질 수 있다. 이는 결과값 즉, outcome이라고 생각한다면 이해가 쉬워진다. 자, 그럼 주사위 던지기라는 확률 실험(Random Experiment)을 통해 측도론에 기반한 확률의 개념을 이해해 보자.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/random_variables/definition_random_variable_1.png" />
</p>

<p><br /> 
표본공간 \(\Omega=\{1,2,3,4,5,6\}\) 에서 주사위의 눈이 2가 나오는 사건(Event, \(\mathcal{F}\))의 크기를 수학적으로 말하기 위해, 우리는 확률 \(Pr(\cdot)\) 라는 측도를 사용할 수 있다. 그리고 이를 정의함으로써 \(Pr(2) = 1/6\) 와 같은 실현값(outcome)을 얻을 수 있게 된다.</p>

\[\begin{equation} 
\begin{aligned} 
&amp; Pr(1) = Pr(2) = Pr(3) = Pr(4) = Pr(5) = Pr(6) = 1/6
\end{aligned} 
\end{equation}\]

<p>다시말해, <strong>‘확률’은 이러한 확률 실험(Random Experiment)의 실현값(Realization)에 대한 측도(Masure)</strong>이며, 우리는 확률 \(Pr(\cdot)\)이라는 측도를 사용하여 공간 내 원소의 크기를 측정한 실현값(Realization)을 얻을 수 있다.</p>

<h3 id="sigma-field-mathcalb">\(\sigma\)-field \(\mathcal{B}\)</h3>
<p>이렇게 측도라는 개념을 도입하여 확률을 모순없이 정의하기 위해서는 측정 대상을 엄밀히 정의하는 과정이 필요한데, 그러한 측정대상을 정의하는 것이 바로 \(\sigma\)-field이다. \(\sigma\)-field는 다음과 같이 정의되는 집합들의 모입이다.</p>

<p>(i) $\emptyset \in \mathcal{B}$  <br />
(ii) $A \in \mathcal{B} \Rightarrow A^c \in \mathcal{B}$ <br />
(iii) $A_i \in \mathcal{B} \Rightarrow \cup_{i=1}^{\infty}A_i \in \mathcal{B}$ <br /></p>

<p>(i)공집합이 아니면서, (ii)여집합, 그리고 (iii) 셀 수 있는 합집합, 교집합에 대하여 닫혀있는 집합 \(S\)의 부분집합의 모임이라고 정의된다. 이러한 집합의 모입이 주어졌을 때, 측정할 수 있는 공간, 즉 가측공간(Measurable Space)를 정의할 수 있고, 측도와 확률을 모순없이 정의할 수 있다.</p>

<p><br /></p>
<ul>
  <li><strong>측도(Measure)</strong><br />
측도\(\mu\)란 가측공간 \((U, \mathcal{B})\)에서 \(\sigma\)-field의 원소를 사용하여 \([0,\infty]\)의 값을 반환하는 일종의 집합 합수(set function)이다.<br />
\begin{equation} 
\begin{aligned} 
\mu : \mathcal{B} \rightarrow [0, \infty]
\end{aligned} 
\end{equation}
    <ul>
      <li>\(\mu(\emptyset) = 0\): 공집합에 대한 측도응 0이다.<br /></li>
      <li>서로소 집합들 \(A_j\), \(A_j\) 들에 대하여 \(\mu(\cup_{i=1}^{\infty} A_i) = \sum_{i=1}^{\infty} \mu(A_i)\)이 성립한다.</li>
    </ul>
  </li>
</ul>

<p><br /></p>
<ul>
  <li><strong>확률(Probability)</strong><br />
확률(Probability)이란 전체집합 \(U\)에 대하여 \(\mu(U)=1\)의 크기를 만족하도록 정규화된 측도(Nomarlized Measure)를 의미한다.</li>
</ul>

<p><br /></p>

<p>확률은 전체 표본공간에 대한 확률의 총량이 1인 측도라고 할 수 있다.</p>

<hr />

<h3 id="확률-변수의-정의">확률 변수의 정의</h3>
<p>이제 확률 변수의 정의를 살펴볼 시간이다.</p>

<p class="info"><strong>정의</strong>   확률 변수 \(x\)는 표본공간 \(\Omega\) 에 정의된 함수를 의미한다. 이 함수는 확률공간\((\Omega, \mathcal{F}, P)\) 의 하나의 원소를 Borel 가측공간 \((\mathbb{R}, \mathcal{B})\) 의 원소로 변환하는 역할을 수행한다.<br /></p>

<p>여기서, 실수들의 집합으로 만들어진 공간을 Borel 가측공간(Mesurable Space)라고 하며, 이 때 \(\sigma\)-field를 Borel set이라고 한다.</p>

<details>
<summary>Borel 가측공간</summary>
<div>

    <p><strong>Borel 가측공간 (Borel Measurable Space)</strong>: 실수 집합 \(\mathbb{R}\) 과 Borel 시그마-대수 \(\mathcal{B}\) 로 구성된다. Borel 시그마-대수는 실수선 위에서 열린 구간을 포함하고, 이로부터 생성될 수 있는 모든 집합의 컬렉션이다. 이것은 기본적으로 우리가 흔히 다루는 실수 세계의 사건들을 측정 가능하게 한다.</p>

  </div>
</details>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/random_variables/definition_random_variable_2.png" />
</p>

<ul>
  <li>\(\Omega\) : 표본공간(Sample Space)라고 하며, 나올 수 있는 원소들의 전체 집합(Set)을 의미한다</li>
  <li>\(\mathcal{F}\) : 표본공간의 부분집합을 의미하며 사건(Event)이라고 부른다.</li>
  <li>\(Pr\) : 측도(Measure)를 수행하는 연산자로써 표본공간의 원소에 확률을 부여하는 역할한다.</li>
</ul>

<p>꽤나 어려운 개념들을 거쳐왔지만 결론적으로 확률 변수란 <strong>표본공간의 하나의 원소를 실수값으로 변환해주는 함수</strong>이다. 또한 이를 정의함으로써 우리는 실직절으로 확률 변수$x$의 확률인 $Pr(x)$의 활용에 관심을 갖게 된다.</p>

<h2 id="확률-변수의-유형">확률 변수의 유형</h2>
<p>확률 변수는 크게 이산형 확률 변수와 연속형 확률 변수로 분류된다.
주사위 던지기, 야구경기 점수와 같이 <u>유한하거나 셀 수 있는 무한한 값을 가지는 확률 변수</u>를 <strong>이산확률변수</strong>라고 한다. 이산확률변수의 확률밀도함수(Probability Mass Function, PMF)은 각 값에 대한 명확한 확률을 할당할 수 있다. 반면에 온도, 주식 가격, 기간, 속력, 물체의 길이 측정 등 <u>연속적인 범위의 값을 가는 확률 변수</u>를 <strong>연속확률변수</strong>라 한다. 연속확률변수의 확률밀도함수(Probability Mass Function, PMF)는 각 값에 대한 확률을 표현할 수는 없지만, 범위에 대한 확률을 표현할 수 있다.</p>

<p>이산확률분포에는 대표적으로 이항분포, 포아송분포, 기하분포 등이 있으며, 연속확률분포에는 정규분포, 균일분포, 지수분포 등이 있다. 다음은 다양한 확률분포 간의 관계를 나타낸다.</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/jenniione/jenniione.github.io/master/pics/random_variables/types of random variables.webp" />
</p>

<p><br /><br />
<strong>참조</strong></p>

<p>Probability and Statistics for Data Science (Carlos Fernandez-Granda)<br />
<a href="https://alida.tistory.com/84">ALIDA (Gyubeom Edward Im)</a><br />
<a href="https://jagan-singhh.medium.com/types-of-probability-distributions-9333d18ed817">Types of Probability Distributions (Jagandeep Singh)</a></p>]]></content><author><name>Jenny Won (Dajeong Won)</name></author><category term="통계학" /><summary type="html"><![CDATA[확률 변수를 쉽게 설명하자면 무작위적인 시행(Random Process)에 따른 결과를 숫자로 연결하는 것이라고 이해할 수 있다. 가장 일반적인 예로 동전 던지기가 있다. 임의로 동전을 5번 던져서 나온 앞면의 합계는 확률 변수라고 할 수 있다. 동전을 5번 던지는 행위가 무작위 시행이라는 것을 이해하기 어렵지 않은, 꽤나 직관적인 개념이다. 그렇다면 이러한 결과를 수치로 연결한다는 것은 어떤 의미가 있을까? 이를 이해하기 위해 수학의 입장에서 ‘크기 혹은 규모’에 대해서 이야기 해보려고 한다. 주사위 던지기와 같은 무작위적 시행의 결과는 불확실성을 갖는다. 이러한 ‘얼마나’라는 불확실성의 크기를 수학적으로 표현할 수 있을까? 물론 그 결과가 수치로써 표현된다면 가장 직관적인 해석이 가능할 것이다. 심지어 연산도 가능하다면?… 이러한 접근에서 확률 변수를 정의하는 것의 가치를 이해해 볼 수 있다. 사실 이 정도의 이해만으로도 충분할 수 있다. 하지만 보다 학문적 공부를 진행해보고자 확률 변수의 개념을 수학적으로 탐색해 보고자 한다. 수학적 접근 확률론에서 정의하는 확률 변수를 이해하기 위해서는 선행되어야 할 개념들이 있다. 수학적으로 꽤나 심도있는 이해를 요구하지만 가능하다면 직관적으로 이해해 보려고 한다. 차근차근 확률 변수의 수학적 정의에 접근해보자. 측도론(Measure Theory) 측도(Measure)라는 개념을 먼저 이해하기 위해 ‘컵에 물이 담겨져 있는 상황’을 가정해보자. ‘물이 얼마나 담겨 있을까?’라는 질문에 답을 하기 위해 우리는 '부피'를 정의하고 측정한다. 3차원 입체라는 어떠한 집합에 ‘부피’라는 크기를 부여하게 된다면, 이는 그 집합에 '크기'라는 개념을 부여하는 것이 된다. 이를 수학에서 측도(Measure)라고 한다. 측도론은 크기, 면적, 부피 등의 일반화한 측도(Measure)의 개념을 다루는 분야로, 집합과 함수의 크기를 측정하고 분석하는 이론이다. 이 이론은 특히 확률론과 함수해석학에서 중요한 역할을 하는데, 우리가 확률을 공부하면서 자꾸만 집합을 마주치는 이유이기도 하다. 중요한 것은, 우리가 이야기하는 ‘확률’이 바로 이러한 크기라는 속성을 나타내는 ‘측도’라는 것이다. 따라서 측도론에 기반하여 확률을 이해할 수 있어서야 비로소 그 정의를 이해할 수 있다. 확률(Probability) 우리는 어떠한 현상으로부터 결과를 얻기 위해 실험(experiment)을 하고, 실현값(outcome)을 얻을 수 있다. 실현값이라는 단어가 다소 생소하게 느껴질 수 있다. 이는 결과값 즉, outcome이라고 생각한다면 이해가 쉬워진다. 자, 그럼 주사위 던지기라는 확률 실험(Random Experiment)을 통해 측도론에 기반한 확률의 개념을 이해해 보자. 표본공간 \(\Omega=\{1,2,3,4,5,6\}\) 에서 주사위의 눈이 2가 나오는 사건(Event, \(\mathcal{F}\))의 크기를 수학적으로 말하기 위해, 우리는 확률 \(Pr(\cdot)\) 라는 측도를 사용할 수 있다. 그리고 이를 정의함으로써 \(Pr(2) = 1/6\) 와 같은 실현값(outcome)을 얻을 수 있게 된다. \[\begin{equation}  \begin{aligned}  &amp; Pr(1) = Pr(2) = Pr(3) = Pr(4) = Pr(5) = Pr(6) = 1/6 \end{aligned}  \end{equation}\] 다시말해, ‘확률’은 이러한 확률 실험(Random Experiment)의 실현값(Realization)에 대한 측도(Masure)이며, 우리는 확률 \(Pr(\cdot)\)이라는 측도를 사용하여 공간 내 원소의 크기를 측정한 실현값(Realization)을 얻을 수 있다. \(\sigma\)-field \(\mathcal{B}\) 이렇게 측도라는 개념을 도입하여 확률을 모순없이 정의하기 위해서는 측정 대상을 엄밀히 정의하는 과정이 필요한데, 그러한 측정대상을 정의하는 것이 바로 \(\sigma\)-field이다. \(\sigma\)-field는 다음과 같이 정의되는 집합들의 모입이다. (i) $\emptyset \in \mathcal{B}$ (ii) $A \in \mathcal{B} \Rightarrow A^c \in \mathcal{B}$ (iii) $A_i \in \mathcal{B} \Rightarrow \cup_{i=1}^{\infty}A_i \in \mathcal{B}$ (i)공집합이 아니면서, (ii)여집합, 그리고 (iii) 셀 수 있는 합집합, 교집합에 대하여 닫혀있는 집합 \(S\)의 부분집합의 모임이라고 정의된다. 이러한 집합의 모입이 주어졌을 때, 측정할 수 있는 공간, 즉 가측공간(Measurable Space)를 정의할 수 있고, 측도와 확률을 모순없이 정의할 수 있다. 측도(Measure) 측도\(\mu\)란 가측공간 \((U, \mathcal{B})\)에서 \(\sigma\)-field의 원소를 사용하여 \([0,\infty]\)의 값을 반환하는 일종의 집합 합수(set function)이다. \begin{equation}  \begin{aligned}  \mu : \mathcal{B} \rightarrow [0, \infty] \end{aligned}  \end{equation} \(\mu(\emptyset) = 0\): 공집합에 대한 측도응 0이다. 서로소 집합들 \(A_j\), \(A_j\) 들에 대하여 \(\mu(\cup_{i=1}^{\infty} A_i) = \sum_{i=1}^{\infty} \mu(A_i)\)이 성립한다. 확률(Probability) 확률(Probability)이란 전체집합 \(U\)에 대하여 \(\mu(U)=1\)의 크기를 만족하도록 정규화된 측도(Nomarlized Measure)를 의미한다. 확률은 전체 표본공간에 대한 확률의 총량이 1인 측도라고 할 수 있다. 확률 변수의 정의 이제 확률 변수의 정의를 살펴볼 시간이다. 정의   확률 변수 \(x\)는 표본공간 \(\Omega\) 에 정의된 함수를 의미한다. 이 함수는 확률공간\((\Omega, \mathcal{F}, P)\) 의 하나의 원소를 Borel 가측공간 \((\mathbb{R}, \mathcal{B})\) 의 원소로 변환하는 역할을 수행한다. 여기서, 실수들의 집합으로 만들어진 공간을 Borel 가측공간(Mesurable Space)라고 하며, 이 때 \(\sigma\)-field를 Borel set이라고 한다. Borel 가측공간 Borel 가측공간 (Borel Measurable Space): 실수 집합 \(\mathbb{R}\) 과 Borel 시그마-대수 \(\mathcal{B}\) 로 구성된다. Borel 시그마-대수는 실수선 위에서 열린 구간을 포함하고, 이로부터 생성될 수 있는 모든 집합의 컬렉션이다. 이것은 기본적으로 우리가 흔히 다루는 실수 세계의 사건들을 측정 가능하게 한다. \(\Omega\) : 표본공간(Sample Space)라고 하며, 나올 수 있는 원소들의 전체 집합(Set)을 의미한다 \(\mathcal{F}\) : 표본공간의 부분집합을 의미하며 사건(Event)이라고 부른다. \(Pr\) : 측도(Measure)를 수행하는 연산자로써 표본공간의 원소에 확률을 부여하는 역할한다. 꽤나 어려운 개념들을 거쳐왔지만 결론적으로 확률 변수란 표본공간의 하나의 원소를 실수값으로 변환해주는 함수이다. 또한 이를 정의함으로써 우리는 실직절으로 확률 변수$x$의 확률인 $Pr(x)$의 활용에 관심을 갖게 된다. 확률 변수의 유형 확률 변수는 크게 이산형 확률 변수와 연속형 확률 변수로 분류된다. 주사위 던지기, 야구경기 점수와 같이 유한하거나 셀 수 있는 무한한 값을 가지는 확률 변수를 이산확률변수라고 한다. 이산확률변수의 확률밀도함수(Probability Mass Function, PMF)은 각 값에 대한 명확한 확률을 할당할 수 있다. 반면에 온도, 주식 가격, 기간, 속력, 물체의 길이 측정 등 연속적인 범위의 값을 가는 확률 변수를 연속확률변수라 한다. 연속확률변수의 확률밀도함수(Probability Mass Function, PMF)는 각 값에 대한 확률을 표현할 수는 없지만, 범위에 대한 확률을 표현할 수 있다. 이산확률분포에는 대표적으로 이항분포, 포아송분포, 기하분포 등이 있으며, 연속확률분포에는 정규분포, 균일분포, 지수분포 등이 있다. 다음은 다양한 확률분포 간의 관계를 나타낸다. 참조 Probability and Statistics for Data Science (Carlos Fernandez-Granda) ALIDA (Gyubeom Edward Im) Types of Probability Distributions (Jagandeep Singh)]]></summary></entry></feed>